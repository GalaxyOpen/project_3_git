{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory:  /mnt/e/py_data/project_3_git/code\n"
     ]
    }
   ],
   "source": [
    "# 기본 작업 경로 설정\n",
    "import os\n",
    "notebook_path = os.path.abspath(\"project_3_git/code/3_lm_t5.ipynb\")\n",
    "notebook_dir = os.path.dirname(notebook_path)\n",
    "os.chdir(notebook_dir)\n",
    "\n",
    "# 현재 작업 디렉토리 출력\n",
    "print(\"Current working directory: \", os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 토이 데이터 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [\n",
    "    {\"input_text\": \"웃음,꽃밭\", \"target_text\": \"꽃밭에서 웃고 계시니 정말 기쁘네요!\"},\n",
    "    {\"input_text\": \"행복,바다\", \"target_text\": \"바다와 함께 행복한 순간을 보내고 계시네요!\"},\n",
    "    {\"input_text\": \"즐거움,산책로\", \"target_text\": \"산책로에서 즐거운 시간을 보내고 계시네요!\"},\n",
    "    {\"input_text\": \"미소,카페\", \"target_text\": \"카페에서 미소를 지으시니 정말 행복해 보이네요!\"},\n",
    "    {\"input_text\": \"기쁨,도서관\", \"target_text\": \"도서관에서 기쁜 표정을 보니 지식의 힘이 느껴지네요!\"},\n",
    "    {\"input_text\": \"활력,자전거\", \"target_text\": \"자전거를 타고 활기찬 모습이 멋지네요!\"},\n",
    "    {\"input_text\": \"행복,정원\", \"target_text\": \"정원에서 행복한 시간 보내시는 모습이 아름답습니다!\"},\n",
    "    {\"input_text\": \"웃음,피크닉\", \"target_text\": \"피크닉에서 웃고 계시니 즐거운 시간이군요!\"},\n",
    "    {\"input_text\": \"기쁨,공원\", \"target_text\": \"공원에서 기뻐하는 모습이 참 보기 좋네요!\"},\n",
    "    {\"input_text\": \"행복,산\", \"target_text\": \"산에서 행복한 표정을 지으시니 멋진 자연을 만끽하고 계시네요!\"},\n",
    "    {\"input_text\": \"미소,해변\", \"target_text\": \"해변에서 미소를 지으시니 정말 평화로워 보이네요!\"},\n",
    "    {\"input_text\": \"즐거움,수영장\", \"target_text\": \"수영장에서 즐거워하는 모습이 아주 기쁘네요!\"},\n",
    "    {\"input_text\": \"기쁨,화원\", \"target_text\": \"화원에서 기쁘게 웃고 계시니 자연이 주는 행복이 느껴지네요!\"},\n",
    "    {\"input_text\": \"웃음,등산로\", \"target_text\": \"등산로에서 웃고 계시니 산의 아름다움을 만끽하고 계신 것 같네요!\"},\n",
    "    {\"input_text\": \"행복,스포츠 경기장\", \"target_text\": \"스포츠 경기장에서 행복한 모습이 정말 열정적이네요!\"},\n",
    "    {\"input_text\": \"미소,산속 오두막\", \"target_text\": \"산속 오두막에서 미소를 지으시니 휴식이 정말 즐거워 보이네요!\"},\n",
    "    {\"input_text\": \"기쁨,수목원\", \"target_text\": \"수목원에서 기쁜 표정을 보니 자연과 함께하는 행복한 시간이군요!\"},\n",
    "    {\"input_text\": \"활력,스케이트보드\", \"target_text\": \"스케이트보드를 타며 활기차 보이시네요! 정말 에너지가 넘치네요!\"},\n",
    "    {\"input_text\": \"행복,겨울 산책\", \"target_text\": \"겨울 산책 중 행복한 모습이 겨울의 아름다움을 더해주네요!\"},\n",
    "    {\"input_text\": \"미소,아트 갤러리\", \"target_text\": \"아트 갤러리에서 미소를 지으시니 예술의 힘이 느껴지네요!\"},\n",
    "    {\"input_text\": \"즐거움,지하철 역\", \"target_text\": \"지하철 역에서도 즐거운 모습이 인상적이네요!\"},\n",
    "    {\"input_text\": \"기쁨,주말 마켓\", \"target_text\": \"주말 마켓에서 기쁜 표정이 행복을 전해주네요!\"},\n",
    "    {\"input_text\": \"활력,무대\", \"target_text\": \"무대에서 활기찬 모습이 정말 멋지네요!\"},\n",
    "    {\"input_text\": \"행복,농장\", \"target_text\": \"농장에서 행복하게 웃고 계시니 자연과 함께하는 기쁨이 느껴지네요!\"},\n",
    "    {\"input_text\": \"미소,로맨틱 레스토랑\", \"target_text\": \"로맨틱 레스토랑에서 미소를 지으시니 특별한 순간이군요!\"},\n",
    "    {\"input_text\": \"즐거움,카약\", \"target_text\": \"카약을 즐기며 행복해 보이시네요! 물과 함께하는 즐거운 시간이군요!\"},\n",
    "    {\"input_text\": \"기쁨,테라스\", \"target_text\": \"테라스에서 기쁜 표정을 보니 멋진 경치를 만끽하고 계시네요!\"},\n",
    "    {\"input_text\": \"활력,헬스장\", \"target_text\": \"헬스장에서 활기차 보이시네요! 운동 후의 기쁨이 전해지네요!\"},\n",
    "    {\"input_text\": \"행복,나무 그늘\", \"target_text\": \"나무 그늘에서 행복한 모습을 보니 여유로운 시간이 느껴지네요!\"},\n",
    "    {\"input_text\": \"미소,리조트\", \"target_text\": \"리조트에서 미소를 지으시니 완벽한 휴식을 취하고 계시네요!\"},\n",
    "    {\"input_text\": \"즐거움,놀이공원\", \"target_text\": \"놀이공원에서 즐거운 모습이 정말 신나 보이네요!\"},\n",
    "    {\"input_text\": \"기쁨,강가\", \"target_text\": \"강가에서 기쁜 표정이 물과 함께하는 행복을 더해주네요!\"},\n",
    "    {\"input_text\": \"활력,러닝\", \"target_text\": \"러닝 중 활기찬 모습이 에너지를 불어넣어주네요!\"},\n",
    "    {\"input_text\": \"행복,차양 아래\", \"target_text\": \"차양 아래에서 행복한 모습이 여유로움을 더해주네요!\"},\n",
    "    {\"input_text\": \"미소,축제\", \"target_text\": \"축제에서 미소를 지으시니 기쁜 분위기가 전해지네요!\"},\n",
    "    {\"input_text\": \"즐거움,골프장\", \"target_text\": \"골프장에서 즐거워하는 모습이 정말 행복해 보이네요!\"},\n",
    "    {\"input_text\": \"기쁨,관람차\", \"target_text\": \"관람차에서 기쁜 표정이 높은 곳에서의 즐거움을 전해주네요!\"},\n",
    "    {\"input_text\": \"활력,댄스홀\", \"target_text\": \"댄스홀에서 활기차 보이시니 춤이 즐거운 시간을 만들어주네요!\"},\n",
    "    {\"input_text\": \"행복,햇볕 아래\", \"target_text\": \"햇볕 아래에서 행복한 모습이 자연의 아름다움을 느끼게 하네요!\"},\n",
    "    {\"input_text\": \"미소,유적지\", \"target_text\": \"유적지에서 미소를 지으시니 역사와 함께하는 즐거움이 느껴지네요!\"},\n",
    "    {\"input_text\": \"즐거움,음악회\", \"target_text\": \"음악회에서 즐거운 모습이 멋진 공연을 만끽하고 계시네요!\"},\n",
    "    {\"input_text\": \"기쁨,조깅 트랙\", \"target_text\": \"조깅 트랙에서 기쁘게 달리시니 건강과 행복이 가득하네요!\"},\n",
    "    {\"input_text\": \"활력,자연 탐방\", \"target_text\": \"자연 탐방 중 활기찬 모습이 대자연과의 조화를 느끼게 하네요!\"},\n",
    "    {\"input_text\": \"행복,캠핑\", \"target_text\": \"캠핑 중 행복한 표정이 자연 속의 특별한 순간을 만들어주네요!\"},\n",
    "    {\"input_text\": \"미소,커피숍\", \"target_text\": \"커피숍에서 미소를 지으시니 따뜻한 음료와 함께하는 여유가 느껴지네요!\"},\n",
    "    {\"input_text\": \"즐거움,체험 박람회\", \"target_text\": \"체험 박람회에서 즐거운 모습이 새로운 경험을 만끽하고 계시네요!\"},\n",
    "    {\"input_text\": \"기쁨,패션 매장\", \"target_text\": \"패션 매장에서 기쁜 표정이 스타일을 즐기는 모습이네요!\"},\n",
    "    {\"input_text\": \"활력,오픈 마켓\", \"target_text\": \"오픈 마켓에서 활기차 보이시니 다양한 즐거움을 찾고 계시군요!\"},\n",
    "    {\"input_text\": \"행복,정글\", \"target_text\": \"정글에서 행복한 표정을 지으시니 자연의 매력을 만끽하고 계시네요!\"},\n",
    "    {\"input_text\": \"미소,민속촌\", \"target_text\": \"민속촌에서 미소를 지으시니 전통의 매력을 느끼고 계시군요!\"},\n",
    "    {\"input_text\": \"즐거움,아울렛\", \"target_text\": \"아울렛에서 즐거워하는 모습이 쇼핑의 재미를 더해주네요!\"}\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TensorFlow installation not found - running with reduced feature set.\n",
      "\n",
      "NOTE: Using experimental fast data loading logic. To disable, pass\n",
      "    \"--load_fast=false\" and report issues on GitHub. More details:\n",
      "    https://github.com/tensorflow/tensorboard/issues/4784\n",
      "\n",
      "Serving TensorBoard on localhost; to expose to the network, use a proxy or pass --bind_all\n",
      "TensorBoard 2.17.1 at http://localhost:6008/ (Press CTRL+C to quit)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorBoard 서버가 http://127.0.0.1:6006 에서 실행중.\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "import time\n",
    "\n",
    "# TensorBoard 서버 실행 (백그라운드)\n",
    "subprocess.Popen(['tensorboard', '--logdir=../model_follow_up/t5/logs', '--port=6100'])\n",
    "\n",
    "# TensorBoard 서버가 시작되기를 잠시 기다립니다\n",
    "time.sleep(5)\n",
    "\n",
    "# 이후 TensorBoard 서버에 접근할 수 있습니다\n",
    "print(\"TensorBoard 서버가 http://127.0.0.1:6100 에서 실행중.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 훈련시 적정 손실값 : 0.0001 ~ 0.0003\n",
    "https://huggingface.co/docs/transformers/model_doc/t5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tommy/miniconda3/envs/project_3/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "Map: 100%|████████████████████████████████████████████████████████████████████████████| 51/51 [00:00<00:00, 4651.72 examples/s]\n",
      "/home/tommy/miniconda3/envs/project_3/lib/python3.11/site-packages/transformers/training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1300' max='1300' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1300/1300 07:16, Epoch 50/50]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>20.752300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>17.037000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>13.353800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>9.971500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>7.990700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>4.651500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>4.091900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>3.388200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>2.601000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>2.087400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>1.539500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>1.255100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>1.137600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.882800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.932700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.778400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.694200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.681600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.623900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.593800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.490500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.475800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>0.413900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.341400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.330200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.302600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>0.278700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.236100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>290</td>\n",
       "      <td>0.206100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.168700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>310</td>\n",
       "      <td>0.207900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.173200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>330</td>\n",
       "      <td>0.156100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>0.157900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.116500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.143300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>370</td>\n",
       "      <td>0.127700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>0.100500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>390</td>\n",
       "      <td>0.132800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.099800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>410</td>\n",
       "      <td>0.088500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>420</td>\n",
       "      <td>0.089400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>430</td>\n",
       "      <td>0.069700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>440</td>\n",
       "      <td>0.093700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.077600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>460</td>\n",
       "      <td>0.082200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>470</td>\n",
       "      <td>0.084400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>480</td>\n",
       "      <td>0.063500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>490</td>\n",
       "      <td>0.075600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.050200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>510</td>\n",
       "      <td>0.064500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>520</td>\n",
       "      <td>0.063600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>530</td>\n",
       "      <td>0.054600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>540</td>\n",
       "      <td>0.052700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.047300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>560</td>\n",
       "      <td>0.050200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>570</td>\n",
       "      <td>0.049500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>580</td>\n",
       "      <td>0.040800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>590</td>\n",
       "      <td>0.038500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.039000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>610</td>\n",
       "      <td>0.032500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>620</td>\n",
       "      <td>0.034600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>630</td>\n",
       "      <td>0.035400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>640</td>\n",
       "      <td>0.027300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.036500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>660</td>\n",
       "      <td>0.041700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>670</td>\n",
       "      <td>0.030100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>680</td>\n",
       "      <td>0.031700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>690</td>\n",
       "      <td>0.029500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.026400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>710</td>\n",
       "      <td>0.048600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>720</td>\n",
       "      <td>0.028900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>730</td>\n",
       "      <td>0.034400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>740</td>\n",
       "      <td>0.025000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.020900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>760</td>\n",
       "      <td>0.017300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>770</td>\n",
       "      <td>0.024700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>780</td>\n",
       "      <td>0.025100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>790</td>\n",
       "      <td>0.017300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.019400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>810</td>\n",
       "      <td>0.024400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>820</td>\n",
       "      <td>0.022900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>830</td>\n",
       "      <td>0.022000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>840</td>\n",
       "      <td>0.016600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>0.018500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>860</td>\n",
       "      <td>0.013100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>870</td>\n",
       "      <td>0.016200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>880</td>\n",
       "      <td>0.017800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>890</td>\n",
       "      <td>0.017200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.014000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>910</td>\n",
       "      <td>0.015400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>920</td>\n",
       "      <td>0.018100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>930</td>\n",
       "      <td>0.012600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>940</td>\n",
       "      <td>0.016700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>0.017900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>960</td>\n",
       "      <td>0.019300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>970</td>\n",
       "      <td>0.008800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>980</td>\n",
       "      <td>0.008900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>990</td>\n",
       "      <td>0.011800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.018800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1010</td>\n",
       "      <td>0.012500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1020</td>\n",
       "      <td>0.012600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1030</td>\n",
       "      <td>0.015000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1040</td>\n",
       "      <td>0.012500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>0.014300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1060</td>\n",
       "      <td>0.012600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1070</td>\n",
       "      <td>0.009500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1080</td>\n",
       "      <td>0.015600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1090</td>\n",
       "      <td>0.012200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.017300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1110</td>\n",
       "      <td>0.010900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1120</td>\n",
       "      <td>0.012600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1130</td>\n",
       "      <td>0.013300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1140</td>\n",
       "      <td>0.011300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1150</td>\n",
       "      <td>0.009100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1160</td>\n",
       "      <td>0.011100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1170</td>\n",
       "      <td>0.010800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1180</td>\n",
       "      <td>0.010500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1190</td>\n",
       "      <td>0.015400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.009600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1210</td>\n",
       "      <td>0.013200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1220</td>\n",
       "      <td>0.011700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1230</td>\n",
       "      <td>0.008100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1240</td>\n",
       "      <td>0.014700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1250</td>\n",
       "      <td>0.010000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1260</td>\n",
       "      <td>0.006700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1270</td>\n",
       "      <td>0.009900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1280</td>\n",
       "      <td>0.010500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1290</td>\n",
       "      <td>0.011100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.010100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모델이 '../model_follow_up/t5/model'에 저장되었습니다.\n",
      "토크나이저가 '../model_follow_up/t5/model/tokenizer'에 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "from transformers import T5TokenizerFast, T5ForConditionalGeneration, Trainer, TrainingArguments\n",
    "from datasets import Dataset\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "from transformers import TrainingArguments\n",
    "\n",
    "# 모델과 토크나이저 로드\n",
    "tokenizer = T5TokenizerFast.from_pretrained('paust/pko-t5-base')\n",
    "model = T5ForConditionalGeneration.from_pretrained('paust/pko-t5-base')\n",
    "\n",
    "# 데이터셋 생성\n",
    "dataset = Dataset.from_dict({\n",
    "    'input_text': [item['input_text'] for item in data],\n",
    "    'target_text': [item['target_text'] for item in data]\n",
    "})\n",
    "\n",
    "# 데이터 전처리 함수 정의\n",
    "def preprocess_function(examples):\n",
    "    model_inputs = tokenizer(examples['input_text'], max_length=128, truncation=True, padding='max_length')\n",
    "    labels = tokenizer(examples['target_text'], max_length=128, truncation=True, padding='max_length')\n",
    "    model_inputs['labels'] = labels['input_ids']\n",
    "    return model_inputs\n",
    "\n",
    "# 데이터셋 토큰화\n",
    "tokenized_datasets = dataset.map(preprocess_function, batched=True)\n",
    "\n",
    "# 학습인자\n",
    "training_args = TrainingArguments(\n",
    "    per_device_train_batch_size=2,  # 학습 배치 사이즈\n",
    "    per_device_eval_batch_size=2,  # 평가 배치 사이즈\n",
    "    output_dir='../t5',  # 모델 및 체크포인트 저장 디렉토리\n",
    "    num_train_epochs=50,  # 학습 에폭 수\n",
    "    evaluation_strategy=\"no\",  # 평가 전략 설정 (여기서는 평가를 하지 않음)\n",
    "    logging_dir='../t5/logs',  # TensorBoard 로그가 저장될 디렉토리\n",
    "    logging_steps=10,  # TensorBoard 로그를 기록할 간격 \n",
    "    report_to='tensorboard',  # TensorBoard로 로깅\n",
    ")\n",
    "\n",
    "# Trainer 객체 생성\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets\n",
    ")\n",
    "\n",
    "# 모델 학습\n",
    "trainer.train()\n",
    "\n",
    "# 모델과 토크나이저 저장\n",
    "model_save_path = '../model_follow_up/t5/model'\n",
    "tokenizer_save_path = '../model_follow_up/t5/model/tokenizer'\n",
    "\n",
    "model.save_pretrained(model_save_path)\n",
    "tokenizer.save_pretrained(tokenizer_save_path)\n",
    "\n",
    "print(f\"모델이 '{model_save_path}'에 저장되었습니다.\")\n",
    "print(f\"토크나이저가 '{tokenizer_save_path}'에 저장되었습니다.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "테스트 입력: 기쁨, 강아지\n",
      "모델의 예측: 강아지 농장에서 기쁜 표정이 행복을 전해주네요!\n"
     ]
    }
   ],
   "source": [
    "from transformers import T5TokenizerFast, T5ForConditionalGeneration\n",
    "import torch\n",
    "\n",
    "# 저장된 모델과 토크나이저 로드\n",
    "model_save_path = '../model_follow_up/t5/model/'\n",
    "tokenizer_save_path = '../model_follow_up/t5/model/tokenizer/'\n",
    "\n",
    "model = T5ForConditionalGeneration.from_pretrained(model_save_path)\n",
    "tokenizer = T5TokenizerFast.from_pretrained(tokenizer_save_path)\n",
    "\n",
    "# 테스트 입력\n",
    "test_input = \"기쁨, 강아지\"\n",
    "# 입력 토큰화\n",
    "input_ids = tokenizer.encode(test_input, return_tensors='pt')\n",
    "\n",
    "# 모델 예측\n",
    "with torch.no_grad():\n",
    "    outputs = model.generate(input_ids, max_length=50, num_beams=4, early_stopping=True)\n",
    "\n",
    "# 예측 결과 디코딩\n",
    "predicted_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "print(f\"테스트 입력: {test_input}\")\n",
    "print(f\"모델의 예측: {predicted_text}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

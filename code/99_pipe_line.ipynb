{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 리눅스"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory:  /mnt/e/py_data/project_3_git/code\n"
     ]
    }
   ],
   "source": [
    "# 기본 작업 경로 설정\n",
    "import os\n",
    "notebook_path = os.path.abspath(\"project_3_git/code/3_lm_t5.ipynb\")\n",
    "notebook_dir = os.path.dirname(notebook_path)\n",
    "os.chdir(notebook_dir)\n",
    "\n",
    "# 현재 작업 디렉토리 출력\n",
    "print(\"Current working directory: \", os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "\n",
    "test_image = cv2.imread('../data/image_data/test/image/happy/1k53eec98dfe2ec7d6f62c7d7c0ec5dc6d8ee4c6d6e8d60ed0076e290fcceu1ww.jpg')\n",
    "# 훈련된 모델 불러오기\n",
    "\n",
    "model_from_pret = YOLO('models/yolov8x-oiv7.pt')\n",
    "\n",
    "model_from_pret(test_image)[0].show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 1 Car, 1 Clothing, 1 Human face, 2 Mans, 1 Tree, 1 Truck, 3 Wheels, 332.5ms\n",
      "Speed: 5.6ms preprocess, 332.5ms inference, 2.7ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    }
   ],
   "source": [
    "result = model_from_pret(test_image)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from ultralytics.models import YOLOv10\n",
    "\n",
    "# 훈련된 모델 불러오기\n",
    "\n",
    "model_transfered = YOLOv10('../yolov10/runs/detect/train/weights/last.pt')\n",
    "\n",
    "model_transfered(test_image)[0].show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 288x512 1 anger, 2 happys, 71.9ms\n",
      "Speed: 2.1ms preprocess, 71.9ms inference, 5.4ms postprocess per image at shape (1, 3, 288, 512)\n"
     ]
    }
   ],
   "source": [
    "result = model_transfered(test_image)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "detections = result.boxes\n",
    "emotion_mapping = {\n",
    "    0 : '분노',\n",
    "    1 : '슬픔',\n",
    "    2 : '공포',\n",
    "    3 : '기쁨',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_intput = [emotion_mapping[int(i)] for i in detections.cls]\n",
    "\n",
    "text_intput_text = ''\n",
    "for i in text_intput:\n",
    "    text_intput_text +=i + ','\n",
    "\n",
    "text_intput_text = text_intput_text[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'기쁨,기쁨,분노'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_intput_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "테스트 입력: 기쁨,기쁨,분노\n",
      "모델의 예측: 기쁨의 표정을 보니 멋진 자연을 만끽하고 계시네요!\n"
     ]
    }
   ],
   "source": [
    "from transformers import T5TokenizerFast, T5ForConditionalGeneration\n",
    "import torch\n",
    "\n",
    "# 저장된 모델과 토크나이저 로드\n",
    "model_save_path = '../model_follow_up/t5/model/'\n",
    "tokenizer_save_path = '../model_follow_up/t5/model/tokenizer/'\n",
    "\n",
    "model = T5ForConditionalGeneration.from_pretrained(model_save_path)\n",
    "tokenizer = T5TokenizerFast.from_pretrained(tokenizer_save_path)\n",
    "\n",
    "# 테스트 입력\n",
    "test_input = text_intput_text\n",
    "# 입력 토큰화\n",
    "input_ids = tokenizer.encode(test_input, return_tensors='pt')\n",
    "\n",
    "# 모델 예측\n",
    "with torch.no_grad():\n",
    "    outputs = model.generate(input_ids, max_length=50, num_beams=4, early_stopping=True)\n",
    "\n",
    "# 예측 결과 디코딩\n",
    "predicted_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "print(f\"테스트 입력: {test_input}\")\n",
    "print(f\"모델의 예측: {predicted_text}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

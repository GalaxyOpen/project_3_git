{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory:  /mnt/e/py_data/project_3_git\n"
     ]
    }
   ],
   "source": [
    "# 기본 작업 경로 설정\n",
    "\n",
    "import os\n",
    "notebook_path = os.path.abspath(\"../readme.md\")\n",
    "notebook_dir = os.path.dirname(notebook_path)\n",
    "os.chdir(notebook_dir)\n",
    "\n",
    "# 현재 작업 디렉토리 출력\n",
    "print(\"Current working directory: \", os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### https://github.com/facebookresearch/detectron2/blob/main/MODEL_ZOO.md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectron2.data import MetadataCatalog, DatasetCatalog\n",
    "from detectron2.data.datasets import register_coco_instances\n",
    "\n",
    "# 데이터셋 경로와 형식 설정\n",
    "register_coco_instances(\"face_data_set\", {}, \"data/ssd_rcnn_face/annotations.json\", \"data/yolo_data/train/\")\n",
    "register_coco_instances(\"face_data_set_valid\", {}, \"data/ssd_rcnn_face/annotations_val.json\", \"data/yolo_data/val/\")\n",
    "\n",
    "# 메타데이터를 확인.\n",
    "metadata = MetadataCatalog.get(\"face_data_set\")\n",
    "dataset_dicts = DatasetCatalog.get(\"face_data_set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[09/06 15:25:53 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc_relu1): ReLU()\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (fc_relu2): ReLU()\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=5, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=16, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\u001b[32m[09/06 15:25:54 d2.data.datasets.coco]: \u001b[0mLoaded 5992 images in COCO format from data/ssd_rcnn_face/annotations.json\n",
      "\u001b[32m[09/06 15:25:54 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 5992 images left.\n",
      "\u001b[32m[09/06 15:25:54 d2.data.build]: \u001b[0mDistribution of instances among all 4 categories:\n",
      "\u001b[36m|  category  | #instances   |  category  | #instances   |  category  | #instances   |\n",
      "|:----------:|:-------------|:----------:|:-------------|:----------:|:-------------|\n",
      "|   angry    | 1500         |    sad     | 1499         | surprised  | 1499         |\n",
      "|   happy    | 1494         |            |              |            |              |\n",
      "|   total    | 5992         |            |              |            |              |\u001b[0m\n",
      "\u001b[32m[09/06 15:25:54 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [RandomCrop(crop_type='relative_range', crop_size=[0.8, 0.8]), ResizeShortestEdge(short_edge_length=(512, 512), max_size=512, sample_style='choice'), RandomFlip()]\n",
      "\u001b[32m[09/06 15:25:54 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[09/06 15:25:54 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[09/06 15:25:54 d2.data.common]: \u001b[0mSerializing 5992 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[09/06 15:25:54 d2.data.common]: \u001b[0mSerialized dataset takes 1.79 MiB\n",
      "\u001b[32m[09/06 15:25:54 d2.data.build]: \u001b[0mMaking batched data loader with batch_size=16\n",
      "\u001b[32m[09/06 15:25:54 d2.checkpoint.detection_checkpoint]: \u001b[0m[DetectionCheckpointer] Loading from detectron2://COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x/137849600/model_final_f10217.pkl ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (5, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (5,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (16, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (16,) in the model! You might want to double check if this is expected.\n",
      "Some model parameters or buffers are not found in the checkpoint:\n",
      "\u001b[34mroi_heads.box_predictor.bbox_pred.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.box_predictor.cls_score.{bias, weight}\u001b[0m\n",
      "The checkpoint state_dict contains keys that are not used by the model:\n",
      "  \u001b[35mroi_heads.mask_head.mask_fcn1.{bias, weight}\u001b[0m\n",
      "  \u001b[35mroi_heads.mask_head.mask_fcn2.{bias, weight}\u001b[0m\n",
      "  \u001b[35mroi_heads.mask_head.mask_fcn3.{bias, weight}\u001b[0m\n",
      "  \u001b[35mroi_heads.mask_head.mask_fcn4.{bias, weight}\u001b[0m\n",
      "  \u001b[35mroi_heads.mask_head.deconv.{bias, weight}\u001b[0m\n",
      "  \u001b[35mroi_heads.mask_head.predictor.{bias, weight}\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[09/06 15:25:54 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tommy/miniconda3/envs/p3/lib/python3.11/site-packages/torch/functional.py:513: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3609.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[09/06 15:26:45 d2.utils.events]: \u001b[0m eta: 0:39:36  iter: 19  total_loss: 2.064  loss_cls: 1.827  loss_box_reg: 0.1404  loss_rpn_cls: 0.08922  loss_rpn_loc: 0.009855    time: 2.4953  last_time: 2.2672  data_time: 1.5805  last_data_time: 1.4263   lr: 1.9962e-05  max_mem: 3888M\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-06 15:26:45.984192: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-09-06 15:26:46.000402: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-09-06 15:26:46.006009: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-09-06 15:26:46.019024: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-09-06 15:26:47.181203: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[09/06 15:27:35 d2.utils.events]: \u001b[0m eta: 0:37:49  iter: 39  total_loss: 1.594  loss_cls: 1.298  loss_box_reg: 0.1646  loss_rpn_cls: 0.08414  loss_rpn_loc: 0.009699    time: 2.4312  last_time: 2.6242  data_time: 1.4421  last_data_time: 1.7176   lr: 3.9922e-05  max_mem: 3888M\n",
      "\u001b[32m[09/06 15:28:24 d2.utils.events]: \u001b[0m eta: 0:37:02  iter: 59  total_loss: 0.95  loss_cls: 0.6248  loss_box_reg: 0.2442  loss_rpn_cls: 0.06401  loss_rpn_loc: 0.01028    time: 2.4315  last_time: 1.9801  data_time: 1.5015  last_data_time: 1.1361   lr: 5.9882e-05  max_mem: 3888M\n",
      "\u001b[32m[09/06 15:29:19 d2.utils.events]: \u001b[0m eta: 0:36:54  iter: 79  total_loss: 0.8377  loss_cls: 0.4112  loss_box_reg: 0.379  loss_rpn_cls: 0.03944  loss_rpn_loc: 0.009045    time: 2.5121  last_time: 3.1003  data_time: 1.7906  last_data_time: 2.1011   lr: 7.9842e-05  max_mem: 3888M\n",
      "\u001b[32m[09/06 15:30:11 d2.utils.events]: \u001b[0m eta: 0:36:18  iter: 99  total_loss: 0.7889  loss_cls: 0.3553  loss_box_reg: 0.4028  loss_rpn_cls: 0.02307  loss_rpn_loc: 0.009188    time: 2.5314  last_time: 2.6414  data_time: 1.6278  last_data_time: 1.6545   lr: 9.9802e-05  max_mem: 3888M\n",
      "\u001b[32m[09/06 15:31:03 d2.utils.events]: \u001b[0m eta: 0:35:44  iter: 119  total_loss: 0.7663  loss_cls: 0.3248  loss_box_reg: 0.4244  loss_rpn_cls: 0.01596  loss_rpn_loc: 0.007649    time: 2.5454  last_time: 2.5951  data_time: 1.6411  last_data_time: 1.5585   lr: 0.00011976  max_mem: 3888M\n",
      "\u001b[32m[09/06 15:31:53 d2.utils.events]: \u001b[0m eta: 0:35:00  iter: 139  total_loss: 0.772  loss_cls: 0.3027  loss_box_reg: 0.4449  loss_rpn_cls: 0.01486  loss_rpn_loc: 0.00833    time: 2.5384  last_time: 2.5263  data_time: 1.5119  last_data_time: 1.6191   lr: 0.00013972  max_mem: 3888M\n",
      "\u001b[32m[09/06 15:32:42 d2.utils.events]: \u001b[0m eta: 0:34:23  iter: 159  total_loss: 0.7459  loss_cls: 0.2847  loss_box_reg: 0.4412  loss_rpn_cls: 0.01234  loss_rpn_loc: 0.007562    time: 2.5275  last_time: 2.7396  data_time: 1.4843  last_data_time: 1.6895   lr: 0.00015968  max_mem: 3888M\n",
      "\u001b[32m[09/06 15:33:33 d2.utils.events]: \u001b[0m eta: 0:33:46  iter: 179  total_loss: 0.7448  loss_cls: 0.2769  loss_box_reg: 0.4484  loss_rpn_cls: 0.01165  loss_rpn_loc: 0.007054    time: 2.5291  last_time: 2.7795  data_time: 1.5598  last_data_time: 1.8454   lr: 0.00017964  max_mem: 3888M\n",
      "\u001b[32m[09/06 15:34:24 d2.utils.events]: \u001b[0m eta: 0:32:57  iter: 199  total_loss: 0.7512  loss_cls: 0.2725  loss_box_reg: 0.4671  loss_rpn_cls: 0.007114  loss_rpn_loc: 0.007054    time: 2.5305  last_time: 2.4726  data_time: 1.5365  last_data_time: 1.4970   lr: 0.0001996  max_mem: 4118M\n",
      "\u001b[32m[09/06 15:35:13 d2.utils.events]: \u001b[0m eta: 0:32:09  iter: 219  total_loss: 0.7835  loss_cls: 0.2791  loss_box_reg: 0.4925  loss_rpn_cls: 0.006572  loss_rpn_loc: 0.006125    time: 2.5252  last_time: 2.2842  data_time: 1.5172  last_data_time: 1.4480   lr: 0.00021956  max_mem: 4118M\n",
      "\u001b[32m[09/06 15:36:06 d2.utils.events]: \u001b[0m eta: 0:31:20  iter: 239  total_loss: 0.7706  loss_cls: 0.2725  loss_box_reg: 0.4902  loss_rpn_cls: 0.007006  loss_rpn_loc: 0.006207    time: 2.5354  last_time: 2.0453  data_time: 1.6769  last_data_time: 1.1694   lr: 0.00023952  max_mem: 4118M\n",
      "\u001b[32m[09/06 15:36:56 d2.utils.events]: \u001b[0m eta: 0:30:26  iter: 259  total_loss: 0.8122  loss_cls: 0.2805  loss_box_reg: 0.5116  loss_rpn_cls: 0.006782  loss_rpn_loc: 0.005938    time: 2.5319  last_time: 2.4638  data_time: 1.5594  last_data_time: 1.5461   lr: 0.00025948  max_mem: 4118M\n",
      "\u001b[32m[09/06 15:37:46 d2.utils.events]: \u001b[0m eta: 0:29:35  iter: 279  total_loss: 0.791  loss_cls: 0.2827  loss_box_reg: 0.4962  loss_rpn_cls: 0.00462  loss_rpn_loc: 0.005709    time: 2.5298  last_time: 3.5040  data_time: 1.5543  last_data_time: 2.4818   lr: 0.00027944  max_mem: 4118M\n",
      "\u001b[32m[09/06 15:38:36 d2.utils.events]: \u001b[0m eta: 0:28:40  iter: 299  total_loss: 0.8583  loss_cls: 0.3063  loss_box_reg: 0.5415  loss_rpn_cls: 0.004488  loss_rpn_loc: 0.005432    time: 2.5280  last_time: 2.6418  data_time: 1.5520  last_data_time: 1.7260   lr: 0.0002994  max_mem: 4118M\n",
      "\u001b[32m[09/06 15:39:24 d2.utils.events]: \u001b[0m eta: 0:27:41  iter: 319  total_loss: 0.8169  loss_cls: 0.3115  loss_box_reg: 0.4935  loss_rpn_cls: 0.003706  loss_rpn_loc: 0.005039    time: 2.5178  last_time: 2.3044  data_time: 1.4521  last_data_time: 1.4496   lr: 0.00031936  max_mem: 4118M\n",
      "\u001b[32m[09/06 15:40:13 d2.utils.events]: \u001b[0m eta: 0:26:54  iter: 339  total_loss: 0.777  loss_cls: 0.3439  loss_box_reg: 0.4302  loss_rpn_cls: 0.003824  loss_rpn_loc: 0.005306    time: 2.5160  last_time: 2.4239  data_time: 1.4966  last_data_time: 1.4586   lr: 0.00033932  max_mem: 4118M\n",
      "\u001b[32m[09/06 15:41:06 d2.utils.events]: \u001b[0m eta: 0:26:06  iter: 359  total_loss: 0.6715  loss_cls: 0.3501  loss_box_reg: 0.3142  loss_rpn_cls: 0.005106  loss_rpn_loc: 0.005634    time: 2.5226  last_time: 2.3279  data_time: 1.6221  last_data_time: 1.3966   lr: 0.00035928  max_mem: 4118M\n",
      "\u001b[32m[09/06 15:42:00 d2.utils.events]: \u001b[0m eta: 0:25:20  iter: 379  total_loss: 0.6214  loss_cls: 0.3434  loss_box_reg: 0.2693  loss_rpn_cls: 0.004946  loss_rpn_loc: 0.004535    time: 2.5318  last_time: 2.5929  data_time: 1.7115  last_data_time: 1.6222   lr: 0.00037924  max_mem: 4118M\n",
      "\u001b[32m[09/06 15:42:47 d2.utils.events]: \u001b[0m eta: 0:24:27  iter: 399  total_loss: 0.5896  loss_cls: 0.3314  loss_box_reg: 0.2462  loss_rpn_cls: 0.002582  loss_rpn_loc: 0.004043    time: 2.5234  last_time: 2.0761  data_time: 1.4327  last_data_time: 1.2500   lr: 0.0003992  max_mem: 4118M\n",
      "\u001b[32m[09/06 15:43:37 d2.utils.events]: \u001b[0m eta: 0:23:37  iter: 419  total_loss: 0.5117  loss_cls: 0.3056  loss_box_reg: 0.2041  loss_rpn_cls: 0.002936  loss_rpn_loc: 0.004129    time: 2.5216  last_time: 2.4644  data_time: 1.5438  last_data_time: 1.5668   lr: 0.00041916  max_mem: 4118M\n",
      "\u001b[32m[09/06 15:44:27 d2.utils.events]: \u001b[0m eta: 0:22:49  iter: 439  total_loss: 0.51  loss_cls: 0.3184  loss_box_reg: 0.1905  loss_rpn_cls: 0.002188  loss_rpn_loc: 0.003464    time: 2.5195  last_time: 2.5536  data_time: 1.5280  last_data_time: 1.6403   lr: 0.00043912  max_mem: 4118M\n",
      "\u001b[32m[09/06 15:45:12 d2.utils.events]: \u001b[0m eta: 0:21:55  iter: 459  total_loss: 0.5174  loss_cls: 0.3133  loss_box_reg: 0.1955  loss_rpn_cls: 0.001569  loss_rpn_loc: 0.003214    time: 2.5094  last_time: 2.0828  data_time: 1.3822  last_data_time: 1.1595   lr: 0.00045908  max_mem: 4118M\n",
      "\u001b[32m[09/06 15:46:03 d2.utils.events]: \u001b[0m eta: 0:21:06  iter: 479  total_loss: 0.4836  loss_cls: 0.2948  loss_box_reg: 0.175  loss_rpn_cls: 0.001785  loss_rpn_loc: 0.003039    time: 2.5099  last_time: 3.2104  data_time: 1.5825  last_data_time: 2.2257   lr: 0.00047904  max_mem: 4118M\n",
      "\u001b[32m[09/06 15:46:53 d2.utils.events]: \u001b[0m eta: 0:20:14  iter: 499  total_loss: 0.4899  loss_cls: 0.3042  loss_box_reg: 0.1828  loss_rpn_cls: 0.001136  loss_rpn_loc: 0.003263    time: 2.5054  last_time: 2.3915  data_time: 1.4848  last_data_time: 1.4302   lr: 0.000499  max_mem: 4118M\n",
      "\u001b[32m[09/06 15:47:45 d2.utils.events]: \u001b[0m eta: 0:19:28  iter: 519  total_loss: 0.4913  loss_cls: 0.308  loss_box_reg: 0.1756  loss_rpn_cls: 0.0009043  loss_rpn_loc: 0.002913    time: 2.5095  last_time: 2.2053  data_time: 1.6323  last_data_time: 1.2872   lr: 0.00047017  max_mem: 4118M\n",
      "\u001b[32m[09/06 15:48:36 d2.utils.events]: \u001b[0m eta: 0:18:40  iter: 539  total_loss: 0.4823  loss_cls: 0.3083  loss_box_reg: 0.1721  loss_rpn_cls: 0.001031  loss_rpn_loc: 0.002692    time: 2.5099  last_time: 2.2791  data_time: 1.5643  last_data_time: 1.3133   lr: 0.00043889  max_mem: 4118M\n",
      "\u001b[32m[09/06 15:49:25 d2.utils.events]: \u001b[0m eta: 0:17:52  iter: 559  total_loss: 0.4925  loss_cls: 0.3191  loss_box_reg: 0.1758  loss_rpn_cls: 0.001065  loss_rpn_loc: 0.002533    time: 2.5084  last_time: 2.0842  data_time: 1.4788  last_data_time: 1.1586   lr: 0.00040785  max_mem: 4118M\n",
      "\u001b[32m[09/06 15:50:23 d2.utils.events]: \u001b[0m eta: 0:17:06  iter: 579  total_loss: 0.4882  loss_cls: 0.3155  loss_box_reg: 0.1694  loss_rpn_cls: 0.001194  loss_rpn_loc: 0.002563    time: 2.5215  last_time: 2.8268  data_time: 1.8270  last_data_time: 1.7499   lr: 0.00037718  max_mem: 4118M\n",
      "\u001b[32m[09/06 15:51:24 d2.utils.events]: \u001b[0m eta: 0:16:20  iter: 599  total_loss: 0.4831  loss_cls: 0.3221  loss_box_reg: 0.1667  loss_rpn_cls: 0.001364  loss_rpn_loc: 0.002455    time: 2.5385  last_time: 2.6401  data_time: 1.9627  last_data_time: 1.6820   lr: 0.00034699  max_mem: 4118M\n",
      "\u001b[32m[09/06 15:52:23 d2.utils.events]: \u001b[0m eta: 0:15:36  iter: 619  total_loss: 0.4941  loss_cls: 0.3123  loss_box_reg: 0.1756  loss_rpn_cls: 0.000835  loss_rpn_loc: 0.002399    time: 2.5524  last_time: 4.3586  data_time: 1.8969  last_data_time: 3.1807   lr: 0.0003174  max_mem: 4118M\n",
      "\u001b[32m[09/06 15:53:19 d2.utils.events]: \u001b[0m eta: 0:14:48  iter: 639  total_loss: 0.4853  loss_cls: 0.3127  loss_box_reg: 0.1703  loss_rpn_cls: 0.0004774  loss_rpn_loc: 0.002366    time: 2.5599  last_time: 3.3728  data_time: 1.7469  last_data_time: 2.1904   lr: 0.00028853  max_mem: 4118M\n",
      "\u001b[32m[09/06 15:54:19 d2.utils.events]: \u001b[0m eta: 0:14:02  iter: 659  total_loss: 0.4814  loss_cls: 0.3127  loss_box_reg: 0.166  loss_rpn_cls: 0.0005603  loss_rpn_loc: 0.002263    time: 2.5731  last_time: 2.6413  data_time: 1.8661  last_data_time: 1.5840   lr: 0.0002605  max_mem: 4118M\n",
      "\u001b[32m[09/06 15:55:15 d2.utils.events]: \u001b[0m eta: 0:13:15  iter: 679  total_loss: 0.4759  loss_cls: 0.31  loss_box_reg: 0.157  loss_rpn_cls: 0.0002732  loss_rpn_loc: 0.002443    time: 2.5804  last_time: 2.5400  data_time: 1.7360  last_data_time: 1.4828   lr: 0.00023341  max_mem: 4118M\n",
      "\u001b[32m[09/06 15:56:15 d2.utils.events]: \u001b[0m eta: 0:12:28  iter: 699  total_loss: 0.4675  loss_cls: 0.3095  loss_box_reg: 0.1526  loss_rpn_cls: 0.0003603  loss_rpn_loc: 0.002499    time: 2.5920  last_time: 3.0530  data_time: 1.8217  last_data_time: 1.8089   lr: 0.00020738  max_mem: 4119M\n",
      "\u001b[32m[09/06 15:57:22 d2.utils.events]: \u001b[0m eta: 0:11:40  iter: 719  total_loss: 0.4769  loss_cls: 0.3124  loss_box_reg: 0.1598  loss_rpn_cls: 0.0002284  loss_rpn_loc: 0.002209    time: 2.6137  last_time: 4.0572  data_time: 2.1887  last_data_time: 2.8278   lr: 0.0001825  max_mem: 4119M\n",
      "\u001b[32m[09/06 15:58:34 d2.utils.events]: \u001b[0m eta: 0:10:53  iter: 739  total_loss: 0.4587  loss_cls: 0.3115  loss_box_reg: 0.1475  loss_rpn_cls: 0.0008393  loss_rpn_loc: 0.002372    time: 2.6399  last_time: 2.6888  data_time: 2.3254  last_data_time: 1.6683   lr: 0.00015887  max_mem: 4119M\n",
      "\u001b[32m[09/06 15:59:36 d2.utils.events]: \u001b[0m eta: 0:10:05  iter: 759  total_loss: 0.4587  loss_cls: 0.3072  loss_box_reg: 0.1527  loss_rpn_cls: 0.0007782  loss_rpn_loc: 0.002391    time: 2.6520  last_time: 3.1376  data_time: 1.9308  last_data_time: 1.9699   lr: 0.00013659  max_mem: 4119M\n"
     ]
    }
   ],
   "source": [
    "from detectron2.engine import DefaultTrainer, DefaultPredictor\n",
    "from detectron2.data import MetadataCatalog, build_detection_test_loader\n",
    "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.utils.logger import setup_logger\n",
    "from detectron2.config import CfgNode as CN\n",
    "import json\n",
    "import os\n",
    "\n",
    "class CustomTrainer(DefaultTrainer):\n",
    "    @classmethod\n",
    "    def build_evaluator(cls, cfg, dataset_name, output_dir=None):\n",
    "        return COCOEvaluator(dataset_name, cfg, True, output_dir)\n",
    "    \n",
    "    def train(self):\n",
    "        self.results = {\"train\": [], \"test\": []}\n",
    "        super().train()\n",
    "        \n",
    "        # Add evaluation after each epoch\n",
    "        for epoch in range(0, self.cfg.SOLVER.MAX_ITER + 1, self.cfg.TEST.EVAL_PERIOD):\n",
    "            self.do_test(epoch)\n",
    "            if epoch % self.cfg.SOLVER.CHECKPOINT_PERIOD == 0:\n",
    "                self.checkpointer.save(f\"model_{epoch}\")\n",
    "\n",
    "    def do_test(self, epoch):\n",
    "        try:\n",
    "            # Perform evaluation\n",
    "            evaluator = self.build_evaluator(self.cfg, self.cfg.DATASETS.TEST[0], output_dir=self.cfg.OUTPUT_DIR)\n",
    "            val_loader = build_detection_test_loader(self.cfg, self.cfg.DATASETS.TEST[0])\n",
    "            results = inference_on_dataset(self.model, val_loader, evaluator)\n",
    "            self.results[\"test\"].append({\"epoch\": epoch, \"results\": results})\n",
    "            print(\"Evaluation results:\", results)\n",
    "    \n",
    "            # Save the results as JSON\n",
    "            self.save_results_as_json()\n",
    "        except Exception as e:\n",
    "            print(f\"Error during evaluation at epoch {epoch}: {e}\")\n",
    "    \n",
    "    def save_results_as_json(self):\n",
    "        try:\n",
    "            output_file_path = os.path.join(self.cfg.OUTPUT_DIR, \"train_test_results.json\")\n",
    "            print(f\"Saving results to: {output_file_path}\")\n",
    "            with open(output_file_path, 'w') as f:\n",
    "                json.dump(self.results, f, indent=2)\n",
    "        except Exception as e:\n",
    "            print(f\"Error saving results as JSON: {e}\")\n",
    "\n",
    "\n",
    "# Set up configuration\n",
    "cfg = get_cfg()\n",
    "cfg.merge_from_file(\"detectron2/configs/COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml\")\n",
    "cfg.DATASETS.TRAIN = (\"face_data_set\",)\n",
    "cfg.DATASETS.TEST = (\"face_data_set_valid\",)\n",
    "cfg.DATALOADER.NUM_WORKERS = 2\n",
    "cfg.MODEL.WEIGHTS = \"detectron2://COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x/137849600/model_final_f10217.pkl\"\n",
    "cfg.SOLVER.IMS_PER_BATCH = 16\n",
    "cfg.SOLVER.BASE_LR = 0.001\n",
    "cfg.SOLVER.MAX_ITER = 1000\n",
    "cfg.INPUT.MIN_SIZE_TRAIN = 512\n",
    "cfg.INPUT.MAX_SIZE_TRAIN = 512\n",
    "cfg.INPUT.MIN_SIZE_TEST = 512\n",
    "cfg.INPUT.MAX_SIZE_TEST = 512\n",
    "cfg.INPUT.RANDOM_FLIP = \"horizontal\"\n",
    "cfg.INPUT.RANDOM_ROTATION = 30\n",
    "cfg.INPUT.CROP = CN({\"ENABLED\": True, \"TYPE\": \"relative_range\", \"SIZE\": [0.8, 0.8]})\n",
    "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 128\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 4\n",
    "cfg.OUTPUT_DIR = \"./models/faster_rcnn_R_50_FPN_3x\"\n",
    "cfg.TEST.EVAL_PERIOD = 1000\n",
    "cfg.SOLVER.CHECKPOINT_PERIOD = 500\n",
    "cfg.SOLVER.LR_SCHEDULER_NAME = \"WarmupCosineLR\"\n",
    "cfg.SOLVER.WARMUP_ITERS = 500\n",
    "\n",
    "setup_logger()\n",
    "trainer = CustomTrainer(cfg)\n",
    "trainer.resume_or_load(resume=False)\n",
    "trainer.train()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

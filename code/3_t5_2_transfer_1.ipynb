{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory:  /mnt/e/py_data/project_3_git\n"
     ]
    }
   ],
   "source": [
    "# 기본 작업 경로 설정\n",
    "import os\n",
    "notebook_path = os.path.abspath(\"project_3_git/readme.md\")\n",
    "notebook_dir = os.path.dirname(notebook_path)\n",
    "os.chdir(notebook_dir)\n",
    "\n",
    "# 현재 작업 디렉토리 출력\n",
    "print(\"Current working directory: \", os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['공포, 헤드폰', '아찔한 분위기네요! 🎧 어떤 음악 듣고 계신가요? 궁금해요! 😊']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 텍스트 데이터 가져오기\n",
    "import json\n",
    "\n",
    "# JSON 파일에서 딕셔너리 읽기\n",
    "with open('data/text_data/output_text.json', 'r') as file:\n",
    "    data_loaded = json.load(file)\n",
    "\n",
    "data_loaded['0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = [data_loaded[i][0] for i in data_loaded][:5000]\n",
    "train_y = [data_loaded[i][1] for i in data_loaded][:5000]\n",
    "test_x = [data_loaded[i][0] for i in data_loaded][5000:]\n",
    "test_y = [data_loaded[i][1] for i in data_loaded][5000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Popen: returncode: None args: ['tensorboard', '--logdir=t5/transfer_1', '--...>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-03 10:37:22.817042: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-09-03 10:37:22.834881: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-09-03 10:37:22.839826: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-09-03 10:37:22.852272: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-09-03 10:37:23.630554: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1725327444.871511    8289 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:07:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1725327445.186911    8289 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:07:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1725327445.187034    8289 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:07:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "\n",
      "NOTE: Using experimental fast data loading logic. To disable, pass\n",
      "    \"--load_fast=false\" and report issues on GitHub. More details:\n",
      "    https://github.com/tensorflow/tensorboard/issues/4784\n",
      "\n",
      "Serving TensorBoard on localhost; to expose to the network, use a proxy or pass --bind_all\n",
      "TensorBoard 2.17.1 at http://localhost:4561/ (Press CTRL+C to quit)\n"
     ]
    }
   ],
   "source": [
    "from transformers import T5Config ,T5TokenizerFast, T5ForConditionalGeneration, Trainer, TrainingArguments, EarlyStoppingCallback\n",
    "from datasets import Dataset\n",
    "from tqdm import tqdm\n",
    "import subprocess\n",
    "\n",
    "\n",
    "\n",
    "name_folder = 'transfer_1'\n",
    "server_port = '4561'\n",
    "batch_size = 16\n",
    "train_epochs = 60\n",
    "\n",
    "\n",
    "\n",
    "# TensorBoard 서버 실행 (백그라운드)\n",
    "subprocess.Popen(['tensorboard', f'--logdir=t5/{name_folder}', f'--port={server_port}'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 인자 조정\n",
    "- 드롭 아웃 비율 조정 기본값 : 0.1 -> 0.2\n",
    "- 학습 률 조정\n",
    "- 웜 업 스텝 설정\n",
    "- 배치 사이즈 : 코랩에서 돌릴때 시도\n",
    "- l2 정규화 (weight decay)\n",
    "- gredient clipping 그라디언트 조정으로 학습 안정화 시키기\n",
    "- 레이블 스무딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|███████████████████████████████████████████████| 5000/5000 [00:00<00:00, 8983.95 examples/s]\n",
      "Map: 100%|████████████████████████████████████████████████| 994/994 [00:00<00:00, 12174.41 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2570' max='18780' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 2570/18780 42:23 < 4:27:36, 1.01 it/s, Epoch 8.21/60]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.400500</td>\n",
       "      <td>0.327589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.254200</td>\n",
       "      <td>0.210854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.217600</td>\n",
       "      <td>0.193800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.197800</td>\n",
       "      <td>0.187665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.187800</td>\n",
       "      <td>0.182515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.181000</td>\n",
       "      <td>0.180372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.173600</td>\n",
       "      <td>0.179033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.168700</td>\n",
       "      <td>0.178390</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 모델과 토크나이저 로드\n",
    "tokenizer = T5TokenizerFast.from_pretrained('paust/pko-t5-base')\n",
    "config = T5Config.from_pretrained('paust/pko-t5-base')\n",
    "model = T5ForConditionalGeneration.from_pretrained('paust/pko-t5-base')\n",
    "\n",
    "config.dropout_rate = 0.2  # 드롭아웃 비율을 20%로 설정 (기본값은 0.1)\n",
    "\n",
    "\n",
    "# 데이터 전처리 함수 정의\n",
    "def preprocess_function(examples):\n",
    "    model_inputs = tokenizer(examples['input_text'], max_length=128, truncation=True, padding='max_length')\n",
    "    labels = tokenizer(examples['target_text'], max_length=128, truncation=True, padding='max_length')\n",
    "    model_inputs['labels'] = labels['input_ids']\n",
    "    return model_inputs\n",
    "\n",
    "# 데이터셋 생성 및 토큰화\n",
    "dataset_train = Dataset.from_dict({'input_text': train_x,'target_text': train_y})\n",
    "dataset_test = Dataset.from_dict({'input_text': test_x,'target_text': test_y})\n",
    "\n",
    "tokenized_train_datasets = dataset_train.map(preprocess_function, batched=True)\n",
    "tokenized_test_datasets = dataset_test.map(preprocess_function, batched=True)\n",
    "\n",
    "# 학습인자\n",
    "training_args = TrainingArguments(\n",
    "    per_device_train_batch_size=batch_size, # 학습 배치 사이즈\n",
    "    per_device_eval_batch_size=batch_size,  # 평가 배치 사이즈\n",
    "    output_dir=f't5/{name_folder}',         # 모델 및 체크포인트 저장 디렉토리\n",
    "    num_train_epochs=train_epochs,          # 학습 에폭 수\n",
    "    logging_dir=f't5/{name_folder}/logs',   # TensorBoard 로그가 저장될 디렉토리\n",
    "    logging_steps=100,                      # TensorBoard 로그를 기록할 간격 \n",
    "    report_to='tensorboard',                # TensorBoard로 로깅\n",
    "    load_best_model_at_end = True,\n",
    "    eval_strategy='epoch',\n",
    "    save_strategy='epoch',                  # 에포크 마다 모델 저장\n",
    "    # resume_from_checkpoint=True           # 이어 학습\n",
    "\n",
    "    # 추가 인자\n",
    "    learning_rate=5e-5,                     # 기본값에서 시작\n",
    "    lr_scheduler_type=\"linear\",             # 스케줄러\n",
    "    warmup_steps=500,                       # 500 스텝 동안 학습률을 점진적으로 증가\n",
    "    weight_decay=0.01,                      # l2 정규화 기법 중 하나\n",
    "    max_grad_norm=1.0,                      # 그라디언트 클리핑\n",
    ")\n",
    "\n",
    "# Trainer 객체 생성\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train_datasets,\n",
    "    eval_dataset=tokenized_test_datasets,\n",
    "    callbacks = [EarlyStoppingCallback(early_stopping_patience=10)]\n",
    ")\n",
    "\n",
    "# 모델 학습\n",
    "trainer.train() # 이어 학습시 (resume_from_checkpoint=checkpoint_dir)\n",
    "\n",
    "# 모델과 토크나이저 저장\n",
    "model_save_path = f't5/{name_folder}/model'\n",
    "tokenizer_save_path = f't5/{name_folder}/model/tokenizer'\n",
    "\n",
    "model.save_pretrained(model_save_path)\n",
    "tokenizer.save_pretrained(tokenizer_save_path)\n",
    "\n",
    "print(f\"모델이 '{model_save_path}'에 저장되었습니다.\")\n",
    "print(f\"토크나이저가 '{tokenizer_save_path}'에 저장되었습니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 결과 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = T5ForConditionalGeneration.from_pretrained('t5/transfer_0/model/')\n",
    "tokenizer = T5TokenizerFast.from_pretrained('t5/transfer_0/model/tokenizer/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "테스트 입력: 야!!!!\n",
      "모델의 예측: 정말 화가 나신 것 같아요! 😠 어떤 일이 있으셨나요?\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# 테스트 입력\n",
    "test_input = \"야!!!!\"\n",
    "\n",
    "# 입력 토큰화\n",
    "input_ids = tokenizer.encode(test_input, return_tensors='pt')\n",
    "\n",
    "# GPU가 사용 가능한지 확인하고, 사용 가능한 경우 GPU로 이동\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# 모델과 토크나이저를 GPU로 이동\n",
    "model.to(device)\n",
    "\n",
    "# 입력 데이터도 GPU로 이동\n",
    "input_ids = input_ids.to(device)\n",
    "\n",
    "# 예측을 GPU에서 수행\n",
    "with torch.no_grad():\n",
    "    outputs = model.generate(input_ids, max_length=50, num_beams=4, early_stopping=True)\n",
    "\n",
    "# 예측 결과 디코딩\n",
    "predicted_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "print(f\"테스트 입력: {test_input}\")\n",
    "print(f\"모델의 예측: {predicted_text}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

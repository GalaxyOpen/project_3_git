{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory:  /mnt/e/py_data/project_3_git\n"
     ]
    }
   ],
   "source": [
    "# 기본 작업 경로 설정\n",
    "\n",
    "import os\n",
    "notebook_path = os.path.abspath(\"../readme.md\")\n",
    "notebook_dir = os.path.dirname(notebook_path)\n",
    "os.chdir(notebook_dir)\n",
    "\n",
    "# 현재 작업 디렉토리 출력\n",
    "print(\"Current working directory: \", os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### https://github.com/facebookresearch/detectron2/blob/main/MODEL_ZOO.md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectron2.data import MetadataCatalog, DatasetCatalog\n",
    "from detectron2.data.datasets import register_coco_instances\n",
    "\n",
    "# 데이터셋 경로와 형식 설정\n",
    "register_coco_instances(\"face_data_set\", {}, \"data/ssd_rcnn_face/annotations.json\", \"data/yolo_data/train/\")\n",
    "register_coco_instances(\"face_data_set_valid\", {}, \"data/ssd_rcnn_face/annotations_val.json\", \"data/yolo_data/val/\")\n",
    "\n",
    "# 메타데이터를 확인.\n",
    "metadata = MetadataCatalog.get(\"face_data_set\")\n",
    "dataset_dicts = DatasetCatalog.get(\"face_data_set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[09/06 16:44:24 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc_relu1): ReLU()\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (fc_relu2): ReLU()\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=5, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=16, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\u001b[32m[09/06 16:44:24 d2.data.datasets.coco]: \u001b[0mLoaded 5992 images in COCO format from data/ssd_rcnn_face/annotations.json\n",
      "\u001b[32m[09/06 16:44:24 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 5992 images left.\n",
      "\u001b[32m[09/06 16:44:24 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [RandomCrop(crop_type='relative_range', crop_size=[0.8, 0.8]), ResizeShortestEdge(short_edge_length=(512, 512), max_size=512, sample_style='choice'), RandomFlip()]\n",
      "\u001b[32m[09/06 16:44:24 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[09/06 16:44:24 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[09/06 16:44:24 d2.data.common]: \u001b[0mSerializing 5992 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[09/06 16:44:24 d2.data.common]: \u001b[0mSerialized dataset takes 1.79 MiB\n",
      "\u001b[32m[09/06 16:44:24 d2.data.build]: \u001b[0mMaking batched data loader with batch_size=16\n",
      "\u001b[32m[09/06 16:44:24 d2.checkpoint.detection_checkpoint]: \u001b[0m[DetectionCheckpointer] Loading from ./models/faster_rcnn_R_50_FPN_3x/model_1000.pth ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tommy/miniconda3/envs/p3/lib/python3.11/site-packages/fvcore/common/checkpoint.py:252: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(f, map_location=torch.device(\"cpu\"))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[09/06 16:44:27 d2.engine.hooks]: \u001b[0mLoading scheduler from state_dict ...\n",
      "\u001b[32m[09/06 16:44:27 d2.engine.train_loop]: \u001b[0mStarting training from iteration 1001\n",
      "\u001b[32m[09/06 16:45:19 d2.utils.events]: \u001b[0m eta: 17 days, 21:59:39  iter: 1019  total_loss: 0.5089  loss_cls: 0.3172  loss_box_reg: 0.1861  loss_rpn_cls: 0.0002765  loss_rpn_loc: 0.002662    time: 2.6776  last_time: 2.3288  data_time: 1.6963  last_data_time: 1.4400   lr: 0.00099999  max_mem: 4119M\n",
      "\u001b[32m[09/06 16:46:08 d2.utils.events]: \u001b[0m eta: 17 days, 1:37:21  iter: 1039  total_loss: 0.5214  loss_cls: 0.3192  loss_box_reg: 0.1953  loss_rpn_cls: 0.0005788  loss_rpn_loc: 0.002664    time: 2.5598  last_time: 2.8627  data_time: 1.4966  last_data_time: 1.8327   lr: 0.00099999  max_mem: 4119M\n",
      "\u001b[32m[09/06 16:46:58 d2.utils.events]: \u001b[0m eta: 16 days, 22:47:14  iter: 1059  total_loss: 0.4912  loss_cls: 0.2998  loss_box_reg: 0.1856  loss_rpn_cls: 0.0004026  loss_rpn_loc: 0.002483    time: 2.5456  last_time: 2.2332  data_time: 1.5663  last_data_time: 1.3175   lr: 0.00099999  max_mem: 4119M\n",
      "\u001b[32m[09/06 16:47:50 d2.utils.events]: \u001b[0m eta: 16 days, 21:45:25  iter: 1079  total_loss: 0.4736  loss_cls: 0.2854  loss_box_reg: 0.1831  loss_rpn_cls: 0.0003691  loss_rpn_loc: 0.00254    time: 2.5566  last_time: 2.3653  data_time: 1.6085  last_data_time: 1.3727   lr: 0.00099999  max_mem: 4119M\n",
      "\u001b[32m[09/06 16:48:42 d2.utils.events]: \u001b[0m eta: 17 days, 0:08:16  iter: 1099  total_loss: 0.4473  loss_cls: 0.2622  loss_box_reg: 0.181  loss_rpn_cls: 0.0001562  loss_rpn_loc: 0.002807    time: 2.5574  last_time: 2.5996  data_time: 1.5782  last_data_time: 1.5730   lr: 0.00099999  max_mem: 4119M\n",
      "\u001b[32m[09/06 16:49:32 d2.utils.events]: \u001b[0m eta: 17 days, 3:03:53  iter: 1119  total_loss: 0.4135  loss_cls: 0.2393  loss_box_reg: 0.1705  loss_rpn_cls: 0.0002772  loss_rpn_loc: 0.002367    time: 2.5512  last_time: 2.5501  data_time: 1.5565  last_data_time: 1.6289   lr: 0.00099999  max_mem: 4119M\n",
      "\u001b[32m[09/06 16:50:26 d2.utils.events]: \u001b[0m eta: 17 days, 4:31:01  iter: 1139  total_loss: 0.4349  loss_cls: 0.2615  loss_box_reg: 0.1724  loss_rpn_cls: 0.0001879  loss_rpn_loc: 0.00238    time: 2.5751  last_time: 2.1074  data_time: 1.7294  last_data_time: 1.1347   lr: 0.00099999  max_mem: 4119M\n",
      "\u001b[32m[09/06 16:51:18 d2.utils.events]: \u001b[0m eta: 17 days, 9:19:55  iter: 1159  total_loss: 0.4335  loss_cls: 0.2623  loss_box_reg: 0.1726  loss_rpn_cls: 0.0002561  loss_rpn_loc: 0.002208    time: 2.5757  last_time: 2.5314  data_time: 1.5873  last_data_time: 1.5122   lr: 0.00099999  max_mem: 4119M\n",
      "\u001b[32m[09/06 16:52:11 d2.utils.events]: \u001b[0m eta: 17 days, 10:31:29  iter: 1179  total_loss: 0.4188  loss_cls: 0.2628  loss_box_reg: 0.1626  loss_rpn_cls: 0.0002813  loss_rpn_loc: 0.002191    time: 2.5822  last_time: 2.6881  data_time: 1.6323  last_data_time: 1.5834   lr: 0.00099999  max_mem: 4119M\n",
      "\u001b[32m[09/06 16:53:06 d2.utils.events]: \u001b[0m eta: 17 days, 10:52:43  iter: 1199  total_loss: 0.4074  loss_cls: 0.2349  loss_box_reg: 0.1666  loss_rpn_cls: 0.0002932  loss_rpn_loc: 0.002177    time: 2.6012  last_time: 2.6362  data_time: 1.7611  last_data_time: 1.6520   lr: 0.00099999  max_mem: 4119M\n",
      "\u001b[32m[09/06 16:53:56 d2.utils.events]: \u001b[0m eta: 17 days, 10:14:55  iter: 1219  total_loss: 0.4036  loss_cls: 0.2273  loss_box_reg: 0.1621  loss_rpn_cls: 0.0004483  loss_rpn_loc: 0.001994    time: 2.5899  last_time: 2.6032  data_time: 1.5016  last_data_time: 1.6852   lr: 0.00099999  max_mem: 4119M\n",
      "\u001b[32m[09/06 16:54:47 d2.utils.events]: \u001b[0m eta: 17 days, 10:14:04  iter: 1239  total_loss: 0.3968  loss_cls: 0.2292  loss_box_reg: 0.1664  loss_rpn_cls: 0.0001137  loss_rpn_loc: 0.002153    time: 2.5865  last_time: 2.2354  data_time: 1.5789  last_data_time: 1.3358   lr: 0.00099999  max_mem: 4119M\n",
      "\u001b[32m[09/06 16:55:37 d2.utils.events]: \u001b[0m eta: 17 days, 9:37:38  iter: 1259  total_loss: 0.4106  loss_cls: 0.2317  loss_box_reg: 0.1792  loss_rpn_cls: 0.0004802  loss_rpn_loc: 0.002405    time: 2.5802  last_time: 2.4289  data_time: 1.5568  last_data_time: 1.5298   lr: 0.00099999  max_mem: 4119M\n",
      "\u001b[32m[09/06 16:56:28 d2.utils.events]: \u001b[0m eta: 17 days, 8:35:03  iter: 1279  total_loss: 0.3858  loss_cls: 0.2141  loss_box_reg: 0.1782  loss_rpn_cls: 0.0001572  loss_rpn_loc: 0.00196    time: 2.5796  last_time: 2.5048  data_time: 1.5891  last_data_time: 1.5229   lr: 0.00099999  max_mem: 4119M\n",
      "\u001b[32m[09/06 16:57:16 d2.utils.events]: \u001b[0m eta: 17 days, 7:55:45  iter: 1299  total_loss: 0.3898  loss_cls: 0.2181  loss_box_reg: 0.1565  loss_rpn_cls: 0.0001881  loss_rpn_loc: 0.002094    time: 2.5658  last_time: 2.9398  data_time: 1.4498  last_data_time: 1.8839   lr: 0.00099999  max_mem: 4119M\n",
      "\u001b[32m[09/06 16:58:06 d2.utils.events]: \u001b[0m eta: 17 days, 5:01:41  iter: 1319  total_loss: 0.3568  loss_cls: 0.1886  loss_box_reg: 0.1672  loss_rpn_cls: 0.0001915  loss_rpn_loc: 0.002058    time: 2.5613  last_time: 3.1530  data_time: 1.5387  last_data_time: 2.0961   lr: 0.00099999  max_mem: 4119M\n",
      "\u001b[32m[09/06 16:58:57 d2.utils.events]: \u001b[0m eta: 17 days, 4:51:17  iter: 1339  total_loss: 0.3721  loss_cls: 0.2017  loss_box_reg: 0.1711  loss_rpn_cls: 0.0002804  loss_rpn_loc: 0.002448    time: 2.5614  last_time: 2.3393  data_time: 1.6016  last_data_time: 1.4220   lr: 0.00099999  max_mem: 4119M\n",
      "\u001b[32m[09/06 16:59:48 d2.utils.events]: \u001b[0m eta: 17 days, 4:01:02  iter: 1359  total_loss: 0.3855  loss_cls: 0.2043  loss_box_reg: 0.1675  loss_rpn_cls: 0.0001286  loss_rpn_loc: 0.002149    time: 2.5602  last_time: 2.4140  data_time: 1.5920  last_data_time: 1.5338   lr: 0.00099999  max_mem: 4119M\n",
      "\u001b[32m[09/06 17:00:36 d2.utils.events]: \u001b[0m eta: 17 days, 3:02:39  iter: 1379  total_loss: 0.3686  loss_cls: 0.1972  loss_box_reg: 0.1647  loss_rpn_cls: 0.0001967  loss_rpn_loc: 0.002074    time: 2.5525  last_time: 2.3288  data_time: 1.4506  last_data_time: 1.4542   lr: 0.00099999  max_mem: 4119M\n",
      "\u001b[32m[09/06 17:01:28 d2.utils.events]: \u001b[0m eta: 17 days, 2:53:13  iter: 1399  total_loss: 0.3532  loss_cls: 0.1908  loss_box_reg: 0.1618  loss_rpn_cls: 0.000123  loss_rpn_loc: 0.00208    time: 2.5548  last_time: 2.2953  data_time: 1.6165  last_data_time: 1.3827   lr: 0.00099999  max_mem: 4119M\n",
      "\u001b[32m[09/06 17:02:20 d2.utils.events]: \u001b[0m eta: 17 days, 2:52:23  iter: 1419  total_loss: 0.3626  loss_cls: 0.1902  loss_box_reg: 0.1665  loss_rpn_cls: 0.000185  loss_rpn_loc: 0.002205    time: 2.5575  last_time: 2.6072  data_time: 1.6334  last_data_time: 1.5763   lr: 0.00099999  max_mem: 4119M\n",
      "\u001b[32m[09/06 17:03:09 d2.utils.events]: \u001b[0m eta: 17 days, 1:45:00  iter: 1439  total_loss: 0.3343  loss_cls: 0.1797  loss_box_reg: 0.1487  loss_rpn_cls: 0.0001641  loss_rpn_loc: 0.002063    time: 2.5515  last_time: 2.7521  data_time: 1.4918  last_data_time: 1.7843   lr: 0.00099999  max_mem: 4119M\n",
      "\u001b[32m[09/06 17:03:58 d2.utils.events]: \u001b[0m eta: 17 days, 2:27:48  iter: 1459  total_loss: 0.3419  loss_cls: 0.1878  loss_box_reg: 0.1515  loss_rpn_cls: 0.0001291  loss_rpn_loc: 0.001868    time: 2.5482  last_time: 2.1639  data_time: 1.5409  last_data_time: 1.3270   lr: 0.00099999  max_mem: 4119M\n",
      "\u001b[32m[09/06 17:04:48 d2.utils.events]: \u001b[0m eta: 17 days, 1:41:11  iter: 1479  total_loss: 0.3444  loss_cls: 0.2059  loss_box_reg: 0.1456  loss_rpn_cls: 0.000229  loss_rpn_loc: 0.001924    time: 2.5457  last_time: 2.4939  data_time: 1.5619  last_data_time: 1.5309   lr: 0.00099999  max_mem: 4119M\n",
      "\u001b[32m[09/06 17:05:40 d2.utils.events]: \u001b[0m eta: 17 days, 1:26:36  iter: 1499  total_loss: 0.3536  loss_cls: 0.1847  loss_box_reg: 0.1448  loss_rpn_cls: 0.0001017  loss_rpn_loc: 0.001813    time: 2.5440  last_time: 2.4226  data_time: 1.5565  last_data_time: 1.5174   lr: 0.00099998  max_mem: 4119M\n",
      "\u001b[32m[09/06 17:06:27 d2.utils.events]: \u001b[0m eta: 17 days, 0:23:26  iter: 1519  total_loss: 0.3548  loss_cls: 0.1894  loss_box_reg: 0.1627  loss_rpn_cls: 0.0001029  loss_rpn_loc: 0.001954    time: 2.5367  last_time: 2.3689  data_time: 1.4342  last_data_time: 1.4641   lr: 0.00099998  max_mem: 4119M\n",
      "\u001b[32m[09/06 17:07:14 d2.utils.events]: \u001b[0m eta: 16 days, 22:23:04  iter: 1539  total_loss: 0.3405  loss_cls: 0.1802  loss_box_reg: 0.1541  loss_rpn_cls: 0.0001369  loss_rpn_loc: 0.001922    time: 2.5281  last_time: 2.2617  data_time: 1.4002  last_data_time: 1.4076   lr: 0.00099998  max_mem: 4119M\n",
      "\u001b[32m[09/06 17:08:03 d2.utils.events]: \u001b[0m eta: 16 days, 22:22:16  iter: 1559  total_loss: 0.3288  loss_cls: 0.1757  loss_box_reg: 0.1485  loss_rpn_cls: 0.0001092  loss_rpn_loc: 0.001989    time: 2.5258  last_time: 2.6174  data_time: 1.5322  last_data_time: 1.7835   lr: 0.00099998  max_mem: 4119M\n",
      "\u001b[32m[09/06 17:08:52 d2.utils.events]: \u001b[0m eta: 16 days, 21:16:25  iter: 1579  total_loss: 0.3301  loss_cls: 0.1726  loss_box_reg: 0.1532  loss_rpn_cls: 0.0001246  loss_rpn_loc: 0.002001    time: 2.5232  last_time: 2.4308  data_time: 1.5047  last_data_time: 1.5222   lr: 0.00099998  max_mem: 4119M\n",
      "\u001b[32m[09/06 17:09:42 d2.utils.events]: \u001b[0m eta: 16 days, 21:16:38  iter: 1599  total_loss: 0.3417  loss_cls: 0.1824  loss_box_reg: 0.1503  loss_rpn_cls: 0.0001094  loss_rpn_loc: 0.002019    time: 2.5221  last_time: 2.3451  data_time: 1.5005  last_data_time: 1.4082   lr: 0.00099998  max_mem: 4119M\n",
      "\u001b[32m[09/06 17:10:31 d2.utils.events]: \u001b[0m eta: 16 days, 20:54:10  iter: 1619  total_loss: 0.3391  loss_cls: 0.1644  loss_box_reg: 0.1652  loss_rpn_cls: 0.0001909  loss_rpn_loc: 0.001919    time: 2.5195  last_time: 2.0383  data_time: 1.4984  last_data_time: 1.1303   lr: 0.00099998  max_mem: 4119M\n",
      "\u001b[32m[09/06 17:11:21 d2.utils.events]: \u001b[0m eta: 16 days, 21:13:59  iter: 1639  total_loss: 0.3352  loss_cls: 0.1777  loss_box_reg: 0.1468  loss_rpn_cls: 0.0001087  loss_rpn_loc: 0.001869    time: 2.5189  last_time: 2.0753  data_time: 1.5451  last_data_time: 1.1857   lr: 0.00099998  max_mem: 4119M\n",
      "\u001b[32m[09/06 17:12:10 d2.utils.events]: \u001b[0m eta: 16 days, 20:53:35  iter: 1659  total_loss: 0.3314  loss_cls: 0.1975  loss_box_reg: 0.1311  loss_rpn_cls: 0.0003  loss_rpn_loc: 0.0018    time: 2.5169  last_time: 2.5320  data_time: 1.5115  last_data_time: 1.6199   lr: 0.00099998  max_mem: 4119M\n",
      "\u001b[32m[09/06 17:13:06 d2.utils.events]: \u001b[0m eta: 16 days, 21:33:58  iter: 1679  total_loss: 0.3211  loss_cls: 0.1691  loss_box_reg: 0.154  loss_rpn_cls: 9.796e-05  loss_rpn_loc: 0.00188    time: 2.5255  last_time: 3.1218  data_time: 1.7778  last_data_time: 2.0199   lr: 0.00099998  max_mem: 4119M\n",
      "\u001b[32m[09/06 17:13:57 d2.utils.events]: \u001b[0m eta: 16 days, 22:30:59  iter: 1699  total_loss: 0.3346  loss_cls: 0.1667  loss_box_reg: 0.1518  loss_rpn_cls: 0.0001112  loss_rpn_loc: 0.001841    time: 2.5262  last_time: 2.1926  data_time: 1.5783  last_data_time: 1.3200   lr: 0.00099998  max_mem: 4119M\n",
      "\u001b[32m[09/06 17:14:47 d2.utils.events]: \u001b[0m eta: 16 days, 21:32:21  iter: 1719  total_loss: 0.3134  loss_cls: 0.1655  loss_box_reg: 0.1491  loss_rpn_cls: 0.0001205  loss_rpn_loc: 0.001901    time: 2.5255  last_time: 2.3514  data_time: 1.5148  last_data_time: 1.3075   lr: 0.00099998  max_mem: 4119M\n",
      "\u001b[32m[09/06 17:15:44 d2.utils.events]: \u001b[0m eta: 16 days, 22:36:12  iter: 1739  total_loss: 0.3093  loss_cls: 0.1587  loss_box_reg: 0.1518  loss_rpn_cls: 0.0001648  loss_rpn_loc: 0.001756    time: 2.5338  last_time: 1.0278  data_time: 1.7844  last_data_time: 0.0123   lr: 0.00099998  max_mem: 4120M\n",
      "\u001b[32m[09/06 17:16:37 d2.utils.events]: \u001b[0m eta: 16 days, 23:41:17  iter: 1759  total_loss: 0.2906  loss_cls: 0.1385  loss_box_reg: 0.151  loss_rpn_cls: 0.0001514  loss_rpn_loc: 0.001862    time: 2.5378  last_time: 2.4814  data_time: 1.7018  last_data_time: 1.6154   lr: 0.00099998  max_mem: 4120M\n",
      "\u001b[32m[09/06 17:17:27 d2.utils.events]: \u001b[0m eta: 16 days, 23:39:24  iter: 1779  total_loss: 0.3195  loss_cls: 0.1689  loss_box_reg: 0.1474  loss_rpn_cls: 7.221e-05  loss_rpn_loc: 0.001751    time: 2.5365  last_time: 2.7228  data_time: 1.5302  last_data_time: 1.5542   lr: 0.00099998  max_mem: 4120M\n",
      "\u001b[32m[09/06 17:18:19 d2.utils.events]: \u001b[0m eta: 16 days, 23:41:37  iter: 1799  total_loss: 0.2963  loss_cls: 0.1404  loss_box_reg: 0.1433  loss_rpn_cls: 0.0001054  loss_rpn_loc: 0.001906    time: 2.5385  last_time: 2.2573  data_time: 1.6797  last_data_time: 1.3588   lr: 0.00099998  max_mem: 4120M\n",
      "\u001b[32m[09/06 17:19:09 d2.utils.events]: \u001b[0m eta: 16 days, 23:43:09  iter: 1819  total_loss: 0.318  loss_cls: 0.1624  loss_box_reg: 0.1454  loss_rpn_cls: 0.0001879  loss_rpn_loc: 0.001841    time: 2.5373  last_time: 2.5702  data_time: 1.5544  last_data_time: 1.6613   lr: 0.00099998  max_mem: 4120M\n",
      "\u001b[32m[09/06 17:19:59 d2.utils.events]: \u001b[0m eta: 17 days, 0:01:33  iter: 1839  total_loss: 0.3014  loss_cls: 0.1556  loss_box_reg: 0.1404  loss_rpn_cls: 6.299e-05  loss_rpn_loc: 0.001804    time: 2.5362  last_time: 2.2631  data_time: 1.5303  last_data_time: 1.3117   lr: 0.00099998  max_mem: 4120M\n",
      "\u001b[32m[09/06 17:20:50 d2.utils.events]: \u001b[0m eta: 17 days, 0:00:44  iter: 1859  total_loss: 0.3029  loss_cls: 0.1544  loss_box_reg: 0.1329  loss_rpn_cls: 8.44e-05  loss_rpn_loc: 0.001713    time: 2.5365  last_time: 3.2898  data_time: 1.6064  last_data_time: 2.1268   lr: 0.00099998  max_mem: 4120M\n",
      "\u001b[32m[09/06 17:21:37 d2.utils.events]: \u001b[0m eta: 16 days, 23:59:55  iter: 1879  total_loss: 0.2871  loss_cls: 0.146  loss_box_reg: 0.1419  loss_rpn_cls: 0.0001215  loss_rpn_loc: 0.001846    time: 2.5327  last_time: 0.9978  data_time: 1.4386  last_data_time: 0.0129   lr: 0.00099998  max_mem: 4120M\n",
      "\u001b[32m[09/06 17:22:29 d2.utils.events]: \u001b[0m eta: 17 days, 0:06:32  iter: 1899  total_loss: 0.3063  loss_cls: 0.1629  loss_box_reg: 0.1449  loss_rpn_cls: 7.891e-05  loss_rpn_loc: 0.001781    time: 2.5335  last_time: 2.5084  data_time: 1.6080  last_data_time: 1.5489   lr: 0.00099998  max_mem: 4120M\n",
      "\u001b[32m[09/06 17:23:22 d2.utils.events]: \u001b[0m eta: 17 days, 0:05:43  iter: 1919  total_loss: 0.287  loss_cls: 0.1565  loss_box_reg: 0.1341  loss_rpn_cls: 0.0001401  loss_rpn_loc: 0.001689    time: 2.5357  last_time: 3.1276  data_time: 1.6450  last_data_time: 2.0766   lr: 0.00099997  max_mem: 4120M\n",
      "\u001b[32m[09/06 17:24:10 d2.utils.events]: \u001b[0m eta: 16 days, 23:35:53  iter: 1939  total_loss: 0.2985  loss_cls: 0.1442  loss_box_reg: 0.151  loss_rpn_cls: 7.962e-05  loss_rpn_loc: 0.001764    time: 2.5328  last_time: 2.3237  data_time: 1.4411  last_data_time: 1.4045   lr: 0.00099997  max_mem: 4120M\n",
      "\u001b[32m[09/06 17:24:58 d2.utils.events]: \u001b[0m eta: 16 days, 23:32:02  iter: 1959  total_loss: 0.2794  loss_cls: 0.1298  loss_box_reg: 0.1413  loss_rpn_cls: 0.0001026  loss_rpn_loc: 0.001686    time: 2.5305  last_time: 2.2901  data_time: 1.4771  last_data_time: 1.3820   lr: 0.00099997  max_mem: 4120M\n",
      "\u001b[32m[09/06 17:25:50 d2.utils.events]: \u001b[0m eta: 16 days, 23:31:13  iter: 1979  total_loss: 0.299  loss_cls: 0.1512  loss_box_reg: 0.1404  loss_rpn_cls: 0.0001925  loss_rpn_loc: 0.001703    time: 2.5320  last_time: 2.2064  data_time: 1.6432  last_data_time: 1.2319   lr: 0.00099997  max_mem: 4120M\n",
      "\u001b[32m[09/06 17:26:42 d2.data.datasets.coco]: \u001b[0mLoaded 1199 images in COCO format from data/ssd_rcnn_face/annotations_val.json\n",
      "\u001b[32m[09/06 17:26:42 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(512, 512), max_size=512, sample_style='choice')]\n",
      "\u001b[32m[09/06 17:26:42 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[09/06 17:26:42 d2.data.common]: \u001b[0mSerializing 1199 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[09/06 17:26:42 d2.data.common]: \u001b[0mSerialized dataset takes 0.36 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[09/06 17:26:42 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n",
      "\u001b[32m[09/06 17:26:42 d2.evaluation.evaluator]: \u001b[0mStart inference on 1199 batches\n",
      "\u001b[32m[09/06 17:26:44 d2.evaluation.evaluator]: \u001b[0mInference done 11/1199. Dataloading: 0.0460 s/iter. Inference: 0.0662 s/iter. Eval: 0.0005 s/iter. Total: 0.1127 s/iter. ETA=0:02:13\n",
      "\u001b[32m[09/06 17:26:49 d2.evaluation.evaluator]: \u001b[0mInference done 47/1199. Dataloading: 0.0728 s/iter. Inference: 0.0623 s/iter. Eval: 0.0005 s/iter. Total: 0.1357 s/iter. ETA=0:02:36\n",
      "\u001b[32m[09/06 17:26:54 d2.evaluation.evaluator]: \u001b[0mInference done 83/1199. Dataloading: 0.0764 s/iter. Inference: 0.0615 s/iter. Eval: 0.0005 s/iter. Total: 0.1385 s/iter. ETA=0:02:34\n",
      "\u001b[32m[09/06 17:27:00 d2.evaluation.evaluator]: \u001b[0mInference done 115/1199. Dataloading: 0.0810 s/iter. Inference: 0.0631 s/iter. Eval: 0.0005 s/iter. Total: 0.1446 s/iter. ETA=0:02:36\n",
      "\u001b[32m[09/06 17:27:05 d2.evaluation.evaluator]: \u001b[0mInference done 142/1199. Dataloading: 0.0893 s/iter. Inference: 0.0636 s/iter. Eval: 0.0005 s/iter. Total: 0.1535 s/iter. ETA=0:02:42\n",
      "\u001b[32m[09/06 17:27:10 d2.evaluation.evaluator]: \u001b[0mInference done 179/1199. Dataloading: 0.0872 s/iter. Inference: 0.0636 s/iter. Eval: 0.0005 s/iter. Total: 0.1513 s/iter. ETA=0:02:34\n",
      "\u001b[32m[09/06 17:27:15 d2.evaluation.evaluator]: \u001b[0mInference done 215/1199. Dataloading: 0.0857 s/iter. Inference: 0.0635 s/iter. Eval: 0.0005 s/iter. Total: 0.1497 s/iter. ETA=0:02:27\n",
      "\u001b[32m[09/06 17:27:20 d2.evaluation.evaluator]: \u001b[0mInference done 243/1199. Dataloading: 0.0896 s/iter. Inference: 0.0642 s/iter. Eval: 0.0005 s/iter. Total: 0.1544 s/iter. ETA=0:02:27\n",
      "\u001b[32m[09/06 17:27:26 d2.evaluation.evaluator]: \u001b[0mInference done 274/1199. Dataloading: 0.0919 s/iter. Inference: 0.0642 s/iter. Eval: 0.0005 s/iter. Total: 0.1567 s/iter. ETA=0:02:24\n",
      "\u001b[32m[09/06 17:27:31 d2.evaluation.evaluator]: \u001b[0mInference done 294/1199. Dataloading: 0.0980 s/iter. Inference: 0.0648 s/iter. Eval: 0.0005 s/iter. Total: 0.1634 s/iter. ETA=0:02:27\n",
      "\u001b[32m[09/06 17:27:36 d2.evaluation.evaluator]: \u001b[0mInference done 327/1199. Dataloading: 0.0982 s/iter. Inference: 0.0644 s/iter. Eval: 0.0005 s/iter. Total: 0.1632 s/iter. ETA=0:02:22\n",
      "\u001b[32m[09/06 17:27:41 d2.evaluation.evaluator]: \u001b[0mInference done 365/1199. Dataloading: 0.0953 s/iter. Inference: 0.0644 s/iter. Eval: 0.0005 s/iter. Total: 0.1602 s/iter. ETA=0:02:13\n",
      "\u001b[32m[09/06 17:27:46 d2.evaluation.evaluator]: \u001b[0mInference done 392/1199. Dataloading: 0.0974 s/iter. Inference: 0.0641 s/iter. Eval: 0.0005 s/iter. Total: 0.1621 s/iter. ETA=0:02:10\n",
      "\u001b[32m[09/06 17:27:51 d2.evaluation.evaluator]: \u001b[0mInference done 429/1199. Dataloading: 0.0955 s/iter. Inference: 0.0640 s/iter. Eval: 0.0005 s/iter. Total: 0.1601 s/iter. ETA=0:02:03\n",
      "\u001b[32m[09/06 17:27:57 d2.evaluation.evaluator]: \u001b[0mInference done 467/1199. Dataloading: 0.0939 s/iter. Inference: 0.0636 s/iter. Eval: 0.0005 s/iter. Total: 0.1581 s/iter. ETA=0:01:55\n",
      "\u001b[32m[09/06 17:28:02 d2.evaluation.evaluator]: \u001b[0mInference done 502/1199. Dataloading: 0.0931 s/iter. Inference: 0.0636 s/iter. Eval: 0.0005 s/iter. Total: 0.1572 s/iter. ETA=0:01:49\n",
      "\u001b[32m[09/06 17:28:07 d2.evaluation.evaluator]: \u001b[0mInference done 536/1199. Dataloading: 0.0927 s/iter. Inference: 0.0634 s/iter. Eval: 0.0005 s/iter. Total: 0.1567 s/iter. ETA=0:01:43\n",
      "\u001b[32m[09/06 17:28:12 d2.evaluation.evaluator]: \u001b[0mInference done 573/1199. Dataloading: 0.0913 s/iter. Inference: 0.0637 s/iter. Eval: 0.0005 s/iter. Total: 0.1556 s/iter. ETA=0:01:37\n",
      "\u001b[32m[09/06 17:28:17 d2.evaluation.evaluator]: \u001b[0mInference done 608/1199. Dataloading: 0.0909 s/iter. Inference: 0.0636 s/iter. Eval: 0.0005 s/iter. Total: 0.1551 s/iter. ETA=0:01:31\n",
      "\u001b[32m[09/06 17:28:22 d2.evaluation.evaluator]: \u001b[0mInference done 642/1199. Dataloading: 0.0906 s/iter. Inference: 0.0635 s/iter. Eval: 0.0005 s/iter. Total: 0.1547 s/iter. ETA=0:01:26\n",
      "\u001b[32m[09/06 17:28:28 d2.evaluation.evaluator]: \u001b[0mInference done 675/1199. Dataloading: 0.0925 s/iter. Inference: 0.0633 s/iter. Eval: 0.0005 s/iter. Total: 0.1564 s/iter. ETA=0:01:21\n",
      "\u001b[32m[09/06 17:28:33 d2.evaluation.evaluator]: \u001b[0mInference done 714/1199. Dataloading: 0.0909 s/iter. Inference: 0.0635 s/iter. Eval: 0.0005 s/iter. Total: 0.1550 s/iter. ETA=0:01:15\n",
      "\u001b[32m[09/06 17:28:40 d2.evaluation.evaluator]: \u001b[0mInference done 747/1199. Dataloading: 0.0921 s/iter. Inference: 0.0635 s/iter. Eval: 0.0005 s/iter. Total: 0.1562 s/iter. ETA=0:01:10\n",
      "\u001b[32m[09/06 17:28:45 d2.evaluation.evaluator]: \u001b[0mInference done 770/1199. Dataloading: 0.0937 s/iter. Inference: 0.0638 s/iter. Eval: 0.0005 s/iter. Total: 0.1581 s/iter. ETA=0:01:07\n",
      "\u001b[32m[09/06 17:28:50 d2.evaluation.evaluator]: \u001b[0mInference done 807/1199. Dataloading: 0.0928 s/iter. Inference: 0.0636 s/iter. Eval: 0.0005 s/iter. Total: 0.1570 s/iter. ETA=0:01:01\n",
      "\u001b[32m[09/06 17:28:55 d2.evaluation.evaluator]: \u001b[0mInference done 846/1199. Dataloading: 0.0918 s/iter. Inference: 0.0635 s/iter. Eval: 0.0005 s/iter. Total: 0.1558 s/iter. ETA=0:00:55\n",
      "\u001b[32m[09/06 17:29:00 d2.evaluation.evaluator]: \u001b[0mInference done 879/1199. Dataloading: 0.0918 s/iter. Inference: 0.0634 s/iter. Eval: 0.0005 s/iter. Total: 0.1558 s/iter. ETA=0:00:49\n",
      "\u001b[32m[09/06 17:29:05 d2.evaluation.evaluator]: \u001b[0mInference done 909/1199. Dataloading: 0.0920 s/iter. Inference: 0.0636 s/iter. Eval: 0.0005 s/iter. Total: 0.1563 s/iter. ETA=0:00:45\n",
      "\u001b[32m[09/06 17:29:10 d2.evaluation.evaluator]: \u001b[0mInference done 948/1199. Dataloading: 0.0910 s/iter. Inference: 0.0636 s/iter. Eval: 0.0005 s/iter. Total: 0.1551 s/iter. ETA=0:00:38\n",
      "\u001b[32m[09/06 17:29:15 d2.evaluation.evaluator]: \u001b[0mInference done 979/1199. Dataloading: 0.0913 s/iter. Inference: 0.0636 s/iter. Eval: 0.0005 s/iter. Total: 0.1555 s/iter. ETA=0:00:34\n",
      "\u001b[32m[09/06 17:29:20 d2.evaluation.evaluator]: \u001b[0mInference done 1014/1199. Dataloading: 0.0910 s/iter. Inference: 0.0636 s/iter. Eval: 0.0005 s/iter. Total: 0.1552 s/iter. ETA=0:00:28\n",
      "\u001b[32m[09/06 17:29:25 d2.evaluation.evaluator]: \u001b[0mInference done 1042/1199. Dataloading: 0.0916 s/iter. Inference: 0.0636 s/iter. Eval: 0.0005 s/iter. Total: 0.1558 s/iter. ETA=0:00:24\n",
      "\u001b[32m[09/06 17:29:30 d2.evaluation.evaluator]: \u001b[0mInference done 1075/1199. Dataloading: 0.0918 s/iter. Inference: 0.0635 s/iter. Eval: 0.0005 s/iter. Total: 0.1559 s/iter. ETA=0:00:19\n",
      "\u001b[32m[09/06 17:29:35 d2.evaluation.evaluator]: \u001b[0mInference done 1112/1199. Dataloading: 0.0912 s/iter. Inference: 0.0634 s/iter. Eval: 0.0005 s/iter. Total: 0.1553 s/iter. ETA=0:00:13\n",
      "\u001b[32m[09/06 17:29:41 d2.evaluation.evaluator]: \u001b[0mInference done 1138/1199. Dataloading: 0.0920 s/iter. Inference: 0.0636 s/iter. Eval: 0.0005 s/iter. Total: 0.1561 s/iter. ETA=0:00:09\n",
      "\u001b[32m[09/06 17:29:46 d2.evaluation.evaluator]: \u001b[0mInference done 1170/1199. Dataloading: 0.0921 s/iter. Inference: 0.0636 s/iter. Eval: 0.0005 s/iter. Total: 0.1563 s/iter. ETA=0:00:04\n",
      "\u001b[32m[09/06 17:29:50 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:03:06.201792 (0.155948 s / iter per device, on 1 devices)\n",
      "\u001b[32m[09/06 17:29:50 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:01:16 (0.063658 s / iter per device, on 1 devices)\n",
      "\u001b[32m[09/06 17:29:50 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[09/06 17:29:50 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.03s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[09/06 17:29:50 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[09/06 17:29:53 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 2.73 seconds.\n",
      "\u001b[32m[09/06 17:29:53 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[09/06 17:29:53 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.03 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.660\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.787\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.780\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.660\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.867\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.867\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.867\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.867\n",
      "\u001b[32m[09/06 17:29:53 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
      "| 65.953 | 78.727 | 77.961 |  nan  |  nan  | 65.953 |\n",
      "\u001b[32m[09/06 17:29:53 d2.evaluation.coco_evaluation]: \u001b[0mSome metrics cannot be computed and is shown as NaN.\n",
      "\u001b[32m[09/06 17:29:53 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category   | AP     | category   | AP     | category   | AP     |\n",
      "|:-----------|:-------|:-----------|:-------|:-----------|:-------|\n",
      "| angry      | 51.326 | sad        | 65.174 | surprised  | 65.822 |\n",
      "| happy      | 81.490 |            |        |            |        |\n",
      "\u001b[32m[09/06 17:29:53 d2.engine.defaults]: \u001b[0mEvaluation results for face_data_set_valid in csv format:\n",
      "\u001b[32m[09/06 17:29:53 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[09/06 17:29:53 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[09/06 17:29:53 d2.evaluation.testing]: \u001b[0mcopypaste: 65.9529,78.7275,77.9610,nan,nan,65.9529\n",
      "\u001b[32m[09/06 17:29:53 d2.utils.events]: \u001b[0m eta: 16 days, 23:30:24  iter: 1999  total_loss: 0.2913  loss_cls: 0.139  loss_box_reg: 0.1476  loss_rpn_cls: 0.0001208  loss_rpn_loc: 0.001839    time: 2.5313  last_time: 2.5927  data_time: 1.5404  last_data_time: 1.6544   lr: 0.00099997  max_mem: 4120M\n",
      "\u001b[32m[09/06 17:30:42 d2.utils.events]: \u001b[0m eta: 16 days, 22:21:22  iter: 2019  total_loss: 0.2806  loss_cls: 0.1311  loss_box_reg: 0.1466  loss_rpn_cls: 5.89e-05  loss_rpn_loc: 0.001775    time: 2.5302  last_time: 2.2319  data_time: 1.5272  last_data_time: 1.3820   lr: 0.00099997  max_mem: 4120M\n",
      "\u001b[32m[09/06 17:31:32 d2.utils.events]: \u001b[0m eta: 16 days, 22:42:06  iter: 2039  total_loss: 0.2642  loss_cls: 0.129  loss_box_reg: 0.1337  loss_rpn_cls: 0.0001108  loss_rpn_loc: 0.001905    time: 2.5298  last_time: 2.5126  data_time: 1.5330  last_data_time: 1.5252   lr: 0.00099997  max_mem: 4120M\n",
      "\u001b[32m[09/06 17:32:35 d2.utils.events]: \u001b[0m eta: 16 days, 23:56:16  iter: 2059  total_loss: 0.2906  loss_cls: 0.1429  loss_box_reg: 0.1413  loss_rpn_cls: 9.173e-05  loss_rpn_loc: 0.001854    time: 2.5409  last_time: 2.6029  data_time: 2.0037  last_data_time: 1.5913   lr: 0.00099997  max_mem: 4120M\n",
      "\u001b[32m[09/06 17:33:43 d2.utils.events]: \u001b[0m eta: 17 days, 1:10:28  iter: 2079  total_loss: 0.2773  loss_cls: 0.1426  loss_box_reg: 0.1402  loss_rpn_cls: 0.0001026  loss_rpn_loc: 0.001868    time: 2.5568  last_time: 3.4897  data_time: 2.2039  last_data_time: 2.2987   lr: 0.00099997  max_mem: 4120M\n",
      "\u001b[32m[09/06 17:34:34 d2.utils.events]: \u001b[0m eta: 17 days, 1:16:48  iter: 2099  total_loss: 0.2943  loss_cls: 0.1468  loss_box_reg: 0.1458  loss_rpn_cls: 0.0001113  loss_rpn_loc: 0.001772    time: 2.5574  last_time: 3.7096  data_time: 1.5749  last_data_time: 2.6728   lr: 0.00099997  max_mem: 4120M\n",
      "\u001b[32m[09/06 17:35:25 d2.utils.events]: \u001b[0m eta: 17 days, 1:02:07  iter: 2119  total_loss: 0.3289  loss_cls: 0.1717  loss_box_reg: 0.1467  loss_rpn_cls: 7.497e-05  loss_rpn_loc: 0.001734    time: 2.5565  last_time: 2.3836  data_time: 1.5439  last_data_time: 1.3789   lr: 0.00099997  max_mem: 4120M\n",
      "\u001b[32m[09/06 17:36:15 d2.utils.events]: \u001b[0m eta: 17 days, 0:57:13  iter: 2139  total_loss: 0.2845  loss_cls: 0.1463  loss_box_reg: 0.1351  loss_rpn_cls: 0.0001275  loss_rpn_loc: 0.001851    time: 2.5559  last_time: 2.2686  data_time: 1.5750  last_data_time: 1.3600   lr: 0.00099997  max_mem: 4120M\n",
      "\u001b[32m[09/06 17:37:06 d2.utils.events]: \u001b[0m eta: 17 days, 0:04:10  iter: 2159  total_loss: 0.2947  loss_cls: 0.149  loss_box_reg: 0.1419  loss_rpn_cls: 8.134e-05  loss_rpn_loc: 0.001755    time: 2.5553  last_time: 2.5180  data_time: 1.5731  last_data_time: 1.6419   lr: 0.00099997  max_mem: 4120M\n",
      "\u001b[32m[09/06 17:37:56 d2.utils.events]: \u001b[0m eta: 16 days, 23:30:57  iter: 2179  total_loss: 0.2787  loss_cls: 0.1387  loss_box_reg: 0.1389  loss_rpn_cls: 0.0001472  loss_rpn_loc: 0.0019    time: 2.5549  last_time: 2.4181  data_time: 1.5673  last_data_time: 1.4637   lr: 0.00099997  max_mem: 4120M\n",
      "\u001b[32m[09/06 17:38:47 d2.utils.events]: \u001b[0m eta: 16 days, 22:57:10  iter: 2199  total_loss: 0.2864  loss_cls: 0.1467  loss_box_reg: 0.1359  loss_rpn_cls: 0.0001442  loss_rpn_loc: 0.001865    time: 2.5547  last_time: 2.6246  data_time: 1.5883  last_data_time: 1.7006   lr: 0.00099997  max_mem: 4120M\n",
      "\u001b[32m[09/06 17:39:39 d2.utils.events]: \u001b[0m eta: 16 days, 23:22:55  iter: 2219  total_loss: 0.2734  loss_cls: 0.1399  loss_box_reg: 0.1259  loss_rpn_cls: 9.652e-05  loss_rpn_loc: 0.001741    time: 2.5550  last_time: 2.2811  data_time: 1.6246  last_data_time: 1.3118   lr: 0.00099997  max_mem: 4120M\n",
      "\u001b[32m[09/06 17:40:31 d2.utils.events]: \u001b[0m eta: 16 days, 23:24:48  iter: 2239  total_loss: 0.2807  loss_cls: 0.1358  loss_box_reg: 0.1411  loss_rpn_cls: 7.226e-05  loss_rpn_loc: 0.00164    time: 2.5564  last_time: 3.0125  data_time: 1.6486  last_data_time: 1.7824   lr: 0.00099997  max_mem: 4120M\n",
      "\u001b[32m[09/06 17:41:21 d2.utils.events]: \u001b[0m eta: 16 days, 23:23:59  iter: 2259  total_loss: 0.2954  loss_cls: 0.1383  loss_box_reg: 0.14  loss_rpn_cls: 9.983e-05  loss_rpn_loc: 0.001642    time: 2.5548  last_time: 2.1215  data_time: 1.5093  last_data_time: 1.2033   lr: 0.00099997  max_mem: 4120M\n",
      "\u001b[32m[09/06 17:42:08 d2.utils.events]: \u001b[0m eta: 16 days, 22:53:54  iter: 2279  total_loss: 0.2848  loss_cls: 0.138  loss_box_reg: 0.1364  loss_rpn_cls: 8.149e-05  loss_rpn_loc: 0.001697    time: 2.5518  last_time: 2.2560  data_time: 1.4264  last_data_time: 1.3239   lr: 0.00099996  max_mem: 4120M\n",
      "\u001b[32m[09/06 17:42:59 d2.utils.events]: \u001b[0m eta: 16 days, 23:24:52  iter: 2299  total_loss: 0.2624  loss_cls: 0.1209  loss_box_reg: 0.1372  loss_rpn_cls: 0.0001736  loss_rpn_loc: 0.001693    time: 2.5516  last_time: 3.8467  data_time: 1.5870  last_data_time: 2.6742   lr: 0.00099996  max_mem: 4120M\n",
      "\u001b[32m[09/06 17:43:50 d2.utils.events]: \u001b[0m eta: 16 days, 23:42:08  iter: 2319  total_loss: 0.274  loss_cls: 0.1238  loss_box_reg: 0.1386  loss_rpn_cls: 8.694e-05  loss_rpn_loc: 0.001592    time: 2.5516  last_time: 2.6044  data_time: 1.5936  last_data_time: 1.5383   lr: 0.00099996  max_mem: 4120M\n",
      "\u001b[32m[09/06 17:44:40 d2.utils.events]: \u001b[0m eta: 16 days, 23:41:19  iter: 2339  total_loss: 0.281  loss_cls: 0.1411  loss_box_reg: 0.134  loss_rpn_cls: 6.805e-05  loss_rpn_loc: 0.001698    time: 2.5511  last_time: 2.2814  data_time: 1.5363  last_data_time: 1.3400   lr: 0.00099996  max_mem: 4120M\n",
      "\u001b[32m[09/06 17:45:33 d2.utils.events]: \u001b[0m eta: 17 days, 0:07:36  iter: 2359  total_loss: 0.2513  loss_cls: 0.1187  loss_box_reg: 0.1429  loss_rpn_cls: 8.073e-05  loss_rpn_loc: 0.001774    time: 2.5524  last_time: 2.7534  data_time: 1.6403  last_data_time: 1.7596   lr: 0.00099996  max_mem: 4120M\n",
      "\u001b[32m[09/06 17:46:28 d2.utils.events]: \u001b[0m eta: 17 days, 1:07:38  iter: 2379  total_loss: 0.255  loss_cls: 0.1243  loss_box_reg: 0.1255  loss_rpn_cls: 9.684e-05  loss_rpn_loc: 0.001666    time: 2.5557  last_time: 2.7205  data_time: 1.7533  last_data_time: 1.7083   lr: 0.00099996  max_mem: 4120M\n",
      "\u001b[32m[09/06 17:47:19 d2.utils.events]: \u001b[0m eta: 17 days, 1:23:29  iter: 2399  total_loss: 0.2572  loss_cls: 0.1174  loss_box_reg: 0.1404  loss_rpn_cls: 4.808e-05  loss_rpn_loc: 0.001811    time: 2.5555  last_time: 3.3722  data_time: 1.5929  last_data_time: 2.2985   lr: 0.00099996  max_mem: 4120M\n",
      "\u001b[32m[09/06 17:48:12 d2.utils.events]: \u001b[0m eta: 17 days, 1:22:40  iter: 2419  total_loss: 0.2584  loss_cls: 0.1263  loss_box_reg: 0.1232  loss_rpn_cls: 0.0001245  loss_rpn_loc: 0.001717    time: 2.5564  last_time: 2.4059  data_time: 1.6618  last_data_time: 1.4765   lr: 0.00099996  max_mem: 4120M\n",
      "\u001b[32m[09/06 17:49:07 d2.utils.events]: \u001b[0m eta: 17 days, 1:50:52  iter: 2439  total_loss: 0.2661  loss_cls: 0.1187  loss_box_reg: 0.1327  loss_rpn_cls: 0.0001136  loss_rpn_loc: 0.001715    time: 2.5590  last_time: 2.4966  data_time: 1.7120  last_data_time: 1.5348   lr: 0.00099996  max_mem: 4120M\n",
      "\u001b[32m[09/06 17:50:01 d2.utils.events]: \u001b[0m eta: 17 days, 2:34:01  iter: 2459  total_loss: 0.2681  loss_cls: 0.1156  loss_box_reg: 0.1416  loss_rpn_cls: 5.579e-05  loss_rpn_loc: 0.001713    time: 2.5608  last_time: 2.5459  data_time: 1.6817  last_data_time: 1.5726   lr: 0.00099996  max_mem: 4120M\n",
      "\u001b[32m[09/06 17:50:50 d2.utils.events]: \u001b[0m eta: 17 days, 3:08:50  iter: 2479  total_loss: 0.2503  loss_cls: 0.0979  loss_box_reg: 0.1374  loss_rpn_cls: 9.403e-05  loss_rpn_loc: 0.00162    time: 2.5600  last_time: 2.9337  data_time: 1.5293  last_data_time: 1.9330   lr: 0.00099996  max_mem: 4120M\n",
      "\u001b[32m[09/06 17:51:43 d2.utils.events]: \u001b[0m eta: 17 days, 3:12:57  iter: 2499  total_loss: 0.2657  loss_cls: 0.1346  loss_box_reg: 0.142  loss_rpn_cls: 0.000116  loss_rpn_loc: 0.001643    time: 2.5594  last_time: 2.3556  data_time: 1.5589  last_data_time: 1.3788   lr: 0.00099996  max_mem: 4120M\n",
      "\u001b[32m[09/06 17:52:33 d2.utils.events]: \u001b[0m eta: 17 days, 3:21:57  iter: 2519  total_loss: 0.255  loss_cls: 0.1006  loss_box_reg: 0.1349  loss_rpn_cls: 5.336e-05  loss_rpn_loc: 0.001695    time: 2.5585  last_time: 2.3735  data_time: 1.5353  last_data_time: 1.4045   lr: 0.00099996  max_mem: 4120M\n",
      "\u001b[32m[09/06 17:53:19 d2.utils.events]: \u001b[0m eta: 17 days, 3:24:47  iter: 2539  total_loss: 0.2386  loss_cls: 0.1127  loss_box_reg: 0.1249  loss_rpn_cls: 6.069e-05  loss_rpn_loc: 0.001745    time: 2.5555  last_time: 2.3843  data_time: 1.4468  last_data_time: 1.5379   lr: 0.00099996  max_mem: 4120M\n",
      "\u001b[32m[09/06 17:54:07 d2.utils.events]: \u001b[0m eta: 17 days, 3:17:21  iter: 2559  total_loss: 0.2579  loss_cls: 0.1232  loss_box_reg: 0.1298  loss_rpn_cls: 7.643e-05  loss_rpn_loc: 0.001668    time: 2.5532  last_time: 2.0405  data_time: 1.4751  last_data_time: 1.1854   lr: 0.00099996  max_mem: 4120M\n",
      "\u001b[32m[09/06 17:54:52 d2.utils.events]: \u001b[0m eta: 17 days, 3:09:39  iter: 2579  total_loss: 0.2665  loss_cls: 0.1323  loss_box_reg: 0.1347  loss_rpn_cls: 0.0001318  loss_rpn_loc: 0.001785    time: 2.5494  last_time: 3.2279  data_time: 1.4131  last_data_time: 2.1921   lr: 0.00099995  max_mem: 4120M\n",
      "\u001b[32m[09/06 17:55:39 d2.utils.events]: \u001b[0m eta: 17 days, 1:46:23  iter: 2599  total_loss: 0.2418  loss_cls: 0.1075  loss_box_reg: 0.1285  loss_rpn_cls: 9.509e-05  loss_rpn_loc: 0.001483    time: 2.5467  last_time: 3.1836  data_time: 1.4805  last_data_time: 2.2341   lr: 0.00099995  max_mem: 4120M\n",
      "\u001b[32m[09/06 17:56:24 d2.utils.events]: \u001b[0m eta: 17 days, 1:20:04  iter: 2619  total_loss: 0.2746  loss_cls: 0.1245  loss_box_reg: 0.1389  loss_rpn_cls: 5.5e-05  loss_rpn_loc: 0.00194    time: 2.5431  last_time: 2.2152  data_time: 1.3947  last_data_time: 1.3258   lr: 0.00099995  max_mem: 4120M\n",
      "\u001b[32m[09/06 17:57:08 d2.utils.events]: \u001b[0m eta: 17 days, 0:44:09  iter: 2639  total_loss: 0.256  loss_cls: 0.1165  loss_box_reg: 0.1289  loss_rpn_cls: 7.943e-05  loss_rpn_loc: 0.001655    time: 2.5392  last_time: 2.0863  data_time: 1.3694  last_data_time: 1.2200   lr: 0.00099995  max_mem: 4120M\n",
      "\u001b[32m[09/06 17:57:54 d2.utils.events]: \u001b[0m eta: 17 days, 0:22:28  iter: 2659  total_loss: 0.267  loss_cls: 0.1142  loss_box_reg: 0.1423  loss_rpn_cls: 7.303e-05  loss_rpn_loc: 0.001863    time: 2.5359  last_time: 2.2474  data_time: 1.4277  last_data_time: 1.3856   lr: 0.00099995  max_mem: 4120M\n",
      "\u001b[32m[09/06 17:58:45 d2.utils.events]: \u001b[0m eta: 16 days, 23:00:33  iter: 2679  total_loss: 0.2628  loss_cls: 0.1291  loss_box_reg: 0.1244  loss_rpn_cls: 7.84e-05  loss_rpn_loc: 0.001692    time: 2.5361  last_time: 3.3301  data_time: 1.6433  last_data_time: 2.3236   lr: 0.00099995  max_mem: 4120M\n",
      "\u001b[32m[09/06 17:59:33 d2.utils.events]: \u001b[0m eta: 16 days, 22:21:34  iter: 2699  total_loss: 0.27  loss_cls: 0.1185  loss_box_reg: 0.1405  loss_rpn_cls: 8.482e-05  loss_rpn_loc: 0.001572    time: 2.5346  last_time: 2.5000  data_time: 1.5062  last_data_time: 1.6460   lr: 0.00099995  max_mem: 4120M\n",
      "\u001b[32m[09/06 18:00:19 d2.utils.events]: \u001b[0m eta: 16 days, 22:11:16  iter: 2719  total_loss: 0.2574  loss_cls: 0.1204  loss_box_reg: 0.1329  loss_rpn_cls: 7.259e-05  loss_rpn_loc: 0.001784    time: 2.5320  last_time: 2.2778  data_time: 1.4426  last_data_time: 1.4414   lr: 0.00099995  max_mem: 4120M\n",
      "\u001b[32m[09/06 18:01:05 d2.utils.events]: \u001b[0m eta: 16 days, 20:52:46  iter: 2739  total_loss: 0.2612  loss_cls: 0.1304  loss_box_reg: 0.124  loss_rpn_cls: 8.549e-05  loss_rpn_loc: 0.001513    time: 2.5292  last_time: 2.4386  data_time: 1.4422  last_data_time: 1.5518   lr: 0.00099995  max_mem: 4120M\n",
      "\u001b[32m[09/06 18:01:51 d2.utils.events]: \u001b[0m eta: 16 days, 19:36:27  iter: 2759  total_loss: 0.2519  loss_cls: 0.1217  loss_box_reg: 0.1276  loss_rpn_cls: 5.971e-05  loss_rpn_loc: 0.001579    time: 2.5266  last_time: 1.9383  data_time: 1.4468  last_data_time: 1.1245   lr: 0.00099995  max_mem: 4120M\n",
      "\u001b[32m[09/06 18:02:37 d2.utils.events]: \u001b[0m eta: 16 days, 19:29:03  iter: 2779  total_loss: 0.2406  loss_cls: 0.108  loss_box_reg: 0.1319  loss_rpn_cls: 6.649e-05  loss_rpn_loc: 0.001607    time: 2.5243  last_time: 2.0254  data_time: 1.4743  last_data_time: 1.1970   lr: 0.00099995  max_mem: 4120M\n",
      "\u001b[32m[09/06 18:03:23 d2.utils.events]: \u001b[0m eta: 16 days, 18:40:37  iter: 2799  total_loss: 0.2638  loss_cls: 0.1176  loss_box_reg: 0.1354  loss_rpn_cls: 5.654e-05  loss_rpn_loc: 0.001711    time: 2.5218  last_time: 2.3727  data_time: 1.4526  last_data_time: 1.5320   lr: 0.00099995  max_mem: 4120M\n",
      "\u001b[32m[09/06 18:04:09 d2.utils.events]: \u001b[0m eta: 16 days, 17:50:45  iter: 2819  total_loss: 0.235  loss_cls: 0.09194  loss_box_reg: 0.1404  loss_rpn_cls: 6.851e-05  loss_rpn_loc: 0.001697    time: 2.5193  last_time: 2.4698  data_time: 1.4191  last_data_time: 1.5467   lr: 0.00099995  max_mem: 4120M\n",
      "\u001b[32m[09/06 18:04:57 d2.utils.events]: \u001b[0m eta: 16 days, 16:38:16  iter: 2839  total_loss: 0.2573  loss_cls: 0.1275  loss_box_reg: 0.1269  loss_rpn_cls: 7.111e-05  loss_rpn_loc: 0.001749    time: 2.5178  last_time: 2.3945  data_time: 1.4873  last_data_time: 1.5791   lr: 0.00099994  max_mem: 4120M\n",
      "\u001b[32m[09/06 18:05:48 d2.utils.events]: \u001b[0m eta: 16 days, 16:27:51  iter: 2859  total_loss: 0.2679  loss_cls: 0.1329  loss_box_reg: 0.1323  loss_rpn_cls: 4.741e-05  loss_rpn_loc: 0.001606    time: 2.5182  last_time: 2.6158  data_time: 1.6698  last_data_time: 1.7636   lr: 0.00099994  max_mem: 4120M\n",
      "\u001b[32m[09/06 18:06:35 d2.utils.events]: \u001b[0m eta: 16 days, 16:01:39  iter: 2879  total_loss: 0.229  loss_cls: 0.1072  loss_box_reg: 0.1318  loss_rpn_cls: 9.243e-05  loss_rpn_loc: 0.001541    time: 2.5163  last_time: 2.0396  data_time: 1.4585  last_data_time: 1.1482   lr: 0.00099994  max_mem: 4120M\n",
      "\u001b[32m[09/06 18:07:21 d2.utils.events]: \u001b[0m eta: 16 days, 15:11:38  iter: 2899  total_loss: 0.2263  loss_cls: 0.09391  loss_box_reg: 0.1252  loss_rpn_cls: 5.808e-05  loss_rpn_loc: 0.001589    time: 2.5139  last_time: 2.0864  data_time: 1.4331  last_data_time: 1.2850   lr: 0.00099994  max_mem: 4120M\n",
      "\u001b[32m[09/06 18:08:05 d2.utils.events]: \u001b[0m eta: 16 days, 14:21:53  iter: 2919  total_loss: 0.2505  loss_cls: 0.1155  loss_box_reg: 0.137  loss_rpn_cls: 6.686e-05  loss_rpn_loc: 0.001787    time: 2.5109  last_time: 1.7941  data_time: 1.3817  last_data_time: 0.9959   lr: 0.00099994  max_mem: 4120M\n",
      "\u001b[32m[09/06 18:08:50 d2.utils.events]: \u001b[0m eta: 16 days, 14:07:03  iter: 2939  total_loss: 0.239  loss_cls: 0.1051  loss_box_reg: 0.1331  loss_rpn_cls: 5.946e-05  loss_rpn_loc: 0.001703    time: 2.5080  last_time: 2.2997  data_time: 1.3765  last_data_time: 1.5262   lr: 0.00099994  max_mem: 4120M\n",
      "\u001b[32m[09/06 18:09:36 d2.utils.events]: \u001b[0m eta: 16 days, 13:37:10  iter: 2959  total_loss: 0.2391  loss_cls: 0.11  loss_box_reg: 0.1285  loss_rpn_cls: 6.306e-05  loss_rpn_loc: 0.001562    time: 2.5057  last_time: 2.1342  data_time: 1.4413  last_data_time: 1.2662   lr: 0.00099994  max_mem: 4120M\n",
      "\u001b[32m[09/06 18:10:20 d2.utils.events]: \u001b[0m eta: 16 days, 13:01:36  iter: 2979  total_loss: 0.2428  loss_cls: 0.1044  loss_box_reg: 0.1272  loss_rpn_cls: 9.456e-05  loss_rpn_loc: 0.001564    time: 2.5027  last_time: 2.2178  data_time: 1.3594  last_data_time: 1.3429   lr: 0.00099994  max_mem: 4120M\n",
      "\u001b[32m[09/06 18:11:07 d2.data.datasets.coco]: \u001b[0mLoaded 1199 images in COCO format from data/ssd_rcnn_face/annotations_val.json\n",
      "\u001b[32m[09/06 18:11:07 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(512, 512), max_size=512, sample_style='choice')]\n",
      "\u001b[32m[09/06 18:11:07 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[09/06 18:11:07 d2.data.common]: \u001b[0mSerializing 1199 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[09/06 18:11:07 d2.data.common]: \u001b[0mSerialized dataset takes 0.36 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[09/06 18:11:07 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n",
      "\u001b[32m[09/06 18:11:07 d2.evaluation.evaluator]: \u001b[0mStart inference on 1199 batches\n",
      "\u001b[32m[09/06 18:11:09 d2.evaluation.evaluator]: \u001b[0mInference done 11/1199. Dataloading: 0.0460 s/iter. Inference: 0.0611 s/iter. Eval: 0.0004 s/iter. Total: 0.1075 s/iter. ETA=0:02:07\n",
      "\u001b[32m[09/06 18:11:14 d2.evaluation.evaluator]: \u001b[0mInference done 50/1199. Dataloading: 0.0697 s/iter. Inference: 0.0575 s/iter. Eval: 0.0004 s/iter. Total: 0.1277 s/iter. ETA=0:02:26\n",
      "\u001b[32m[09/06 18:11:20 d2.evaluation.evaluator]: \u001b[0mInference done 85/1199. Dataloading: 0.0907 s/iter. Inference: 0.0544 s/iter. Eval: 0.0004 s/iter. Total: 0.1456 s/iter. ETA=0:02:42\n",
      "\u001b[32m[09/06 18:11:25 d2.evaluation.evaluator]: \u001b[0mInference done 119/1199. Dataloading: 0.0905 s/iter. Inference: 0.0562 s/iter. Eval: 0.0004 s/iter. Total: 0.1472 s/iter. ETA=0:02:38\n",
      "\u001b[32m[09/06 18:11:30 d2.evaluation.evaluator]: \u001b[0mInference done 159/1199. Dataloading: 0.0861 s/iter. Inference: 0.0567 s/iter. Eval: 0.0004 s/iter. Total: 0.1433 s/iter. ETA=0:02:29\n",
      "\u001b[32m[09/06 18:11:35 d2.evaluation.evaluator]: \u001b[0mInference done 195/1199. Dataloading: 0.0854 s/iter. Inference: 0.0572 s/iter. Eval: 0.0004 s/iter. Total: 0.1432 s/iter. ETA=0:02:23\n",
      "\u001b[32m[09/06 18:11:40 d2.evaluation.evaluator]: \u001b[0mInference done 229/1199. Dataloading: 0.0864 s/iter. Inference: 0.0574 s/iter. Eval: 0.0004 s/iter. Total: 0.1443 s/iter. ETA=0:02:19\n",
      "\u001b[32m[09/06 18:11:45 d2.evaluation.evaluator]: \u001b[0mInference done 263/1199. Dataloading: 0.0866 s/iter. Inference: 0.0577 s/iter. Eval: 0.0004 s/iter. Total: 0.1448 s/iter. ETA=0:02:15\n",
      "\u001b[32m[09/06 18:11:51 d2.evaluation.evaluator]: \u001b[0mInference done 282/1199. Dataloading: 0.0953 s/iter. Inference: 0.0583 s/iter. Eval: 0.0004 s/iter. Total: 0.1541 s/iter. ETA=0:02:21\n",
      "\u001b[32m[09/06 18:11:56 d2.evaluation.evaluator]: \u001b[0mInference done 319/1199. Dataloading: 0.0934 s/iter. Inference: 0.0585 s/iter. Eval: 0.0004 s/iter. Total: 0.1524 s/iter. ETA=0:02:14\n",
      "\u001b[32m[09/06 18:12:01 d2.evaluation.evaluator]: \u001b[0mInference done 355/1199. Dataloading: 0.0917 s/iter. Inference: 0.0588 s/iter. Eval: 0.0004 s/iter. Total: 0.1510 s/iter. ETA=0:02:07\n",
      "\u001b[32m[09/06 18:12:06 d2.evaluation.evaluator]: \u001b[0mInference done 388/1199. Dataloading: 0.0921 s/iter. Inference: 0.0588 s/iter. Eval: 0.0004 s/iter. Total: 0.1514 s/iter. ETA=0:02:02\n",
      "\u001b[32m[09/06 18:12:11 d2.evaluation.evaluator]: \u001b[0mInference done 426/1199. Dataloading: 0.0908 s/iter. Inference: 0.0586 s/iter. Eval: 0.0004 s/iter. Total: 0.1499 s/iter. ETA=0:01:55\n",
      "\u001b[32m[09/06 18:12:16 d2.evaluation.evaluator]: \u001b[0mInference done 466/1199. Dataloading: 0.0886 s/iter. Inference: 0.0586 s/iter. Eval: 0.0004 s/iter. Total: 0.1478 s/iter. ETA=0:01:48\n",
      "\u001b[32m[09/06 18:12:21 d2.evaluation.evaluator]: \u001b[0mInference done 504/1199. Dataloading: 0.0878 s/iter. Inference: 0.0587 s/iter. Eval: 0.0004 s/iter. Total: 0.1470 s/iter. ETA=0:01:42\n",
      "\u001b[32m[09/06 18:12:26 d2.evaluation.evaluator]: \u001b[0mInference done 542/1199. Dataloading: 0.0875 s/iter. Inference: 0.0583 s/iter. Eval: 0.0004 s/iter. Total: 0.1463 s/iter. ETA=0:01:36\n",
      "\u001b[32m[09/06 18:12:32 d2.evaluation.evaluator]: \u001b[0mInference done 581/1199. Dataloading: 0.0865 s/iter. Inference: 0.0581 s/iter. Eval: 0.0004 s/iter. Total: 0.1451 s/iter. ETA=0:01:29\n",
      "\u001b[32m[09/06 18:12:37 d2.evaluation.evaluator]: \u001b[0mInference done 620/1199. Dataloading: 0.0857 s/iter. Inference: 0.0580 s/iter. Eval: 0.0004 s/iter. Total: 0.1442 s/iter. ETA=0:01:23\n",
      "\u001b[32m[09/06 18:12:42 d2.evaluation.evaluator]: \u001b[0mInference done 649/1199. Dataloading: 0.0873 s/iter. Inference: 0.0578 s/iter. Eval: 0.0004 s/iter. Total: 0.1457 s/iter. ETA=0:01:20\n",
      "\u001b[32m[09/06 18:12:47 d2.evaluation.evaluator]: \u001b[0mInference done 685/1199. Dataloading: 0.0870 s/iter. Inference: 0.0579 s/iter. Eval: 0.0004 s/iter. Total: 0.1453 s/iter. ETA=0:01:14\n",
      "\u001b[32m[09/06 18:12:52 d2.evaluation.evaluator]: \u001b[0mInference done 724/1199. Dataloading: 0.0865 s/iter. Inference: 0.0579 s/iter. Eval: 0.0004 s/iter. Total: 0.1448 s/iter. ETA=0:01:08\n",
      "\u001b[32m[09/06 18:12:58 d2.evaluation.evaluator]: \u001b[0mInference done 752/1199. Dataloading: 0.0882 s/iter. Inference: 0.0580 s/iter. Eval: 0.0004 s/iter. Total: 0.1467 s/iter. ETA=0:01:05\n",
      "\u001b[32m[09/06 18:13:03 d2.evaluation.evaluator]: \u001b[0mInference done 785/1199. Dataloading: 0.0885 s/iter. Inference: 0.0580 s/iter. Eval: 0.0004 s/iter. Total: 0.1469 s/iter. ETA=0:01:00\n",
      "\u001b[32m[09/06 18:13:08 d2.evaluation.evaluator]: \u001b[0mInference done 827/1199. Dataloading: 0.0871 s/iter. Inference: 0.0579 s/iter. Eval: 0.0004 s/iter. Total: 0.1455 s/iter. ETA=0:00:54\n",
      "\u001b[32m[09/06 18:13:13 d2.evaluation.evaluator]: \u001b[0mInference done 867/1199. Dataloading: 0.0864 s/iter. Inference: 0.0579 s/iter. Eval: 0.0004 s/iter. Total: 0.1448 s/iter. ETA=0:00:48\n",
      "\u001b[32m[09/06 18:13:18 d2.evaluation.evaluator]: \u001b[0mInference done 901/1199. Dataloading: 0.0866 s/iter. Inference: 0.0579 s/iter. Eval: 0.0004 s/iter. Total: 0.1450 s/iter. ETA=0:00:43\n",
      "\u001b[32m[09/06 18:13:23 d2.evaluation.evaluator]: \u001b[0mInference done 941/1199. Dataloading: 0.0859 s/iter. Inference: 0.0578 s/iter. Eval: 0.0004 s/iter. Total: 0.1442 s/iter. ETA=0:00:37\n",
      "\u001b[32m[09/06 18:13:28 d2.evaluation.evaluator]: \u001b[0mInference done 975/1199. Dataloading: 0.0861 s/iter. Inference: 0.0578 s/iter. Eval: 0.0004 s/iter. Total: 0.1444 s/iter. ETA=0:00:32\n",
      "\u001b[32m[09/06 18:13:33 d2.evaluation.evaluator]: \u001b[0mInference done 1011/1199. Dataloading: 0.0861 s/iter. Inference: 0.0576 s/iter. Eval: 0.0004 s/iter. Total: 0.1442 s/iter. ETA=0:00:27\n",
      "\u001b[32m[09/06 18:13:38 d2.evaluation.evaluator]: \u001b[0mInference done 1044/1199. Dataloading: 0.0864 s/iter. Inference: 0.0577 s/iter. Eval: 0.0004 s/iter. Total: 0.1445 s/iter. ETA=0:00:22\n",
      "\u001b[32m[09/06 18:13:43 d2.evaluation.evaluator]: \u001b[0mInference done 1077/1199. Dataloading: 0.0866 s/iter. Inference: 0.0577 s/iter. Eval: 0.0004 s/iter. Total: 0.1448 s/iter. ETA=0:00:17\n",
      "\u001b[32m[09/06 18:13:48 d2.evaluation.evaluator]: \u001b[0mInference done 1113/1199. Dataloading: 0.0864 s/iter. Inference: 0.0577 s/iter. Eval: 0.0004 s/iter. Total: 0.1446 s/iter. ETA=0:00:12\n",
      "\u001b[32m[09/06 18:13:53 d2.evaluation.evaluator]: \u001b[0mInference done 1144/1199. Dataloading: 0.0870 s/iter. Inference: 0.0577 s/iter. Eval: 0.0004 s/iter. Total: 0.1452 s/iter. ETA=0:00:07\n",
      "\u001b[32m[09/06 18:13:58 d2.evaluation.evaluator]: \u001b[0mInference done 1182/1199. Dataloading: 0.0865 s/iter. Inference: 0.0579 s/iter. Eval: 0.0004 s/iter. Total: 0.1448 s/iter. ETA=0:00:02\n",
      "\u001b[32m[09/06 18:14:01 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:02:52.983720 (0.144877 s / iter per device, on 1 devices)\n",
      "\u001b[32m[09/06 18:14:01 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:01:09 (0.057845 s / iter per device, on 1 devices)\n",
      "\u001b[32m[09/06 18:14:01 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[09/06 18:14:01 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.02s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[09/06 18:14:01 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[09/06 18:14:01 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.16 seconds.\n",
      "\u001b[32m[09/06 18:14:01 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[09/06 18:14:01 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.02 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.720\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.851\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.845\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.720\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.872\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.872\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.872\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.872\n",
      "\u001b[32m[09/06 18:14:01 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
      "| 72.017 | 85.150 | 84.494 |  nan  |  nan  | 72.017 |\n",
      "\u001b[32m[09/06 18:14:01 d2.evaluation.coco_evaluation]: \u001b[0mSome metrics cannot be computed and is shown as NaN.\n",
      "\u001b[32m[09/06 18:14:01 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category   | AP     | category   | AP     | category   | AP     |\n",
      "|:-----------|:-------|:-----------|:-------|:-----------|:-------|\n",
      "| angry      | 65.174 | sad        | 72.085 | surprised  | 68.285 |\n",
      "| happy      | 82.523 |            |        |            |        |\n",
      "\u001b[32m[09/06 18:14:01 d2.engine.defaults]: \u001b[0mEvaluation results for face_data_set_valid in csv format:\n",
      "\u001b[32m[09/06 18:14:01 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[09/06 18:14:01 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[09/06 18:14:01 d2.evaluation.testing]: \u001b[0mcopypaste: 72.0169,85.1496,84.4944,nan,nan,72.0169\n",
      "\u001b[32m[09/06 18:14:01 d2.utils.events]: \u001b[0m eta: 16 days, 11:22:59  iter: 2999  total_loss: 0.2511  loss_cls: 0.1153  loss_box_reg: 0.1258  loss_rpn_cls: 6.886e-05  loss_rpn_loc: 0.001636    time: 2.5001  last_time: 2.4595  data_time: 1.4058  last_data_time: 1.7018   lr: 0.00099994  max_mem: 4120M\n",
      "\u001b[32m[09/06 18:14:47 d2.utils.events]: \u001b[0m eta: 16 days, 11:04:05  iter: 3019  total_loss: 0.2316  loss_cls: 0.1084  loss_box_reg: 0.1249  loss_rpn_cls: 5.931e-05  loss_rpn_loc: 0.001797    time: 2.4980  last_time: 2.9914  data_time: 1.4248  last_data_time: 1.9582   lr: 0.00099994  max_mem: 4120M\n",
      "\u001b[32m[09/06 18:15:32 d2.utils.events]: \u001b[0m eta: 16 days, 10:25:28  iter: 3039  total_loss: 0.2454  loss_cls: 0.1154  loss_box_reg: 0.1277  loss_rpn_cls: 7.659e-05  loss_rpn_loc: 0.001575    time: 2.4959  last_time: 2.1759  data_time: 1.4241  last_data_time: 1.3261   lr: 0.00099994  max_mem: 4120M\n",
      "\u001b[32m[09/06 18:16:19 d2.utils.events]: \u001b[0m eta: 16 days, 8:00:42  iter: 3059  total_loss: 0.246  loss_cls: 0.1088  loss_box_reg: 0.1427  loss_rpn_cls: 8.775e-05  loss_rpn_loc: 0.001719    time: 2.4941  last_time: 2.0991  data_time: 1.4678  last_data_time: 1.3042   lr: 0.00099994  max_mem: 4120M\n",
      "\u001b[32m[09/06 18:17:04 d2.utils.events]: \u001b[0m eta: 16 days, 6:41:44  iter: 3079  total_loss: 0.2279  loss_cls: 0.0954  loss_box_reg: 0.1278  loss_rpn_cls: 7.223e-05  loss_rpn_loc: 0.001591    time: 2.4919  last_time: 2.0904  data_time: 1.4172  last_data_time: 1.2535   lr: 0.00099994  max_mem: 4120M\n",
      "\u001b[32m[09/06 18:17:51 d2.utils.events]: \u001b[0m eta: 16 days, 5:52:47  iter: 3099  total_loss: 0.2391  loss_cls: 0.1143  loss_box_reg: 0.1259  loss_rpn_cls: 6.177e-05  loss_rpn_loc: 0.001597    time: 2.4904  last_time: 2.2239  data_time: 1.4615  last_data_time: 1.3726   lr: 0.00099993  max_mem: 4120M\n",
      "\u001b[32m[09/06 18:18:36 d2.utils.events]: \u001b[0m eta: 16 days, 4:56:15  iter: 3119  total_loss: 0.2525  loss_cls: 0.1206  loss_box_reg: 0.1332  loss_rpn_cls: 6.275e-05  loss_rpn_loc: 0.001444    time: 2.4882  last_time: 2.2597  data_time: 1.4250  last_data_time: 1.4918   lr: 0.00099993  max_mem: 4120M\n",
      "\u001b[32m[09/06 18:19:20 d2.utils.events]: \u001b[0m eta: 16 days, 3:42:16  iter: 3139  total_loss: 0.257  loss_cls: 0.1226  loss_box_reg: 0.1347  loss_rpn_cls: 0.000113  loss_rpn_loc: 0.00173    time: 2.4854  last_time: 2.0256  data_time: 1.3294  last_data_time: 1.2348   lr: 0.00099993  max_mem: 4120M\n",
      "\u001b[32m[09/06 18:20:04 d2.utils.events]: \u001b[0m eta: 16 days, 2:41:07  iter: 3159  total_loss: 0.2406  loss_cls: 0.103  loss_box_reg: 0.1314  loss_rpn_cls: 6.477e-05  loss_rpn_loc: 0.001674    time: 2.4830  last_time: 2.3306  data_time: 1.3827  last_data_time: 1.5029   lr: 0.00099993  max_mem: 4120M\n",
      "\u001b[32m[09/06 18:20:52 d2.utils.events]: \u001b[0m eta: 16 days, 2:11:42  iter: 3179  total_loss: 0.252  loss_cls: 0.1091  loss_box_reg: 0.1306  loss_rpn_cls: 6.377e-05  loss_rpn_loc: 0.001698    time: 2.4823  last_time: 2.0813  data_time: 1.5123  last_data_time: 1.2596   lr: 0.00099993  max_mem: 4120M\n",
      "\u001b[32m[09/06 18:21:48 d2.utils.events]: \u001b[0m eta: 16 days, 2:10:55  iter: 3199  total_loss: 0.2333  loss_cls: 0.1069  loss_box_reg: 0.1236  loss_rpn_cls: 6.313e-05  loss_rpn_loc: 0.001676    time: 2.4848  last_time: 2.7644  data_time: 1.7875  last_data_time: 1.8667   lr: 0.00099993  max_mem: 4120M\n",
      "\u001b[32m[09/06 18:22:40 d2.utils.events]: \u001b[0m eta: 16 days, 2:24:25  iter: 3219  total_loss: 0.2356  loss_cls: 0.1049  loss_box_reg: 0.129  loss_rpn_cls: 6.858e-05  loss_rpn_loc: 0.001498    time: 2.4860  last_time: 2.6536  data_time: 1.6441  last_data_time: 1.6848   lr: 0.00099993  max_mem: 4120M\n",
      "\u001b[32m[09/06 18:23:36 d2.utils.events]: \u001b[0m eta: 16 days, 3:04:08  iter: 3239  total_loss: 0.2365  loss_cls: 0.112  loss_box_reg: 0.1227  loss_rpn_cls: 5.76e-05  loss_rpn_loc: 0.001679    time: 2.4890  last_time: 3.0669  data_time: 1.8255  last_data_time: 2.0255   lr: 0.00099993  max_mem: 4120M\n",
      "\u001b[32m[09/06 18:24:31 d2.utils.events]: \u001b[0m eta: 16 days, 3:30:08  iter: 3259  total_loss: 0.2302  loss_cls: 0.08849  loss_box_reg: 0.1379  loss_rpn_cls: 8.815e-05  loss_rpn_loc: 0.001563    time: 2.4913  last_time: 2.5143  data_time: 1.7703  last_data_time: 1.5934   lr: 0.00099993  max_mem: 4120M\n",
      "\u001b[32m[09/06 18:25:25 d2.utils.events]: \u001b[0m eta: 16 days, 4:25:01  iter: 3279  total_loss: 0.2323  loss_cls: 0.09741  loss_box_reg: 0.131  loss_rpn_cls: 8.504e-05  loss_rpn_loc: 0.001773    time: 2.4929  last_time: 2.8481  data_time: 1.6949  last_data_time: 1.7876   lr: 0.00099993  max_mem: 4120M\n",
      "\u001b[32m[09/06 18:26:15 d2.utils.events]: \u001b[0m eta: 16 days, 4:19:09  iter: 3299  total_loss: 0.2124  loss_cls: 0.07986  loss_box_reg: 0.1289  loss_rpn_cls: 9.903e-05  loss_rpn_loc: 0.001571    time: 2.4930  last_time: 2.0742  data_time: 1.5228  last_data_time: 1.1608   lr: 0.00099993  max_mem: 4120M\n",
      "\u001b[32m[09/06 18:27:02 d2.utils.events]: \u001b[0m eta: 16 days, 2:46:05  iter: 3319  total_loss: 0.2419  loss_cls: 0.1083  loss_box_reg: 0.1316  loss_rpn_cls: 9.153e-05  loss_rpn_loc: 0.001594    time: 2.4918  last_time: 2.1972  data_time: 1.4589  last_data_time: 1.3046   lr: 0.00099992  max_mem: 4120M\n",
      "\u001b[32m[09/06 18:27:46 d2.utils.events]: \u001b[0m eta: 16 days, 2:05:29  iter: 3339  total_loss: 0.2195  loss_cls: 0.09356  loss_box_reg: 0.1211  loss_rpn_cls: 5.664e-05  loss_rpn_loc: 0.001461    time: 2.4892  last_time: 1.9935  data_time: 1.3194  last_data_time: 1.1577   lr: 0.00099992  max_mem: 4120M\n",
      "\u001b[32m[09/06 18:28:32 d2.utils.events]: \u001b[0m eta: 16 days, 1:10:14  iter: 3359  total_loss: 0.2438  loss_cls: 0.1053  loss_box_reg: 0.1294  loss_rpn_cls: 6.649e-05  loss_rpn_loc: 0.001749    time: 2.4878  last_time: 2.0327  data_time: 1.4308  last_data_time: 1.1306   lr: 0.00099992  max_mem: 4120M\n",
      "\u001b[32m[09/06 18:29:17 d2.utils.events]: \u001b[0m eta: 15 days, 23:29:49  iter: 3379  total_loss: 0.2321  loss_cls: 0.09968  loss_box_reg: 0.1267  loss_rpn_cls: 3.592e-05  loss_rpn_loc: 0.001547    time: 2.4857  last_time: 2.0644  data_time: 1.3560  last_data_time: 1.0730   lr: 0.00099992  max_mem: 4120M\n",
      "\u001b[32m[09/06 18:30:05 d2.utils.events]: \u001b[0m eta: 15 days, 23:01:25  iter: 3399  total_loss: 0.2336  loss_cls: 0.09855  loss_box_reg: 0.1199  loss_rpn_cls: 7.451e-05  loss_rpn_loc: 0.00158    time: 2.4851  last_time: 2.1360  data_time: 1.5205  last_data_time: 1.2564   lr: 0.00099992  max_mem: 4120M\n",
      "\u001b[32m[09/06 18:30:50 d2.utils.events]: \u001b[0m eta: 15 days, 22:00:08  iter: 3419  total_loss: 0.2369  loss_cls: 0.1048  loss_box_reg: 0.124  loss_rpn_cls: 6.85e-05  loss_rpn_loc: 0.001473    time: 2.4830  last_time: 2.3437  data_time: 1.3439  last_data_time: 1.3861   lr: 0.00099992  max_mem: 4120M\n",
      "\u001b[32m[09/06 18:31:38 d2.utils.events]: \u001b[0m eta: 15 days, 21:27:30  iter: 3439  total_loss: 0.222  loss_cls: 0.09217  loss_box_reg: 0.1254  loss_rpn_cls: 7.472e-05  loss_rpn_loc: 0.001542    time: 2.4821  last_time: 2.3594  data_time: 1.4725  last_data_time: 1.4306   lr: 0.00099992  max_mem: 4120M\n",
      "\u001b[32m[09/06 18:32:25 d2.utils.events]: \u001b[0m eta: 15 days, 20:36:39  iter: 3459  total_loss: 0.2153  loss_cls: 0.08946  loss_box_reg: 0.1232  loss_rpn_cls: 6.278e-05  loss_rpn_loc: 0.001526    time: 2.4812  last_time: 1.9604  data_time: 1.4759  last_data_time: 1.1561   lr: 0.00099992  max_mem: 4120M\n",
      "\u001b[32m[09/06 18:33:13 d2.utils.events]: \u001b[0m eta: 15 days, 20:11:36  iter: 3479  total_loss: 0.2294  loss_cls: 0.1006  loss_box_reg: 0.1259  loss_rpn_cls: 4.045e-05  loss_rpn_loc: 0.00164    time: 2.4807  last_time: 2.4855  data_time: 1.5453  last_data_time: 1.6274   lr: 0.00099992  max_mem: 4120M\n",
      "\u001b[32m[09/06 18:34:03 d2.utils.events]: \u001b[0m eta: 15 days, 19:43:20  iter: 3499  total_loss: 0.2387  loss_cls: 0.1011  loss_box_reg: 0.1257  loss_rpn_cls: 6.439e-05  loss_rpn_loc: 0.001621    time: 2.4797  last_time: 2.3021  data_time: 1.4651  last_data_time: 1.3972   lr: 0.00099992  max_mem: 4120M\n",
      "\u001b[32m[09/06 18:34:49 d2.utils.events]: \u001b[0m eta: 15 days, 18:39:09  iter: 3519  total_loss: 0.2473  loss_cls: 0.1184  loss_box_reg: 0.1257  loss_rpn_cls: 7.443e-05  loss_rpn_loc: 0.001688    time: 2.4784  last_time: 2.2259  data_time: 1.4311  last_data_time: 1.3510   lr: 0.00099992  max_mem: 4120M\n",
      "\u001b[32m[09/06 18:35:36 d2.utils.events]: \u001b[0m eta: 15 days, 19:01:53  iter: 3539  total_loss: 0.234  loss_cls: 0.09819  loss_box_reg: 0.1336  loss_rpn_cls: 9.343e-05  loss_rpn_loc: 0.001698    time: 2.4772  last_time: 2.2646  data_time: 1.4432  last_data_time: 1.3117   lr: 0.00099991  max_mem: 4120M\n",
      "\u001b[32m[09/06 18:36:21 d2.utils.events]: \u001b[0m eta: 15 days, 18:37:57  iter: 3559  total_loss: 0.2313  loss_cls: 0.09371  loss_box_reg: 0.1285  loss_rpn_cls: 7.182e-05  loss_rpn_loc: 0.001704    time: 2.4755  last_time: 1.9659  data_time: 1.3648  last_data_time: 1.1468   lr: 0.00099991  max_mem: 4120M\n",
      "\u001b[32m[09/06 18:37:08 d2.utils.events]: \u001b[0m eta: 15 days, 19:13:54  iter: 3579  total_loss: 0.2246  loss_cls: 0.08485  loss_box_reg: 0.1232  loss_rpn_cls: 8.975e-05  loss_rpn_loc: 0.001633    time: 2.4745  last_time: 2.0808  data_time: 1.4679  last_data_time: 1.2579   lr: 0.00099991  max_mem: 4120M\n",
      "\u001b[32m[09/06 18:37:55 d2.utils.events]: \u001b[0m eta: 15 days, 19:13:09  iter: 3599  total_loss: 0.2174  loss_cls: 0.09513  loss_box_reg: 0.1235  loss_rpn_cls: 0.0001039  loss_rpn_loc: 0.001649    time: 2.4736  last_time: 2.2388  data_time: 1.4907  last_data_time: 1.3744   lr: 0.00099991  max_mem: 4120M\n",
      "\u001b[32m[09/06 18:38:44 d2.utils.events]: \u001b[0m eta: 15 days, 20:00:26  iter: 3619  total_loss: 0.2096  loss_cls: 0.07675  loss_box_reg: 0.1254  loss_rpn_cls: 5.795e-05  loss_rpn_loc: 0.001679    time: 2.4733  last_time: 2.2367  data_time: 1.5135  last_data_time: 1.3713   lr: 0.00099991  max_mem: 4120M\n",
      "\u001b[32m[09/06 18:39:30 d2.utils.events]: \u001b[0m eta: 15 days, 19:52:07  iter: 3639  total_loss: 0.2123  loss_cls: 0.08618  loss_box_reg: 0.1267  loss_rpn_cls: 9.296e-05  loss_rpn_loc: 0.001567    time: 2.4721  last_time: 2.2381  data_time: 1.4072  last_data_time: 1.4053   lr: 0.00099991  max_mem: 4120M\n",
      "\u001b[32m[09/06 18:40:18 d2.utils.events]: \u001b[0m eta: 15 days, 19:28:59  iter: 3659  total_loss: 0.2337  loss_cls: 0.1056  loss_box_reg: 0.1259  loss_rpn_cls: 6.502e-05  loss_rpn_loc: 0.001696    time: 2.4716  last_time: 2.3685  data_time: 1.5140  last_data_time: 1.3818   lr: 0.00099991  max_mem: 4120M\n",
      "\u001b[32m[09/06 18:41:04 d2.utils.events]: \u001b[0m eta: 15 days, 19:08:25  iter: 3679  total_loss: 0.2165  loss_cls: 0.07452  loss_box_reg: 0.1246  loss_rpn_cls: 9.745e-05  loss_rpn_loc: 0.001644    time: 2.4703  last_time: 2.3288  data_time: 1.4340  last_data_time: 1.4587   lr: 0.00099991  max_mem: 4120M\n",
      "\u001b[32m[09/06 18:41:52 d2.utils.events]: \u001b[0m eta: 15 days, 18:35:00  iter: 3699  total_loss: 0.2255  loss_cls: 0.08492  loss_box_reg: 0.1337  loss_rpn_cls: 7.857e-05  loss_rpn_loc: 0.001673    time: 2.4697  last_time: 2.1632  data_time: 1.4778  last_data_time: 1.2508   lr: 0.00099991  max_mem: 4120M\n",
      "\u001b[32m[09/06 18:42:41 d2.utils.events]: \u001b[0m eta: 15 days, 19:10:55  iter: 3719  total_loss: 0.2242  loss_cls: 0.08005  loss_box_reg: 0.1255  loss_rpn_cls: 9.361e-05  loss_rpn_loc: 0.001557    time: 2.4696  last_time: 2.3859  data_time: 1.5274  last_data_time: 1.4397   lr: 0.00099991  max_mem: 4120M\n",
      "\u001b[32m[09/06 18:43:30 d2.utils.events]: \u001b[0m eta: 15 days, 19:52:26  iter: 3739  total_loss: 0.2174  loss_cls: 0.08095  loss_box_reg: 0.1178  loss_rpn_cls: 5.191e-05  loss_rpn_loc: 0.001539    time: 2.4696  last_time: 2.2776  data_time: 1.5486  last_data_time: 1.3862   lr: 0.0009999  max_mem: 4120M\n",
      "\u001b[32m[09/06 18:44:19 d2.utils.events]: \u001b[0m eta: 15 days, 20:25:10  iter: 3759  total_loss: 0.2444  loss_cls: 0.09798  loss_box_reg: 0.1259  loss_rpn_cls: 0.0001507  loss_rpn_loc: 0.001574    time: 2.4695  last_time: 2.1560  data_time: 1.5159  last_data_time: 1.2093   lr: 0.0009999  max_mem: 4120M\n",
      "\u001b[32m[09/06 18:45:08 d2.utils.events]: \u001b[0m eta: 15 days, 20:39:41  iter: 3779  total_loss: 0.2362  loss_cls: 0.1018  loss_box_reg: 0.1287  loss_rpn_cls: 5.284e-05  loss_rpn_loc: 0.001801    time: 2.4692  last_time: 2.4744  data_time: 1.5281  last_data_time: 1.5266   lr: 0.0009999  max_mem: 4120M\n",
      "\u001b[32m[09/06 18:45:57 d2.utils.events]: \u001b[0m eta: 15 days, 20:45:24  iter: 3799  total_loss: 0.2214  loss_cls: 0.09002  loss_box_reg: 0.1223  loss_rpn_cls: 8.484e-05  loss_rpn_loc: 0.001539    time: 2.4691  last_time: 2.2395  data_time: 1.5381  last_data_time: 1.3777   lr: 0.0009999  max_mem: 4120M\n",
      "\u001b[32m[09/06 18:46:46 d2.utils.events]: \u001b[0m eta: 15 days, 21:16:56  iter: 3819  total_loss: 0.2076  loss_cls: 0.0839  loss_box_reg: 0.1186  loss_rpn_cls: 3.928e-05  loss_rpn_loc: 0.001446    time: 2.4688  last_time: 2.3405  data_time: 1.5193  last_data_time: 1.3976   lr: 0.0009999  max_mem: 4120M\n",
      "\u001b[32m[09/06 18:47:36 d2.utils.events]: \u001b[0m eta: 15 days, 21:27:22  iter: 3839  total_loss: 0.2168  loss_cls: 0.08851  loss_box_reg: 0.1269  loss_rpn_cls: 8.415e-05  loss_rpn_loc: 0.001875    time: 2.4690  last_time: 2.5297  data_time: 1.5634  last_data_time: 1.6590   lr: 0.0009999  max_mem: 4120M\n",
      "\u001b[32m[09/06 18:48:26 d2.utils.events]: \u001b[0m eta: 15 days, 21:27:13  iter: 3859  total_loss: 0.2353  loss_cls: 0.1078  loss_box_reg: 0.1212  loss_rpn_cls: 6.886e-05  loss_rpn_loc: 0.001516    time: 2.4694  last_time: 2.7425  data_time: 1.5962  last_data_time: 1.7460   lr: 0.0009999  max_mem: 4120M\n",
      "\u001b[32m[09/06 18:49:18 d2.utils.events]: \u001b[0m eta: 15 days, 23:07:55  iter: 3879  total_loss: 0.2299  loss_cls: 0.09459  loss_box_reg: 0.1303  loss_rpn_cls: 5.622e-05  loss_rpn_loc: 0.001565    time: 2.4702  last_time: 3.0922  data_time: 1.6647  last_data_time: 2.0219   lr: 0.0009999  max_mem: 4120M\n",
      "\u001b[32m[09/06 18:50:15 d2.utils.events]: \u001b[0m eta: 16 days, 0:52:38  iter: 3899  total_loss: 0.2013  loss_cls: 0.07978  loss_box_reg: 0.1263  loss_rpn_cls: 8.172e-05  loss_rpn_loc: 0.001584    time: 2.4729  last_time: 2.7686  data_time: 1.7847  last_data_time: 1.7336   lr: 0.0009999  max_mem: 4120M\n",
      "\u001b[32m[09/06 18:51:15 d2.utils.events]: \u001b[0m eta: 16 days, 1:54:10  iter: 3919  total_loss: 0.2073  loss_cls: 0.08689  loss_box_reg: 0.1227  loss_rpn_cls: 6.734e-05  loss_rpn_loc: 0.001491    time: 2.4766  last_time: 3.3259  data_time: 1.8957  last_data_time: 2.1762   lr: 0.00099989  max_mem: 4120M\n",
      "\u001b[32m[09/06 18:52:11 d2.utils.events]: \u001b[0m eta: 16 days, 3:57:42  iter: 3939  total_loss: 0.2171  loss_cls: 0.09915  loss_box_reg: 0.1196  loss_rpn_cls: 5.787e-05  loss_rpn_loc: 0.001549    time: 2.4786  last_time: 3.2443  data_time: 1.7021  last_data_time: 2.1389   lr: 0.00099989  max_mem: 4120M\n",
      "\u001b[32m[09/06 18:53:09 d2.utils.events]: \u001b[0m eta: 16 days, 4:54:23  iter: 3959  total_loss: 0.2104  loss_cls: 0.08383  loss_box_reg: 0.1214  loss_rpn_cls: 4.304e-05  loss_rpn_loc: 0.001477    time: 2.4816  last_time: 2.7759  data_time: 1.8388  last_data_time: 1.6036   lr: 0.00099989  max_mem: 4120M\n",
      "\u001b[32m[09/06 18:54:09 d2.utils.events]: \u001b[0m eta: 16 days, 6:21:09  iter: 3979  total_loss: 0.2105  loss_cls: 0.09182  loss_box_reg: 0.1264  loss_rpn_cls: 6.266e-05  loss_rpn_loc: 0.001535    time: 2.4848  last_time: 2.5908  data_time: 1.8601  last_data_time: 1.5511   lr: 0.00099989  max_mem: 4120M\n",
      "\u001b[32m[09/06 18:55:20 d2.data.datasets.coco]: \u001b[0mLoaded 1199 images in COCO format from data/ssd_rcnn_face/annotations_val.json\n",
      "\u001b[32m[09/06 18:55:20 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(512, 512), max_size=512, sample_style='choice')]\n",
      "\u001b[32m[09/06 18:55:20 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[09/06 18:55:20 d2.data.common]: \u001b[0mSerializing 1199 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[09/06 18:55:20 d2.data.common]: \u001b[0mSerialized dataset takes 0.36 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[09/06 18:55:20 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n",
      "\u001b[32m[09/06 18:55:20 d2.evaluation.evaluator]: \u001b[0mStart inference on 1199 batches\n",
      "\u001b[32m[09/06 18:55:22 d2.evaluation.evaluator]: \u001b[0mInference done 11/1199. Dataloading: 0.0727 s/iter. Inference: 0.0809 s/iter. Eval: 0.0008 s/iter. Total: 0.1544 s/iter. ETA=0:03:03\n",
      "\u001b[32m[09/06 18:55:27 d2.evaluation.evaluator]: \u001b[0mInference done 34/1199. Dataloading: 0.1071 s/iter. Inference: 0.0986 s/iter. Eval: 0.0007 s/iter. Total: 0.2065 s/iter. ETA=0:04:00\n",
      "\u001b[32m[09/06 18:55:33 d2.evaluation.evaluator]: \u001b[0mInference done 64/1199. Dataloading: 0.0973 s/iter. Inference: 0.0935 s/iter. Eval: 0.0008 s/iter. Total: 0.1917 s/iter. ETA=0:03:37\n",
      "\u001b[32m[09/06 18:55:38 d2.evaluation.evaluator]: \u001b[0mInference done 87/1199. Dataloading: 0.1086 s/iter. Inference: 0.0897 s/iter. Eval: 0.0007 s/iter. Total: 0.1992 s/iter. ETA=0:03:41\n",
      "\u001b[32m[09/06 18:55:43 d2.evaluation.evaluator]: \u001b[0mInference done 118/1199. Dataloading: 0.0983 s/iter. Inference: 0.0898 s/iter. Eval: 0.0008 s/iter. Total: 0.1890 s/iter. ETA=0:03:24\n",
      "\u001b[32m[09/06 18:55:48 d2.evaluation.evaluator]: \u001b[0mInference done 136/1199. Dataloading: 0.1121 s/iter. Inference: 0.0885 s/iter. Eval: 0.0007 s/iter. Total: 0.2014 s/iter. ETA=0:03:34\n",
      "\u001b[32m[09/06 18:55:53 d2.evaluation.evaluator]: \u001b[0mInference done 168/1199. Dataloading: 0.1053 s/iter. Inference: 0.0864 s/iter. Eval: 0.0007 s/iter. Total: 0.1926 s/iter. ETA=0:03:18\n",
      "\u001b[32m[09/06 18:55:58 d2.evaluation.evaluator]: \u001b[0mInference done 196/1199. Dataloading: 0.1051 s/iter. Inference: 0.0850 s/iter. Eval: 0.0007 s/iter. Total: 0.1909 s/iter. ETA=0:03:11\n",
      "\u001b[32m[09/06 18:56:03 d2.evaluation.evaluator]: \u001b[0mInference done 223/1199. Dataloading: 0.1052 s/iter. Inference: 0.0849 s/iter. Eval: 0.0007 s/iter. Total: 0.1909 s/iter. ETA=0:03:06\n",
      "\u001b[32m[09/06 18:56:08 d2.evaluation.evaluator]: \u001b[0mInference done 247/1199. Dataloading: 0.1076 s/iter. Inference: 0.0844 s/iter. Eval: 0.0007 s/iter. Total: 0.1928 s/iter. ETA=0:03:03\n",
      "\u001b[32m[09/06 18:56:14 d2.evaluation.evaluator]: \u001b[0mInference done 272/1199. Dataloading: 0.1102 s/iter. Inference: 0.0843 s/iter. Eval: 0.0007 s/iter. Total: 0.1953 s/iter. ETA=0:03:01\n",
      "\u001b[32m[09/06 18:56:19 d2.evaluation.evaluator]: \u001b[0mInference done 282/1199. Dataloading: 0.1200 s/iter. Inference: 0.0855 s/iter. Eval: 0.0007 s/iter. Total: 0.2063 s/iter. ETA=0:03:09\n",
      "\u001b[32m[09/06 18:56:24 d2.evaluation.evaluator]: \u001b[0mInference done 302/1199. Dataloading: 0.1211 s/iter. Inference: 0.0875 s/iter. Eval: 0.0007 s/iter. Total: 0.2095 s/iter. ETA=0:03:07\n",
      "\u001b[32m[09/06 18:56:29 d2.evaluation.evaluator]: \u001b[0mInference done 331/1199. Dataloading: 0.1187 s/iter. Inference: 0.0873 s/iter. Eval: 0.0007 s/iter. Total: 0.2069 s/iter. ETA=0:02:59\n",
      "\u001b[32m[09/06 18:56:34 d2.evaluation.evaluator]: \u001b[0mInference done 360/1199. Dataloading: 0.1167 s/iter. Inference: 0.0867 s/iter. Eval: 0.0007 s/iter. Total: 0.2043 s/iter. ETA=0:02:51\n",
      "\u001b[32m[09/06 18:56:39 d2.evaluation.evaluator]: \u001b[0mInference done 384/1199. Dataloading: 0.1178 s/iter. Inference: 0.0865 s/iter. Eval: 0.0007 s/iter. Total: 0.2051 s/iter. ETA=0:02:47\n",
      "\u001b[32m[09/06 18:56:44 d2.evaluation.evaluator]: \u001b[0mInference done 410/1199. Dataloading: 0.1170 s/iter. Inference: 0.0865 s/iter. Eval: 0.0007 s/iter. Total: 0.2043 s/iter. ETA=0:02:41\n",
      "\u001b[32m[09/06 18:56:49 d2.evaluation.evaluator]: \u001b[0mInference done 444/1199. Dataloading: 0.1135 s/iter. Inference: 0.0860 s/iter. Eval: 0.0007 s/iter. Total: 0.2003 s/iter. ETA=0:02:31\n",
      "\u001b[32m[09/06 18:56:55 d2.evaluation.evaluator]: \u001b[0mInference done 471/1199. Dataloading: 0.1135 s/iter. Inference: 0.0857 s/iter. Eval: 0.0007 s/iter. Total: 0.2001 s/iter. ETA=0:02:25\n",
      "\u001b[32m[09/06 18:57:00 d2.evaluation.evaluator]: \u001b[0mInference done 502/1199. Dataloading: 0.1118 s/iter. Inference: 0.0854 s/iter. Eval: 0.0007 s/iter. Total: 0.1980 s/iter. ETA=0:02:18\n",
      "\u001b[32m[09/06 18:57:05 d2.evaluation.evaluator]: \u001b[0mInference done 526/1199. Dataloading: 0.1119 s/iter. Inference: 0.0859 s/iter. Eval: 0.0007 s/iter. Total: 0.1986 s/iter. ETA=0:02:13\n",
      "\u001b[32m[09/06 18:57:10 d2.evaluation.evaluator]: \u001b[0mInference done 553/1199. Dataloading: 0.1117 s/iter. Inference: 0.0855 s/iter. Eval: 0.0007 s/iter. Total: 0.1980 s/iter. ETA=0:02:07\n",
      "\u001b[32m[09/06 18:57:15 d2.evaluation.evaluator]: \u001b[0mInference done 580/1199. Dataloading: 0.1108 s/iter. Inference: 0.0859 s/iter. Eval: 0.0007 s/iter. Total: 0.1976 s/iter. ETA=0:02:02\n",
      "\u001b[32m[09/06 18:57:20 d2.evaluation.evaluator]: \u001b[0mInference done 608/1199. Dataloading: 0.1103 s/iter. Inference: 0.0857 s/iter. Eval: 0.0007 s/iter. Total: 0.1969 s/iter. ETA=0:01:56\n",
      "\u001b[32m[09/06 18:57:25 d2.evaluation.evaluator]: \u001b[0mInference done 638/1199. Dataloading: 0.1096 s/iter. Inference: 0.0854 s/iter. Eval: 0.0007 s/iter. Total: 0.1958 s/iter. ETA=0:01:49\n",
      "\u001b[32m[09/06 18:57:30 d2.evaluation.evaluator]: \u001b[0mInference done 662/1199. Dataloading: 0.1101 s/iter. Inference: 0.0853 s/iter. Eval: 0.0007 s/iter. Total: 0.1963 s/iter. ETA=0:01:45\n",
      "\u001b[32m[09/06 18:57:35 d2.evaluation.evaluator]: \u001b[0mInference done 689/1199. Dataloading: 0.1100 s/iter. Inference: 0.0851 s/iter. Eval: 0.0007 s/iter. Total: 0.1960 s/iter. ETA=0:01:39\n",
      "\u001b[32m[09/06 18:57:41 d2.evaluation.evaluator]: \u001b[0mInference done 718/1199. Dataloading: 0.1095 s/iter. Inference: 0.0850 s/iter. Eval: 0.0007 s/iter. Total: 0.1953 s/iter. ETA=0:01:33\n",
      "\u001b[32m[09/06 18:57:47 d2.evaluation.evaluator]: \u001b[0mInference done 747/1199. Dataloading: 0.1105 s/iter. Inference: 0.0847 s/iter. Eval: 0.0007 s/iter. Total: 0.1961 s/iter. ETA=0:01:28\n",
      "\u001b[32m[09/06 18:57:52 d2.evaluation.evaluator]: \u001b[0mInference done 766/1199. Dataloading: 0.1120 s/iter. Inference: 0.0850 s/iter. Eval: 0.0007 s/iter. Total: 0.1978 s/iter. ETA=0:01:25\n",
      "\u001b[32m[09/06 18:57:57 d2.evaluation.evaluator]: \u001b[0mInference done 799/1199. Dataloading: 0.1106 s/iter. Inference: 0.0845 s/iter. Eval: 0.0007 s/iter. Total: 0.1960 s/iter. ETA=0:01:18\n",
      "\u001b[32m[09/06 18:58:02 d2.evaluation.evaluator]: \u001b[0mInference done 829/1199. Dataloading: 0.1098 s/iter. Inference: 0.0844 s/iter. Eval: 0.0007 s/iter. Total: 0.1950 s/iter. ETA=0:01:12\n",
      "\u001b[32m[09/06 18:58:07 d2.evaluation.evaluator]: \u001b[0mInference done 861/1199. Dataloading: 0.1087 s/iter. Inference: 0.0843 s/iter. Eval: 0.0007 s/iter. Total: 0.1938 s/iter. ETA=0:01:05\n",
      "\u001b[32m[09/06 18:58:12 d2.evaluation.evaluator]: \u001b[0mInference done 891/1199. Dataloading: 0.1081 s/iter. Inference: 0.0841 s/iter. Eval: 0.0007 s/iter. Total: 0.1930 s/iter. ETA=0:00:59\n",
      "\u001b[32m[09/06 18:58:17 d2.evaluation.evaluator]: \u001b[0mInference done 917/1199. Dataloading: 0.1082 s/iter. Inference: 0.0840 s/iter. Eval: 0.0007 s/iter. Total: 0.1930 s/iter. ETA=0:00:54\n",
      "\u001b[32m[09/06 18:58:23 d2.evaluation.evaluator]: \u001b[0mInference done 948/1199. Dataloading: 0.1074 s/iter. Inference: 0.0838 s/iter. Eval: 0.0007 s/iter. Total: 0.1920 s/iter. ETA=0:00:48\n",
      "\u001b[32m[09/06 18:58:28 d2.evaluation.evaluator]: \u001b[0mInference done 974/1199. Dataloading: 0.1077 s/iter. Inference: 0.0836 s/iter. Eval: 0.0007 s/iter. Total: 0.1921 s/iter. ETA=0:00:43\n",
      "\u001b[32m[09/06 18:58:33 d2.evaluation.evaluator]: \u001b[0mInference done 1002/1199. Dataloading: 0.1077 s/iter. Inference: 0.0834 s/iter. Eval: 0.0007 s/iter. Total: 0.1919 s/iter. ETA=0:00:37\n",
      "\u001b[32m[09/06 18:58:38 d2.evaluation.evaluator]: \u001b[0mInference done 1028/1199. Dataloading: 0.1081 s/iter. Inference: 0.0832 s/iter. Eval: 0.0007 s/iter. Total: 0.1921 s/iter. ETA=0:00:32\n",
      "\u001b[32m[09/06 18:58:43 d2.evaluation.evaluator]: \u001b[0mInference done 1055/1199. Dataloading: 0.1081 s/iter. Inference: 0.0832 s/iter. Eval: 0.0007 s/iter. Total: 0.1921 s/iter. ETA=0:00:27\n",
      "\u001b[32m[09/06 18:58:48 d2.evaluation.evaluator]: \u001b[0mInference done 1081/1199. Dataloading: 0.1081 s/iter. Inference: 0.0832 s/iter. Eval: 0.0007 s/iter. Total: 0.1922 s/iter. ETA=0:00:22\n",
      "\u001b[32m[09/06 18:58:53 d2.evaluation.evaluator]: \u001b[0mInference done 1111/1199. Dataloading: 0.1077 s/iter. Inference: 0.0830 s/iter. Eval: 0.0007 s/iter. Total: 0.1915 s/iter. ETA=0:00:16\n",
      "\u001b[32m[09/06 18:58:58 d2.evaluation.evaluator]: \u001b[0mInference done 1130/1199. Dataloading: 0.1088 s/iter. Inference: 0.0831 s/iter. Eval: 0.0007 s/iter. Total: 0.1928 s/iter. ETA=0:00:13\n",
      "\u001b[32m[09/06 18:59:03 d2.evaluation.evaluator]: \u001b[0mInference done 1158/1199. Dataloading: 0.1086 s/iter. Inference: 0.0832 s/iter. Eval: 0.0007 s/iter. Total: 0.1926 s/iter. ETA=0:00:07\n",
      "\u001b[32m[09/06 18:59:08 d2.evaluation.evaluator]: \u001b[0mInference done 1187/1199. Dataloading: 0.1081 s/iter. Inference: 0.0832 s/iter. Eval: 0.0007 s/iter. Total: 0.1921 s/iter. ETA=0:00:02\n",
      "\u001b[32m[09/06 18:59:11 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:03:49.404889 (0.192131 s / iter per device, on 1 devices)\n",
      "\u001b[32m[09/06 18:59:11 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:01:39 (0.083073 s / iter per device, on 1 devices)\n",
      "\u001b[32m[09/06 18:59:11 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[09/06 18:59:11 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[09/06 18:59:11 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[09/06 18:59:11 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.19 seconds.\n",
      "\u001b[32m[09/06 18:59:11 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[09/06 18:59:11 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.02 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.726\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.860\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.858\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.726\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.862\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.862\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.862\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.862\n",
      "\u001b[32m[09/06 18:59:11 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
      "| 72.582 | 86.016 | 85.789 |  nan  |  nan  | 72.582 |\n",
      "\u001b[32m[09/06 18:59:11 d2.evaluation.coco_evaluation]: \u001b[0mSome metrics cannot be computed and is shown as NaN.\n",
      "\u001b[32m[09/06 18:59:11 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category   | AP     | category   | AP     | category   | AP     |\n",
      "|:-----------|:-------|:-----------|:-------|:-----------|:-------|\n",
      "| angry      | 68.030 | sad        | 73.544 | surprised  | 66.127 |\n",
      "| happy      | 82.626 |            |        |            |        |\n",
      "\u001b[32m[09/06 18:59:11 d2.engine.defaults]: \u001b[0mEvaluation results for face_data_set_valid in csv format:\n",
      "\u001b[32m[09/06 18:59:11 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[09/06 18:59:11 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[09/06 18:59:11 d2.evaluation.testing]: \u001b[0mcopypaste: 72.5815,86.0157,85.7886,nan,nan,72.5815\n",
      "\u001b[32m[09/06 18:59:11 d2.utils.events]: \u001b[0m eta: 16 days, 7:50:55  iter: 3999  total_loss: 0.2141  loss_cls: 0.0797  loss_box_reg: 0.1239  loss_rpn_cls: 6.985e-05  loss_rpn_loc: 0.001621    time: 2.4912  last_time: 3.0826  data_time: 2.2092  last_data_time: 1.9234   lr: 0.00099989  max_mem: 4120M\n",
      "\u001b[32m[09/06 19:00:08 d2.utils.events]: \u001b[0m eta: 16 days, 9:53:24  iter: 4019  total_loss: 0.2211  loss_cls: 0.08459  loss_box_reg: 0.1258  loss_rpn_cls: 0.0001349  loss_rpn_loc: 0.001605    time: 2.4935  last_time: 2.4202  data_time: 1.7657  last_data_time: 1.3741   lr: 0.00099989  max_mem: 4120M\n",
      "\u001b[32m[09/06 19:01:07 d2.utils.events]: \u001b[0m eta: 16 days, 11:40:09  iter: 4039  total_loss: 0.2291  loss_cls: 0.09306  loss_box_reg: 0.1276  loss_rpn_cls: 0.0001776  loss_rpn_loc: 0.001546    time: 2.4966  last_time: 2.8568  data_time: 1.8934  last_data_time: 1.7125   lr: 0.00099989  max_mem: 4120M\n",
      "\u001b[32m[09/06 19:02:03 d2.utils.events]: \u001b[0m eta: 16 days, 12:57:48  iter: 4059  total_loss: 0.2094  loss_cls: 0.07945  loss_box_reg: 0.1212  loss_rpn_cls: 6.416e-05  loss_rpn_loc: 0.001589    time: 2.4987  last_time: 2.5664  data_time: 1.7325  last_data_time: 1.5145   lr: 0.00099989  max_mem: 4120M\n",
      "\u001b[32m[09/06 19:03:00 d2.utils.events]: \u001b[0m eta: 16 days, 15:27:30  iter: 4079  total_loss: 0.213  loss_cls: 0.09244  loss_box_reg: 0.1191  loss_rpn_cls: 9.884e-05  loss_rpn_loc: 0.0014    time: 2.5010  last_time: 2.9703  data_time: 1.7668  last_data_time: 1.8350   lr: 0.00099989  max_mem: 4120M\n",
      "\u001b[32m[09/06 19:03:59 d2.utils.events]: \u001b[0m eta: 16 days, 17:58:37  iter: 4099  total_loss: 0.2068  loss_cls: 0.08678  loss_box_reg: 0.1191  loss_rpn_cls: 9.869e-05  loss_rpn_loc: 0.00158    time: 2.5038  last_time: 3.0690  data_time: 1.8685  last_data_time: 1.8281   lr: 0.00099988  max_mem: 4120M\n",
      "\u001b[32m[09/06 19:05:01 d2.utils.events]: \u001b[0m eta: 16 days, 20:53:13  iter: 4119  total_loss: 0.2273  loss_cls: 0.09244  loss_box_reg: 0.1207  loss_rpn_cls: 8.133e-05  loss_rpn_loc: 0.001616    time: 2.5075  last_time: 4.4600  data_time: 1.9778  last_data_time: 3.2323   lr: 0.00099988  max_mem: 4120M\n",
      "\u001b[32m[09/06 19:05:57 d2.utils.events]: \u001b[0m eta: 16 days, 23:15:01  iter: 4139  total_loss: 0.1978  loss_cls: 0.0862  loss_box_reg: 0.1166  loss_rpn_cls: 8.232e-05  loss_rpn_loc: 0.001551    time: 2.5094  last_time: 2.6077  data_time: 1.7462  last_data_time: 1.6550   lr: 0.00099988  max_mem: 4120M\n",
      "\u001b[32m[09/06 19:06:58 d2.utils.events]: \u001b[0m eta: 17 days, 1:54:16  iter: 4159  total_loss: 0.2199  loss_cls: 0.07976  loss_box_reg: 0.1244  loss_rpn_cls: 5.832e-05  loss_rpn_loc: 0.001534    time: 2.5129  last_time: 3.1652  data_time: 1.9575  last_data_time: 2.0686   lr: 0.00099988  max_mem: 4120M\n",
      "\u001b[32m[09/06 19:07:58 d2.utils.events]: \u001b[0m eta: 17 days, 3:42:55  iter: 4179  total_loss: 0.2548  loss_cls: 0.1189  loss_box_reg: 0.1261  loss_rpn_cls: 7.174e-05  loss_rpn_loc: 0.001675    time: 2.5158  last_time: 2.9731  data_time: 1.8863  last_data_time: 1.8392   lr: 0.00099988  max_mem: 4120M\n",
      "\u001b[32m[09/06 19:08:57 d2.utils.events]: \u001b[0m eta: 17 days, 4:21:37  iter: 4199  total_loss: 0.2076  loss_cls: 0.09444  loss_box_reg: 0.1168  loss_rpn_cls: 7.527e-05  loss_rpn_loc: 0.001473    time: 2.5186  last_time: 3.0617  data_time: 1.8835  last_data_time: 1.9601   lr: 0.00099988  max_mem: 4120M\n",
      "\u001b[32m[09/06 19:09:57 d2.utils.events]: \u001b[0m eta: 17 days, 5:39:02  iter: 4219  total_loss: 0.2154  loss_cls: 0.08793  loss_box_reg: 0.124  loss_rpn_cls: 6.703e-05  loss_rpn_loc: 0.001639    time: 2.5216  last_time: 3.2819  data_time: 1.9241  last_data_time: 2.0946   lr: 0.00099988  max_mem: 4120M\n",
      "\u001b[32m[09/06 19:10:58 d2.utils.events]: \u001b[0m eta: 17 days, 6:42:11  iter: 4239  total_loss: 0.2199  loss_cls: 0.09531  loss_box_reg: 0.1267  loss_rpn_cls: 7.13e-05  loss_rpn_loc: 0.001627    time: 2.5250  last_time: 4.2000  data_time: 1.9925  last_data_time: 2.9721   lr: 0.00099988  max_mem: 4120M\n",
      "\u001b[32m[09/06 19:11:53 d2.utils.events]: \u001b[0m eta: 17 days, 6:18:25  iter: 4259  total_loss: 0.2061  loss_cls: 0.07157  loss_box_reg: 0.1189  loss_rpn_cls: 6.807e-05  loss_rpn_loc: 0.001666    time: 2.5263  last_time: 2.8141  data_time: 1.7041  last_data_time: 1.7205   lr: 0.00099988  max_mem: 4120M\n",
      "\u001b[32m[09/06 19:12:49 d2.utils.events]: \u001b[0m eta: 17 days, 7:18:42  iter: 4279  total_loss: 0.208  loss_cls: 0.08483  loss_box_reg: 0.1203  loss_rpn_cls: 7.896e-05  loss_rpn_loc: 0.001483    time: 2.5278  last_time: 3.0329  data_time: 1.7306  last_data_time: 1.9244   lr: 0.00099987  max_mem: 4120M\n",
      "\u001b[32m[09/06 19:13:48 d2.utils.events]: \u001b[0m eta: 17 days, 8:08:56  iter: 4299  total_loss: 0.2147  loss_cls: 0.09154  loss_box_reg: 0.1262  loss_rpn_cls: 6.493e-05  loss_rpn_loc: 0.001878    time: 2.5304  last_time: 2.8820  data_time: 1.8763  last_data_time: 1.7960   lr: 0.00099987  max_mem: 4120M\n",
      "\u001b[32m[09/06 19:14:46 d2.utils.events]: \u001b[0m eta: 17 days, 10:36:35  iter: 4319  total_loss: 0.2203  loss_cls: 0.1013  loss_box_reg: 0.1239  loss_rpn_cls: 4.946e-05  loss_rpn_loc: 0.001624    time: 2.5327  last_time: 2.7576  data_time: 1.8464  last_data_time: 1.8077   lr: 0.00099987  max_mem: 4120M\n",
      "\u001b[32m[09/06 19:15:47 d2.utils.events]: \u001b[0m eta: 17 days, 15:28:54  iter: 4339  total_loss: 0.2388  loss_cls: 0.09945  loss_box_reg: 0.1244  loss_rpn_cls: 3.903e-05  loss_rpn_loc: 0.001651    time: 2.5358  last_time: 4.8242  data_time: 1.9688  last_data_time: 3.6338   lr: 0.00099987  max_mem: 4120M\n",
      "\u001b[32m[09/06 19:16:42 d2.utils.events]: \u001b[0m eta: 17 days, 17:08:43  iter: 4359  total_loss: 0.2139  loss_cls: 0.08568  loss_box_reg: 0.1205  loss_rpn_cls: 7.055e-05  loss_rpn_loc: 0.001453    time: 2.5372  last_time: 3.3354  data_time: 1.7402  last_data_time: 2.2243   lr: 0.00099987  max_mem: 4120M\n",
      "\u001b[32m[09/06 19:17:38 d2.utils.events]: \u001b[0m eta: 17 days, 20:13:51  iter: 4379  total_loss: 0.2054  loss_cls: 0.07955  loss_box_reg: 0.125  loss_rpn_cls: 7.537e-05  loss_rpn_loc: 0.001695    time: 2.5385  last_time: 3.0188  data_time: 1.7149  last_data_time: 1.8801   lr: 0.00099987  max_mem: 4120M\n",
      "\u001b[32m[09/06 19:18:40 d2.utils.events]: \u001b[0m eta: 17 days, 21:41:52  iter: 4399  total_loss: 0.1938  loss_cls: 0.06961  loss_box_reg: 0.1136  loss_rpn_cls: 6.955e-05  loss_rpn_loc: 0.001599    time: 2.5418  last_time: 3.5150  data_time: 2.0154  last_data_time: 2.3530   lr: 0.00099987  max_mem: 4120M\n",
      "\u001b[32m[09/06 19:19:36 d2.utils.events]: \u001b[0m eta: 18 days, 0:39:02  iter: 4419  total_loss: 0.2018  loss_cls: 0.08301  loss_box_reg: 0.114  loss_rpn_cls: 4.949e-05  loss_rpn_loc: 0.001442    time: 2.5435  last_time: 2.7262  data_time: 1.7858  last_data_time: 1.6935   lr: 0.00099987  max_mem: 4120M\n",
      "\u001b[32m[09/06 19:20:32 d2.utils.events]: \u001b[0m eta: 18 days, 1:59:41  iter: 4439  total_loss: 0.2255  loss_cls: 0.09872  loss_box_reg: 0.1188  loss_rpn_cls: 5.309e-05  loss_rpn_loc: 0.001706    time: 2.5448  last_time: 4.3427  data_time: 1.7529  last_data_time: 3.2297   lr: 0.00099987  max_mem: 4120M\n",
      "\u001b[32m[09/06 19:21:27 d2.utils.events]: \u001b[0m eta: 18 days, 3:26:28  iter: 4459  total_loss: 0.2088  loss_cls: 0.07935  loss_box_reg: 0.1254  loss_rpn_cls: 5.114e-05  loss_rpn_loc: 0.001485    time: 2.5461  last_time: 2.7995  data_time: 1.6956  last_data_time: 1.7374   lr: 0.00099986  max_mem: 4120M\n",
      "\u001b[32m[09/06 19:22:27 d2.utils.events]: \u001b[0m eta: 18 days, 5:37:58  iter: 4479  total_loss: 0.2169  loss_cls: 0.09032  loss_box_reg: 0.1239  loss_rpn_cls: 7.589e-05  loss_rpn_loc: 0.001515    time: 2.5488  last_time: 2.6327  data_time: 1.9517  last_data_time: 1.6312   lr: 0.00099986  max_mem: 4120M\n",
      "\u001b[32m[09/06 19:23:28 d2.utils.events]: \u001b[0m eta: 18 days, 7:45:34  iter: 4499  total_loss: 0.2204  loss_cls: 0.08792  loss_box_reg: 0.1197  loss_rpn_cls: 8.265e-05  loss_rpn_loc: 0.001586    time: 2.5508  last_time: 4.0926  data_time: 1.8326  last_data_time: 2.9492   lr: 0.00099986  max_mem: 4120M\n",
      "\u001b[32m[09/06 19:24:23 d2.utils.events]: \u001b[0m eta: 18 days, 10:09:45  iter: 4519  total_loss: 0.2315  loss_cls: 0.08706  loss_box_reg: 0.1332  loss_rpn_cls: 5.331e-05  loss_rpn_loc: 0.001582    time: 2.5520  last_time: 2.5261  data_time: 1.7029  last_data_time: 1.5021   lr: 0.00099986  max_mem: 4120M\n",
      "\u001b[32m[09/06 19:25:21 d2.utils.events]: \u001b[0m eta: 18 days, 11:52:34  iter: 4539  total_loss: 0.2112  loss_cls: 0.08322  loss_box_reg: 0.1207  loss_rpn_cls: 5.572e-05  loss_rpn_loc: 0.001552    time: 2.5537  last_time: 2.5823  data_time: 1.7938  last_data_time: 1.6522   lr: 0.00099986  max_mem: 4120M\n",
      "\u001b[32m[09/06 19:26:19 d2.utils.events]: \u001b[0m eta: 18 days, 13:42:32  iter: 4559  total_loss: 0.2325  loss_cls: 0.08765  loss_box_reg: 0.1263  loss_rpn_cls: 7.816e-05  loss_rpn_loc: 0.001656    time: 2.5558  last_time: 2.6024  data_time: 1.8696  last_data_time: 1.6110   lr: 0.00099986  max_mem: 4120M\n",
      "\u001b[32m[09/06 19:27:15 d2.utils.events]: \u001b[0m eta: 18 days, 15:27:36  iter: 4579  total_loss: 0.1948  loss_cls: 0.07668  loss_box_reg: 0.1195  loss_rpn_cls: 7.135e-05  loss_rpn_loc: 0.001552    time: 2.5571  last_time: 2.9630  data_time: 1.6940  last_data_time: 1.8436   lr: 0.00099986  max_mem: 4120M\n",
      "\u001b[32m[09/06 19:28:14 d2.utils.events]: \u001b[0m eta: 18 days, 18:42:39  iter: 4599  total_loss: 0.1855  loss_cls: 0.0697  loss_box_reg: 0.118  loss_rpn_cls: 4.978e-05  loss_rpn_loc: 0.00158    time: 2.5593  last_time: 2.7096  data_time: 1.8789  last_data_time: 1.6817   lr: 0.00099986  max_mem: 4120M\n",
      "\u001b[32m[09/06 19:29:12 d2.utils.events]: \u001b[0m eta: 18 days, 19:47:35  iter: 4619  total_loss: 0.232  loss_cls: 0.09804  loss_box_reg: 0.1279  loss_rpn_cls: 0.0001012  loss_rpn_loc: 0.001543    time: 2.5611  last_time: 3.2286  data_time: 1.8331  last_data_time: 2.1158   lr: 0.00099985  max_mem: 4120M\n",
      "\u001b[32m[09/06 19:30:11 d2.utils.events]: \u001b[0m eta: 18 days, 21:26:05  iter: 4639  total_loss: 0.2279  loss_cls: 0.09641  loss_box_reg: 0.1251  loss_rpn_cls: 5.439e-05  loss_rpn_loc: 0.001651    time: 2.5634  last_time: 3.0504  data_time: 1.9050  last_data_time: 1.8347   lr: 0.00099985  max_mem: 4120M\n",
      "\u001b[32m[09/06 19:31:13 d2.utils.events]: \u001b[0m eta: 18 days, 23:32:02  iter: 4659  total_loss: 0.222  loss_cls: 0.096  loss_box_reg: 0.1247  loss_rpn_cls: 5.171e-05  loss_rpn_loc: 0.001478    time: 2.5662  last_time: 3.2603  data_time: 2.0010  last_data_time: 2.1166   lr: 0.00099985  max_mem: 4120M\n",
      "\u001b[32m[09/06 19:32:13 d2.utils.events]: \u001b[0m eta: 19 days, 2:45:09  iter: 4679  total_loss: 0.1938  loss_cls: 0.07867  loss_box_reg: 0.1181  loss_rpn_cls: 5.421e-05  loss_rpn_loc: 0.001458    time: 2.5686  last_time: 3.0905  data_time: 1.9267  last_data_time: 2.0399   lr: 0.00099985  max_mem: 4120M\n",
      "\u001b[32m[09/06 19:33:13 d2.utils.events]: \u001b[0m eta: 19 days, 5:58:18  iter: 4699  total_loss: 0.2087  loss_cls: 0.07618  loss_box_reg: 0.1206  loss_rpn_cls: 6.602e-05  loss_rpn_loc: 0.001611    time: 2.5709  last_time: 2.6716  data_time: 1.9337  last_data_time: 1.6606   lr: 0.00099985  max_mem: 4120M\n",
      "\u001b[32m[09/06 19:34:10 d2.utils.events]: \u001b[0m eta: 19 days, 7:27:35  iter: 4719  total_loss: 0.2132  loss_cls: 0.08585  loss_box_reg: 0.1264  loss_rpn_cls: 5.177e-05  loss_rpn_loc: 0.001525    time: 2.5724  last_time: 2.9455  data_time: 1.7808  last_data_time: 1.8657   lr: 0.00099985  max_mem: 4120M\n",
      "\u001b[32m[09/06 19:35:09 d2.utils.events]: \u001b[0m eta: 19 days, 9:02:37  iter: 4739  total_loss: 0.2181  loss_cls: 0.08923  loss_box_reg: 0.1174  loss_rpn_cls: 4.979e-05  loss_rpn_loc: 0.00164    time: 2.5746  last_time: 3.3541  data_time: 1.8973  last_data_time: 2.2243   lr: 0.00099985  max_mem: 4120M\n",
      "\u001b[32m[09/06 19:36:06 d2.utils.events]: \u001b[0m eta: 19 days, 9:44:19  iter: 4759  total_loss: 0.2031  loss_cls: 0.07024  loss_box_reg: 0.114  loss_rpn_cls: 5.824e-05  loss_rpn_loc: 0.001536    time: 2.5759  last_time: 3.0227  data_time: 1.7487  last_data_time: 1.8755   lr: 0.00099984  max_mem: 4120M\n",
      "\u001b[32m[09/06 19:37:02 d2.utils.events]: \u001b[0m eta: 19 days, 11:09:51  iter: 4779  total_loss: 0.1987  loss_cls: 0.07761  loss_box_reg: 0.127  loss_rpn_cls: 5.437e-05  loss_rpn_loc: 0.001512    time: 2.5770  last_time: 2.3762  data_time: 1.7659  last_data_time: 1.3991   lr: 0.00099984  max_mem: 4120M\n",
      "\u001b[32m[09/06 19:37:54 d2.utils.events]: \u001b[0m eta: 19 days, 11:30:56  iter: 4799  total_loss: 0.2195  loss_cls: 0.094  loss_box_reg: 0.121  loss_rpn_cls: 5.34e-05  loss_rpn_loc: 0.001635    time: 2.5772  last_time: 2.2048  data_time: 1.6616  last_data_time: 1.3040   lr: 0.00099984  max_mem: 4120M\n",
      "\u001b[32m[09/06 19:38:45 d2.utils.events]: \u001b[0m eta: 19 days, 11:34:39  iter: 4819  total_loss: 0.2162  loss_cls: 0.09153  loss_box_reg: 0.1213  loss_rpn_cls: 5.498e-05  loss_rpn_loc: 0.001589    time: 2.5771  last_time: 2.5952  data_time: 1.5828  last_data_time: 1.5614   lr: 0.00099984  max_mem: 4120M\n",
      "\u001b[32m[09/06 19:39:38 d2.utils.events]: \u001b[0m eta: 19 days, 12:09:50  iter: 4839  total_loss: 0.2148  loss_cls: 0.08668  loss_box_reg: 0.1223  loss_rpn_cls: 4.716e-05  loss_rpn_loc: 0.001553    time: 2.5774  last_time: 2.3403  data_time: 1.6668  last_data_time: 1.3757   lr: 0.00099984  max_mem: 4120M\n",
      "\u001b[32m[09/06 19:40:30 d2.utils.events]: \u001b[0m eta: 19 days, 12:08:53  iter: 4859  total_loss: 0.2072  loss_cls: 0.09089  loss_box_reg: 0.1197  loss_rpn_cls: 8.204e-05  loss_rpn_loc: 0.001482    time: 2.5776  last_time: 2.9973  data_time: 1.6701  last_data_time: 1.9711   lr: 0.00099984  max_mem: 4120M\n",
      "\u001b[32m[09/06 19:41:26 d2.utils.events]: \u001b[0m eta: 19 days, 13:21:33  iter: 4879  total_loss: 0.1981  loss_cls: 0.0861  loss_box_reg: 0.1122  loss_rpn_cls: 7.497e-05  loss_rpn_loc: 0.001501    time: 2.5786  last_time: 2.6110  data_time: 1.7650  last_data_time: 1.6947   lr: 0.00099984  max_mem: 4120M\n",
      "\u001b[32m[09/06 19:42:16 d2.utils.events]: \u001b[0m eta: 19 days, 11:29:24  iter: 4899  total_loss: 0.1893  loss_cls: 0.06931  loss_box_reg: 0.1214  loss_rpn_cls: 5.476e-05  loss_rpn_loc: 0.001585    time: 2.5782  last_time: 2.6049  data_time: 1.5518  last_data_time: 1.6584   lr: 0.00099984  max_mem: 4120M\n",
      "\u001b[32m[09/06 19:43:03 d2.utils.events]: \u001b[0m eta: 19 days, 9:11:23  iter: 4919  total_loss: 0.1908  loss_cls: 0.06362  loss_box_reg: 0.1253  loss_rpn_cls: 7.943e-05  loss_rpn_loc: 0.001645    time: 2.5770  last_time: 2.5176  data_time: 1.4302  last_data_time: 1.5373   lr: 0.00099983  max_mem: 4120M\n",
      "\u001b[32m[09/06 19:43:52 d2.utils.events]: \u001b[0m eta: 19 days, 7:44:24  iter: 4939  total_loss: 0.203  loss_cls: 0.08739  loss_box_reg: 0.1148  loss_rpn_cls: 8.764e-05  loss_rpn_loc: 0.001526    time: 2.5764  last_time: 2.1022  data_time: 1.5171  last_data_time: 1.1354   lr: 0.00099983  max_mem: 4120M\n",
      "\u001b[32m[09/06 19:44:42 d2.utils.events]: \u001b[0m eta: 19 days, 6:13:06  iter: 4959  total_loss: 0.1976  loss_cls: 0.07372  loss_box_reg: 0.1193  loss_rpn_cls: 5.914e-05  loss_rpn_loc: 0.001558    time: 2.5760  last_time: 2.1516  data_time: 1.5710  last_data_time: 1.3555   lr: 0.00099983  max_mem: 4120M\n",
      "\u001b[32m[09/06 19:45:33 d2.utils.events]: \u001b[0m eta: 19 days, 6:00:06  iter: 4979  total_loss: 0.1936  loss_cls: 0.06571  loss_box_reg: 0.1258  loss_rpn_cls: 5.781e-05  loss_rpn_loc: 0.001573    time: 2.5759  last_time: 2.9284  data_time: 1.5903  last_data_time: 1.9010   lr: 0.00099983  max_mem: 4120M\n",
      "\u001b[32m[09/06 19:46:33 d2.data.datasets.coco]: \u001b[0mLoaded 1199 images in COCO format from data/ssd_rcnn_face/annotations_val.json\n",
      "\u001b[32m[09/06 19:46:33 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(512, 512), max_size=512, sample_style='choice')]\n",
      "\u001b[32m[09/06 19:46:33 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[09/06 19:46:33 d2.data.common]: \u001b[0mSerializing 1199 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[09/06 19:46:33 d2.data.common]: \u001b[0mSerialized dataset takes 0.36 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[09/06 19:46:33 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n",
      "\u001b[32m[09/06 19:46:33 d2.evaluation.evaluator]: \u001b[0mStart inference on 1199 batches\n",
      "\u001b[32m[09/06 19:46:38 d2.evaluation.evaluator]: \u001b[0mInference done 11/1199. Dataloading: 0.0623 s/iter. Inference: 0.0717 s/iter. Eval: 0.0007 s/iter. Total: 0.1347 s/iter. ETA=0:02:40\n",
      "\u001b[32m[09/06 19:46:43 d2.evaluation.evaluator]: \u001b[0mInference done 44/1199. Dataloading: 0.0825 s/iter. Inference: 0.0673 s/iter. Eval: 0.0005 s/iter. Total: 0.1504 s/iter. ETA=0:02:53\n",
      "\u001b[32m[09/06 19:46:48 d2.evaluation.evaluator]: \u001b[0mInference done 80/1199. Dataloading: 0.0815 s/iter. Inference: 0.0630 s/iter. Eval: 0.0005 s/iter. Total: 0.1451 s/iter. ETA=0:02:42\n",
      "\u001b[32m[09/06 19:46:53 d2.evaluation.evaluator]: \u001b[0mInference done 109/1199. Dataloading: 0.0885 s/iter. Inference: 0.0639 s/iter. Eval: 0.0005 s/iter. Total: 0.1530 s/iter. ETA=0:02:46\n",
      "\u001b[32m[09/06 19:46:58 d2.evaluation.evaluator]: \u001b[0mInference done 135/1199. Dataloading: 0.0964 s/iter. Inference: 0.0644 s/iter. Eval: 0.0005 s/iter. Total: 0.1614 s/iter. ETA=0:02:51\n",
      "\u001b[32m[09/06 19:47:03 d2.evaluation.evaluator]: \u001b[0mInference done 173/1199. Dataloading: 0.0903 s/iter. Inference: 0.0640 s/iter. Eval: 0.0005 s/iter. Total: 0.1549 s/iter. ETA=0:02:38\n",
      "\u001b[32m[09/06 19:47:08 d2.evaluation.evaluator]: \u001b[0mInference done 208/1199. Dataloading: 0.0893 s/iter. Inference: 0.0638 s/iter. Eval: 0.0005 s/iter. Total: 0.1537 s/iter. ETA=0:02:32\n",
      "\u001b[32m[09/06 19:47:14 d2.evaluation.evaluator]: \u001b[0mInference done 241/1199. Dataloading: 0.0913 s/iter. Inference: 0.0636 s/iter. Eval: 0.0005 s/iter. Total: 0.1555 s/iter. ETA=0:02:28\n",
      "\u001b[32m[09/06 19:47:19 d2.evaluation.evaluator]: \u001b[0mInference done 272/1199. Dataloading: 0.0926 s/iter. Inference: 0.0640 s/iter. Eval: 0.0005 s/iter. Total: 0.1572 s/iter. ETA=0:02:25\n",
      "\u001b[32m[09/06 19:47:24 d2.evaluation.evaluator]: \u001b[0mInference done 290/1199. Dataloading: 0.0996 s/iter. Inference: 0.0647 s/iter. Eval: 0.0005 s/iter. Total: 0.1650 s/iter. ETA=0:02:29\n",
      "\u001b[32m[09/06 19:47:29 d2.evaluation.evaluator]: \u001b[0mInference done 324/1199. Dataloading: 0.0982 s/iter. Inference: 0.0644 s/iter. Eval: 0.0005 s/iter. Total: 0.1631 s/iter. ETA=0:02:22\n",
      "\u001b[32m[09/06 19:47:34 d2.evaluation.evaluator]: \u001b[0mInference done 358/1199. Dataloading: 0.0973 s/iter. Inference: 0.0639 s/iter. Eval: 0.0005 s/iter. Total: 0.1618 s/iter. ETA=0:02:16\n",
      "\u001b[32m[09/06 19:47:40 d2.evaluation.evaluator]: \u001b[0mInference done 388/1199. Dataloading: 0.0981 s/iter. Inference: 0.0640 s/iter. Eval: 0.0005 s/iter. Total: 0.1628 s/iter. ETA=0:02:12\n",
      "\u001b[32m[09/06 19:47:45 d2.evaluation.evaluator]: \u001b[0mInference done 424/1199. Dataloading: 0.0966 s/iter. Inference: 0.0637 s/iter. Eval: 0.0005 s/iter. Total: 0.1609 s/iter. ETA=0:02:04\n",
      "\u001b[32m[09/06 19:47:50 d2.evaluation.evaluator]: \u001b[0mInference done 463/1199. Dataloading: 0.0940 s/iter. Inference: 0.0635 s/iter. Eval: 0.0005 s/iter. Total: 0.1581 s/iter. ETA=0:01:56\n",
      "\u001b[32m[09/06 19:47:55 d2.evaluation.evaluator]: \u001b[0mInference done 498/1199. Dataloading: 0.0936 s/iter. Inference: 0.0632 s/iter. Eval: 0.0005 s/iter. Total: 0.1574 s/iter. ETA=0:01:50\n",
      "\u001b[32m[09/06 19:48:00 d2.evaluation.evaluator]: \u001b[0mInference done 534/1199. Dataloading: 0.0931 s/iter. Inference: 0.0634 s/iter. Eval: 0.0005 s/iter. Total: 0.1571 s/iter. ETA=0:01:44\n",
      "\u001b[32m[09/06 19:48:05 d2.evaluation.evaluator]: \u001b[0mInference done 573/1199. Dataloading: 0.0916 s/iter. Inference: 0.0630 s/iter. Eval: 0.0005 s/iter. Total: 0.1551 s/iter. ETA=0:01:37\n",
      "\u001b[32m[09/06 19:48:10 d2.evaluation.evaluator]: \u001b[0mInference done 606/1199. Dataloading: 0.0916 s/iter. Inference: 0.0628 s/iter. Eval: 0.0005 s/iter. Total: 0.1550 s/iter. ETA=0:01:31\n",
      "\u001b[32m[09/06 19:48:15 d2.evaluation.evaluator]: \u001b[0mInference done 641/1199. Dataloading: 0.0910 s/iter. Inference: 0.0629 s/iter. Eval: 0.0005 s/iter. Total: 0.1544 s/iter. ETA=0:01:26\n",
      "\u001b[32m[09/06 19:48:21 d2.evaluation.evaluator]: \u001b[0mInference done 673/1199. Dataloading: 0.0911 s/iter. Inference: 0.0630 s/iter. Eval: 0.0005 s/iter. Total: 0.1547 s/iter. ETA=0:01:21\n",
      "\u001b[32m[09/06 19:48:26 d2.evaluation.evaluator]: \u001b[0mInference done 703/1199. Dataloading: 0.0915 s/iter. Inference: 0.0634 s/iter. Eval: 0.0005 s/iter. Total: 0.1555 s/iter. ETA=0:01:17\n",
      "\u001b[32m[09/06 19:48:31 d2.evaluation.evaluator]: \u001b[0mInference done 737/1199. Dataloading: 0.0909 s/iter. Inference: 0.0636 s/iter. Eval: 0.0005 s/iter. Total: 0.1551 s/iter. ETA=0:01:11\n",
      "\u001b[32m[09/06 19:48:36 d2.evaluation.evaluator]: \u001b[0mInference done 759/1199. Dataloading: 0.0928 s/iter. Inference: 0.0638 s/iter. Eval: 0.0005 s/iter. Total: 0.1572 s/iter. ETA=0:01:09\n",
      "\u001b[32m[09/06 19:48:41 d2.evaluation.evaluator]: \u001b[0mInference done 793/1199. Dataloading: 0.0927 s/iter. Inference: 0.0636 s/iter. Eval: 0.0005 s/iter. Total: 0.1568 s/iter. ETA=0:01:03\n",
      "\u001b[32m[09/06 19:48:46 d2.evaluation.evaluator]: \u001b[0mInference done 832/1199. Dataloading: 0.0917 s/iter. Inference: 0.0633 s/iter. Eval: 0.0005 s/iter. Total: 0.1555 s/iter. ETA=0:00:57\n",
      "\u001b[32m[09/06 19:48:51 d2.evaluation.evaluator]: \u001b[0mInference done 867/1199. Dataloading: 0.0913 s/iter. Inference: 0.0632 s/iter. Eval: 0.0005 s/iter. Total: 0.1551 s/iter. ETA=0:00:51\n",
      "\u001b[32m[09/06 19:48:56 d2.evaluation.evaluator]: \u001b[0mInference done 899/1199. Dataloading: 0.0915 s/iter. Inference: 0.0632 s/iter. Eval: 0.0005 s/iter. Total: 0.1552 s/iter. ETA=0:00:46\n",
      "\u001b[32m[09/06 19:49:01 d2.evaluation.evaluator]: \u001b[0mInference done 936/1199. Dataloading: 0.0908 s/iter. Inference: 0.0631 s/iter. Eval: 0.0005 s/iter. Total: 0.1544 s/iter. ETA=0:00:40\n",
      "\u001b[32m[09/06 19:49:06 d2.evaluation.evaluator]: \u001b[0mInference done 966/1199. Dataloading: 0.0911 s/iter. Inference: 0.0632 s/iter. Eval: 0.0005 s/iter. Total: 0.1548 s/iter. ETA=0:00:36\n",
      "\u001b[32m[09/06 19:49:11 d2.evaluation.evaluator]: \u001b[0mInference done 1002/1199. Dataloading: 0.0907 s/iter. Inference: 0.0631 s/iter. Eval: 0.0005 s/iter. Total: 0.1543 s/iter. ETA=0:00:30\n",
      "\u001b[32m[09/06 19:49:16 d2.evaluation.evaluator]: \u001b[0mInference done 1034/1199. Dataloading: 0.0911 s/iter. Inference: 0.0629 s/iter. Eval: 0.0005 s/iter. Total: 0.1545 s/iter. ETA=0:00:25\n",
      "\u001b[32m[09/06 19:49:21 d2.evaluation.evaluator]: \u001b[0mInference done 1067/1199. Dataloading: 0.0911 s/iter. Inference: 0.0629 s/iter. Eval: 0.0005 s/iter. Total: 0.1545 s/iter. ETA=0:00:20\n",
      "\u001b[32m[09/06 19:49:26 d2.evaluation.evaluator]: \u001b[0mInference done 1099/1199. Dataloading: 0.0913 s/iter. Inference: 0.0628 s/iter. Eval: 0.0005 s/iter. Total: 0.1547 s/iter. ETA=0:00:15\n",
      "\u001b[32m[09/06 19:49:32 d2.evaluation.evaluator]: \u001b[0mInference done 1128/1199. Dataloading: 0.0919 s/iter. Inference: 0.0629 s/iter. Eval: 0.0005 s/iter. Total: 0.1554 s/iter. ETA=0:00:11\n",
      "\u001b[32m[09/06 19:49:37 d2.evaluation.evaluator]: \u001b[0mInference done 1158/1199. Dataloading: 0.0919 s/iter. Inference: 0.0632 s/iter. Eval: 0.0005 s/iter. Total: 0.1557 s/iter. ETA=0:00:06\n",
      "\u001b[32m[09/06 19:49:42 d2.evaluation.evaluator]: \u001b[0mInference done 1187/1199. Dataloading: 0.0919 s/iter. Inference: 0.0637 s/iter. Eval: 0.0005 s/iter. Total: 0.1562 s/iter. ETA=0:00:01\n",
      "\u001b[32m[09/06 19:49:44 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:03:06.877144 (0.156514 s / iter per device, on 1 devices)\n",
      "\u001b[32m[09/06 19:49:44 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:01:16 (0.063673 s / iter per device, on 1 devices)\n",
      "\u001b[32m[09/06 19:49:44 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[09/06 19:49:44 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[09/06 19:49:44 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[09/06 19:49:44 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.12 seconds.\n",
      "\u001b[32m[09/06 19:49:44 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[09/06 19:49:44 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.02 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.715\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.849\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.845\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.715\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.852\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.852\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.852\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.852\n",
      "\u001b[32m[09/06 19:49:44 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
      "| 71.458 | 84.905 | 84.496 |  nan  |  nan  | 71.458 |\n",
      "\u001b[32m[09/06 19:49:44 d2.evaluation.coco_evaluation]: \u001b[0mSome metrics cannot be computed and is shown as NaN.\n",
      "\u001b[32m[09/06 19:49:44 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category   | AP     | category   | AP     | category   | AP     |\n",
      "|:-----------|:-------|:-----------|:-------|:-----------|:-------|\n",
      "| angry      | 64.714 | sad        | 70.243 | surprised  | 69.231 |\n",
      "| happy      | 81.644 |            |        |            |        |\n",
      "\u001b[32m[09/06 19:49:44 d2.engine.defaults]: \u001b[0mEvaluation results for face_data_set_valid in csv format:\n",
      "\u001b[32m[09/06 19:49:44 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[09/06 19:49:44 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[09/06 19:49:44 d2.evaluation.testing]: \u001b[0mcopypaste: 71.4580,84.9048,84.4963,nan,nan,71.4580\n",
      "\u001b[32m[09/06 19:49:44 d2.utils.events]: \u001b[0m eta: 19 days, 3:40:25  iter: 4999  total_loss: 0.2017  loss_cls: 0.07659  loss_box_reg: 0.1231  loss_rpn_cls: 6.349e-05  loss_rpn_loc: 0.001549    time: 2.5773  last_time: 2.7981  data_time: 1.8282  last_data_time: 1.7316   lr: 0.00099983  max_mem: 4120M\n",
      "\u001b[32m[09/06 19:50:35 d2.utils.events]: \u001b[0m eta: 19 days, 1:29:09  iter: 5019  total_loss: 0.1812  loss_cls: 0.05685  loss_box_reg: 0.1203  loss_rpn_cls: 4.107e-05  loss_rpn_loc: 0.001454    time: 2.5771  last_time: 2.4236  data_time: 1.5483  last_data_time: 1.5491   lr: 0.00099983  max_mem: 4120M\n",
      "\u001b[32m[09/06 19:51:25 d2.utils.events]: \u001b[0m eta: 18 days, 23:23:23  iter: 5039  total_loss: 0.2034  loss_cls: 0.07557  loss_box_reg: 0.1195  loss_rpn_cls: 7.351e-05  loss_rpn_loc: 0.001688    time: 2.5767  last_time: 2.9602  data_time: 1.5407  last_data_time: 1.9033   lr: 0.00099983  max_mem: 4120M\n",
      "\u001b[32m[09/06 19:52:13 d2.utils.events]: \u001b[0m eta: 18 days, 20:53:12  iter: 5059  total_loss: 0.1978  loss_cls: 0.07884  loss_box_reg: 0.1163  loss_rpn_cls: 5.558e-05  loss_rpn_loc: 0.001443    time: 2.5760  last_time: 2.5862  data_time: 1.5387  last_data_time: 1.7499   lr: 0.00099982  max_mem: 4120M\n",
      "\u001b[32m[09/06 19:53:02 d2.utils.events]: \u001b[0m eta: 18 days, 19:44:03  iter: 5079  total_loss: 0.1824  loss_cls: 0.05805  loss_box_reg: 0.1157  loss_rpn_cls: 4.423e-05  loss_rpn_loc: 0.001573    time: 2.5752  last_time: 2.5891  data_time: 1.5116  last_data_time: 1.7148   lr: 0.00099982  max_mem: 4120M\n",
      "\u001b[32m[09/06 19:53:54 d2.utils.events]: \u001b[0m eta: 18 days, 18:45:30  iter: 5099  total_loss: 0.1971  loss_cls: 0.08303  loss_box_reg: 0.1136  loss_rpn_cls: 5.232e-05  loss_rpn_loc: 0.001509    time: 2.5753  last_time: 2.3734  data_time: 1.6704  last_data_time: 1.4590   lr: 0.00099982  max_mem: 4120M\n",
      "\u001b[32m[09/06 19:54:41 d2.utils.events]: \u001b[0m eta: 18 days, 17:19:08  iter: 5119  total_loss: 0.2199  loss_cls: 0.0953  loss_box_reg: 0.1191  loss_rpn_cls: 5.813e-05  loss_rpn_loc: 0.001548    time: 2.5744  last_time: 2.3849  data_time: 1.4649  last_data_time: 1.4774   lr: 0.00099982  max_mem: 4120M\n",
      "\u001b[32m[09/06 19:55:30 d2.utils.events]: \u001b[0m eta: 18 days, 15:04:54  iter: 5139  total_loss: 0.2091  loss_cls: 0.08515  loss_box_reg: 0.1287  loss_rpn_cls: 7.175e-05  loss_rpn_loc: 0.001579    time: 2.5736  last_time: 3.6676  data_time: 1.5058  last_data_time: 2.6445   lr: 0.00099982  max_mem: 4120M\n",
      "\u001b[32m[09/06 19:56:18 d2.utils.events]: \u001b[0m eta: 18 days, 13:23:24  iter: 5159  total_loss: 0.2063  loss_cls: 0.08161  loss_box_reg: 0.1143  loss_rpn_cls: 6.134e-05  loss_rpn_loc: 0.001489    time: 2.5728  last_time: 2.9124  data_time: 1.5324  last_data_time: 1.9157   lr: 0.00099982  max_mem: 4120M\n",
      "\u001b[32m[09/06 19:57:06 d2.utils.events]: \u001b[0m eta: 18 days, 11:57:16  iter: 5179  total_loss: 0.2001  loss_cls: 0.08072  loss_box_reg: 0.1078  loss_rpn_cls: 4.167e-05  loss_rpn_loc: 0.001536    time: 2.5720  last_time: 2.8907  data_time: 1.4667  last_data_time: 1.7255   lr: 0.00099982  max_mem: 4120M\n",
      "\u001b[32m[09/06 19:57:57 d2.utils.events]: \u001b[0m eta: 18 days, 10:18:40  iter: 5199  total_loss: 0.1759  loss_cls: 0.06548  loss_box_reg: 0.1086  loss_rpn_cls: 8.724e-05  loss_rpn_loc: 0.001375    time: 2.5718  last_time: 2.2239  data_time: 1.5523  last_data_time: 1.3595   lr: 0.00099981  max_mem: 4120M\n",
      "\u001b[32m[09/06 19:58:44 d2.utils.events]: \u001b[0m eta: 18 days, 8:33:22  iter: 5219  total_loss: 0.194  loss_cls: 0.07499  loss_box_reg: 0.1227  loss_rpn_cls: 7.958e-05  loss_rpn_loc: 0.001577    time: 2.5707  last_time: 2.1363  data_time: 1.4751  last_data_time: 1.2093   lr: 0.00099981  max_mem: 4120M\n",
      "\u001b[32m[09/06 19:59:32 d2.utils.events]: \u001b[0m eta: 18 days, 6:43:00  iter: 5239  total_loss: 0.2099  loss_cls: 0.08898  loss_box_reg: 0.1148  loss_rpn_cls: 5.291e-05  loss_rpn_loc: 0.001695    time: 2.5700  last_time: 2.4681  data_time: 1.5105  last_data_time: 1.6184   lr: 0.00099981  max_mem: 4120M\n",
      "\u001b[32m[09/06 20:00:21 d2.utils.events]: \u001b[0m eta: 18 days, 5:25:12  iter: 5259  total_loss: 0.2036  loss_cls: 0.08838  loss_box_reg: 0.1098  loss_rpn_cls: 6.168e-05  loss_rpn_loc: 0.001598    time: 2.5695  last_time: 2.2301  data_time: 1.5600  last_data_time: 1.3311   lr: 0.00099981  max_mem: 4120M\n",
      "\u001b[32m[09/06 20:01:15 d2.utils.events]: \u001b[0m eta: 18 days, 4:27:47  iter: 5279  total_loss: 0.2011  loss_cls: 0.07007  loss_box_reg: 0.1218  loss_rpn_cls: 6.049e-05  loss_rpn_loc: 0.0016    time: 2.5701  last_time: 3.0297  data_time: 1.6945  last_data_time: 1.8966   lr: 0.00099981  max_mem: 4120M\n",
      "\u001b[32m[09/06 20:02:05 d2.utils.events]: \u001b[0m eta: 18 days, 2:54:02  iter: 5299  total_loss: 0.1889  loss_cls: 0.06356  loss_box_reg: 0.1194  loss_rpn_cls: 6.706e-05  loss_rpn_loc: 0.001578    time: 2.5698  last_time: 2.3121  data_time: 1.5716  last_data_time: 1.3822   lr: 0.00099981  max_mem: 4120M\n",
      "\u001b[32m[09/06 20:02:53 d2.utils.events]: \u001b[0m eta: 18 days, 0:44:46  iter: 5319  total_loss: 0.2095  loss_cls: 0.09493  loss_box_reg: 0.1083  loss_rpn_cls: 4.84e-05  loss_rpn_loc: 0.001448    time: 2.5688  last_time: 2.3776  data_time: 1.4606  last_data_time: 1.5069   lr: 0.00099981  max_mem: 4120M\n",
      "\u001b[32m[09/06 20:03:42 d2.utils.events]: \u001b[0m eta: 17 days, 23:51:20  iter: 5339  total_loss: 0.1773  loss_cls: 0.0583  loss_box_reg: 0.1154  loss_rpn_cls: 5.566e-05  loss_rpn_loc: 0.001391    time: 2.5683  last_time: 2.1486  data_time: 1.5487  last_data_time: 1.2616   lr: 0.0009998  max_mem: 4120M\n",
      "\u001b[32m[09/06 20:04:34 d2.utils.events]: \u001b[0m eta: 17 days, 22:36:39  iter: 5359  total_loss: 0.1855  loss_cls: 0.06699  loss_box_reg: 0.1142  loss_rpn_cls: 7.925e-05  loss_rpn_loc: 0.001577    time: 2.5685  last_time: 2.5934  data_time: 1.6593  last_data_time: 1.5632   lr: 0.0009998  max_mem: 4120M\n",
      "\u001b[32m[09/06 20:05:23 d2.utils.events]: \u001b[0m eta: 17 days, 21:18:53  iter: 5379  total_loss: 0.1929  loss_cls: 0.07188  loss_box_reg: 0.1191  loss_rpn_cls: 6.22e-05  loss_rpn_loc: 0.001537    time: 2.5679  last_time: 2.1673  data_time: 1.5329  last_data_time: 1.2638   lr: 0.0009998  max_mem: 4120M\n",
      "\u001b[32m[09/06 20:06:12 d2.utils.events]: \u001b[0m eta: 17 days, 19:50:54  iter: 5399  total_loss: 0.1883  loss_cls: 0.07014  loss_box_reg: 0.1195  loss_rpn_cls: 7.565e-05  loss_rpn_loc: 0.001685    time: 2.5675  last_time: 3.6672  data_time: 1.5506  last_data_time: 2.6130   lr: 0.0009998  max_mem: 4120M\n",
      "\u001b[32m[09/06 20:07:03 d2.utils.events]: \u001b[0m eta: 17 days, 17:04:38  iter: 5419  total_loss: 0.1932  loss_cls: 0.08343  loss_box_reg: 0.1148  loss_rpn_cls: 3.11e-05  loss_rpn_loc: 0.001487    time: 2.5674  last_time: 3.7027  data_time: 1.5707  last_data_time: 2.6522   lr: 0.0009998  max_mem: 4120M\n",
      "\u001b[32m[09/06 20:07:53 d2.utils.events]: \u001b[0m eta: 17 days, 13:53:07  iter: 5439  total_loss: 0.1994  loss_cls: 0.07642  loss_box_reg: 0.1229  loss_rpn_cls: 4.762e-05  loss_rpn_loc: 0.001558    time: 2.5670  last_time: 2.1663  data_time: 1.5478  last_data_time: 1.2498   lr: 0.0009998  max_mem: 4120M\n",
      "\u001b[32m[09/06 20:08:41 d2.utils.events]: \u001b[0m eta: 17 days, 11:28:24  iter: 5459  total_loss: 0.2092  loss_cls: 0.08087  loss_box_reg: 0.1201  loss_rpn_cls: 5.386e-05  loss_rpn_loc: 0.001496    time: 2.5664  last_time: 2.1816  data_time: 1.5174  last_data_time: 1.2570   lr: 0.0009998  max_mem: 4120M\n",
      "\u001b[32m[09/06 20:09:32 d2.utils.events]: \u001b[0m eta: 17 days, 9:09:18  iter: 5479  total_loss: 0.1712  loss_cls: 0.05645  loss_box_reg: 0.1187  loss_rpn_cls: 4.354e-05  loss_rpn_loc: 0.001505    time: 2.5662  last_time: 2.4133  data_time: 1.6195  last_data_time: 1.5228   lr: 0.00099979  max_mem: 4120M\n",
      "\u001b[32m[09/06 20:10:22 d2.utils.events]: \u001b[0m eta: 17 days, 7:02:23  iter: 5499  total_loss: 0.184  loss_cls: 0.06478  loss_box_reg: 0.1162  loss_rpn_cls: 6.779e-05  loss_rpn_loc: 0.001489    time: 2.5655  last_time: 2.2506  data_time: 1.4895  last_data_time: 1.3384   lr: 0.00099979  max_mem: 4120M\n",
      "\u001b[32m[09/06 20:11:10 d2.utils.events]: \u001b[0m eta: 17 days, 5:26:38  iter: 5519  total_loss: 0.1828  loss_cls: 0.05865  loss_box_reg: 0.1175  loss_rpn_cls: 5.666e-05  loss_rpn_loc: 0.001695    time: 2.5648  last_time: 1.3339  data_time: 1.4866  last_data_time: 0.4608   lr: 0.00099979  max_mem: 4120M\n",
      "\u001b[32m[09/06 20:11:57 d2.utils.events]: \u001b[0m eta: 17 days, 3:39:39  iter: 5539  total_loss: 0.1879  loss_cls: 0.06733  loss_box_reg: 0.118  loss_rpn_cls: 7.502e-05  loss_rpn_loc: 0.001635    time: 2.5638  last_time: 2.3650  data_time: 1.4402  last_data_time: 1.5339   lr: 0.00099979  max_mem: 4120M\n",
      "\u001b[32m[09/06 20:12:46 d2.utils.events]: \u001b[0m eta: 17 days, 2:04:03  iter: 5559  total_loss: 0.2044  loss_cls: 0.08402  loss_box_reg: 0.1185  loss_rpn_cls: 5.953e-05  loss_rpn_loc: 0.001525    time: 2.5633  last_time: 2.3600  data_time: 1.5293  last_data_time: 1.4453   lr: 0.00099979  max_mem: 4120M\n",
      "\u001b[32m[09/06 20:13:42 d2.utils.events]: \u001b[0m eta: 17 days, 1:10:20  iter: 5579  total_loss: 0.1875  loss_cls: 0.07177  loss_box_reg: 0.114  loss_rpn_cls: 0.00017  loss_rpn_loc: 0.001606    time: 2.5643  last_time: 2.9903  data_time: 1.7895  last_data_time: 1.8674   lr: 0.00099979  max_mem: 4120M\n",
      "\u001b[32m[09/06 20:14:43 d2.utils.events]: \u001b[0m eta: 17 days, 1:09:31  iter: 5599  total_loss: 0.1765  loss_cls: 0.0634  loss_box_reg: 0.1101  loss_rpn_cls: 6.326e-05  loss_rpn_loc: 0.001608    time: 2.5664  last_time: 3.0779  data_time: 1.9767  last_data_time: 2.0080   lr: 0.00099979  max_mem: 4120M\n",
      "\u001b[32m[09/06 20:15:40 d2.utils.events]: \u001b[0m eta: 17 days, 1:08:41  iter: 5619  total_loss: 0.1812  loss_cls: 0.08054  loss_box_reg: 0.1127  loss_rpn_cls: 4.988e-05  loss_rpn_loc: 0.001312    time: 2.5677  last_time: 3.0282  data_time: 1.8076  last_data_time: 1.8782   lr: 0.00099978  max_mem: 4120M\n",
      "\u001b[32m[09/06 20:16:36 d2.utils.events]: \u001b[0m eta: 17 days, 0:29:48  iter: 5639  total_loss: 0.1842  loss_cls: 0.05998  loss_box_reg: 0.1225  loss_rpn_cls: 6.793e-05  loss_rpn_loc: 0.00165    time: 2.5685  last_time: 3.0137  data_time: 1.7345  last_data_time: 1.9022   lr: 0.00099978  max_mem: 4120M\n",
      "\u001b[32m[09/06 20:17:34 d2.utils.events]: \u001b[0m eta: 16 days, 23:58:18  iter: 5659  total_loss: 0.2014  loss_cls: 0.08461  loss_box_reg: 0.12  loss_rpn_cls: 6.653e-05  loss_rpn_loc: 0.001568    time: 2.5700  last_time: 2.5743  data_time: 1.8507  last_data_time: 1.6040   lr: 0.00099978  max_mem: 4120M\n",
      "\u001b[32m[09/06 20:18:19 d2.utils.events]: \u001b[0m eta: 16 days, 22:03:18  iter: 5679  total_loss: 0.2136  loss_cls: 0.09615  loss_box_reg: 0.1115  loss_rpn_cls: 7.093e-05  loss_rpn_loc: 0.001482    time: 2.5688  last_time: 1.9002  data_time: 1.3954  last_data_time: 1.0101   lr: 0.00099978  max_mem: 4120M\n",
      "\u001b[32m[09/06 20:19:02 d2.utils.events]: \u001b[0m eta: 16 days, 19:27:58  iter: 5699  total_loss: 0.1848  loss_cls: 0.0649  loss_box_reg: 0.1146  loss_rpn_cls: 9.147e-05  loss_rpn_loc: 0.001461    time: 2.5668  last_time: 2.0885  data_time: 1.2437  last_data_time: 1.2545   lr: 0.00099978  max_mem: 4120M\n",
      "\u001b[32m[09/06 20:19:47 d2.utils.events]: \u001b[0m eta: 16 days, 17:54:26  iter: 5719  total_loss: 0.1914  loss_cls: 0.06774  loss_box_reg: 0.1155  loss_rpn_cls: 7.218e-05  loss_rpn_loc: 0.00158    time: 2.5656  last_time: 2.2131  data_time: 1.4149  last_data_time: 1.3090   lr: 0.00099978  max_mem: 4120M\n",
      "\u001b[32m[09/06 20:20:34 d2.utils.events]: \u001b[0m eta: 16 days, 16:24:19  iter: 5739  total_loss: 0.1817  loss_cls: 0.07215  loss_box_reg: 0.1121  loss_rpn_cls: 4.075e-05  loss_rpn_loc: 0.001455    time: 2.5647  last_time: 2.2043  data_time: 1.4918  last_data_time: 1.4002   lr: 0.00099977  max_mem: 4120M\n",
      "\u001b[32m[09/06 20:21:20 d2.utils.events]: \u001b[0m eta: 16 days, 15:04:29  iter: 5759  total_loss: 0.1836  loss_cls: 0.06606  loss_box_reg: 0.1164  loss_rpn_cls: 4.288e-05  loss_rpn_loc: 0.001494    time: 2.5635  last_time: 2.3534  data_time: 1.4132  last_data_time: 1.4991   lr: 0.00099977  max_mem: 4120M\n",
      "\u001b[32m[09/06 20:22:07 d2.utils.events]: \u001b[0m eta: 16 days, 13:55:54  iter: 5779  total_loss: 0.196  loss_cls: 0.08355  loss_box_reg: 0.1168  loss_rpn_cls: 6.794e-05  loss_rpn_loc: 0.001509    time: 2.5627  last_time: 1.9863  data_time: 1.4795  last_data_time: 1.1873   lr: 0.00099977  max_mem: 4120M\n",
      "\u001b[32m[09/06 20:22:58 d2.utils.events]: \u001b[0m eta: 16 days, 13:49:09  iter: 5799  total_loss: 0.18  loss_cls: 0.06817  loss_box_reg: 0.1085  loss_rpn_cls: 7.948e-05  loss_rpn_loc: 0.001517    time: 2.5626  last_time: 2.1343  data_time: 1.5885  last_data_time: 1.2230   lr: 0.00099977  max_mem: 4120M\n",
      "\u001b[32m[09/06 20:23:49 d2.utils.events]: \u001b[0m eta: 16 days, 13:08:06  iter: 5819  total_loss: 0.1877  loss_cls: 0.07127  loss_box_reg: 0.1181  loss_rpn_cls: 6.302e-05  loss_rpn_loc: 0.001534    time: 2.5625  last_time: 2.4058  data_time: 1.6219  last_data_time: 1.5178   lr: 0.00099977  max_mem: 4120M\n",
      "\u001b[32m[09/06 20:24:36 d2.utils.events]: \u001b[0m eta: 16 days, 12:31:42  iter: 5839  total_loss: 0.1797  loss_cls: 0.0638  loss_box_reg: 0.1157  loss_rpn_cls: 5.571e-05  loss_rpn_loc: 0.001566    time: 2.5617  last_time: 2.7818  data_time: 1.4703  last_data_time: 1.7495   lr: 0.00099977  max_mem: 4120M\n",
      "\u001b[32m[09/06 20:25:29 d2.utils.events]: \u001b[0m eta: 16 days, 11:49:33  iter: 5859  total_loss: 0.1833  loss_cls: 0.06642  loss_box_reg: 0.1187  loss_rpn_cls: 5.685e-05  loss_rpn_loc: 0.001551    time: 2.5619  last_time: 2.1855  data_time: 1.6577  last_data_time: 1.3194   lr: 0.00099976  max_mem: 4120M\n",
      "\u001b[32m[09/06 20:26:18 d2.utils.events]: \u001b[0m eta: 16 days, 11:03:31  iter: 5879  total_loss: 0.1823  loss_cls: 0.0751  loss_box_reg: 0.1094  loss_rpn_cls: 5.438e-05  loss_rpn_loc: 0.001477    time: 2.5614  last_time: 2.6761  data_time: 1.5069  last_data_time: 1.7625   lr: 0.00099976  max_mem: 4120M\n",
      "\u001b[32m[09/06 20:27:07 d2.utils.events]: \u001b[0m eta: 16 days, 11:34:59  iter: 5899  total_loss: 0.1941  loss_cls: 0.0662  loss_box_reg: 0.1109  loss_rpn_cls: 6.059e-05  loss_rpn_loc: 0.001562    time: 2.5611  last_time: 2.4029  data_time: 1.5665  last_data_time: 1.5141   lr: 0.00099976  max_mem: 4120M\n",
      "\u001b[32m[09/06 20:27:59 d2.utils.events]: \u001b[0m eta: 16 days, 11:44:35  iter: 5919  total_loss: 0.1743  loss_cls: 0.05421  loss_box_reg: 0.1174  loss_rpn_cls: 6.553e-05  loss_rpn_loc: 0.00156    time: 2.5612  last_time: 2.4601  data_time: 1.6323  last_data_time: 1.4919   lr: 0.00099976  max_mem: 4120M\n",
      "\u001b[32m[09/06 20:28:53 d2.utils.events]: \u001b[0m eta: 16 days, 12:40:29  iter: 5939  total_loss: 0.1785  loss_cls: 0.05903  loss_box_reg: 0.1174  loss_rpn_cls: 0.0001142  loss_rpn_loc: 0.001674    time: 2.5618  last_time: 3.8967  data_time: 1.7173  last_data_time: 2.8435   lr: 0.00099976  max_mem: 4120M\n",
      "\u001b[32m[09/06 20:29:50 d2.utils.events]: \u001b[0m eta: 16 days, 13:14:14  iter: 5959  total_loss: 0.2086  loss_cls: 0.08532  loss_box_reg: 0.1149  loss_rpn_cls: 5.64e-05  loss_rpn_loc: 0.001567    time: 2.5629  last_time: 2.6147  data_time: 1.7779  last_data_time: 1.6341   lr: 0.00099976  max_mem: 4120M\n",
      "\u001b[32m[09/06 20:30:45 d2.utils.events]: \u001b[0m eta: 16 days, 14:00:26  iter: 5979  total_loss: 0.1876  loss_cls: 0.06504  loss_box_reg: 0.1092  loss_rpn_cls: 6.072e-05  loss_rpn_loc: 0.001553    time: 2.5637  last_time: 2.7021  data_time: 1.7528  last_data_time: 1.7075   lr: 0.00099976  max_mem: 4120M\n",
      "\u001b[32m[09/06 20:31:59 d2.data.datasets.coco]: \u001b[0mLoaded 1199 images in COCO format from data/ssd_rcnn_face/annotations_val.json\n",
      "\u001b[32m[09/06 20:31:59 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(512, 512), max_size=512, sample_style='choice')]\n",
      "\u001b[32m[09/06 20:31:59 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[09/06 20:31:59 d2.data.common]: \u001b[0mSerializing 1199 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[09/06 20:31:59 d2.data.common]: \u001b[0mSerialized dataset takes 0.36 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[09/06 20:31:59 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n",
      "\u001b[32m[09/06 20:31:59 d2.evaluation.evaluator]: \u001b[0mStart inference on 1199 batches\n",
      "\u001b[32m[09/06 20:32:01 d2.evaluation.evaluator]: \u001b[0mInference done 11/1199. Dataloading: 0.0417 s/iter. Inference: 0.0728 s/iter. Eval: 0.0006 s/iter. Total: 0.1152 s/iter. ETA=0:02:16\n",
      "\u001b[32m[09/06 20:32:06 d2.evaluation.evaluator]: \u001b[0mInference done 44/1199. Dataloading: 0.0799 s/iter. Inference: 0.0711 s/iter. Eval: 0.0006 s/iter. Total: 0.1517 s/iter. ETA=0:02:55\n",
      "\u001b[32m[09/06 20:32:12 d2.evaluation.evaluator]: \u001b[0mInference done 75/1199. Dataloading: 0.0831 s/iter. Inference: 0.0763 s/iter. Eval: 0.0006 s/iter. Total: 0.1601 s/iter. ETA=0:02:59\n",
      "\u001b[32m[09/06 20:32:17 d2.evaluation.evaluator]: \u001b[0mInference done 95/1199. Dataloading: 0.1002 s/iter. Inference: 0.0799 s/iter. Eval: 0.0007 s/iter. Total: 0.1808 s/iter. ETA=0:03:19\n",
      "\u001b[32m[09/06 20:32:22 d2.evaluation.evaluator]: \u001b[0mInference done 119/1199. Dataloading: 0.1065 s/iter. Inference: 0.0796 s/iter. Eval: 0.0007 s/iter. Total: 0.1869 s/iter. ETA=0:03:21\n",
      "\u001b[32m[09/06 20:32:27 d2.evaluation.evaluator]: \u001b[0mInference done 154/1199. Dataloading: 0.0983 s/iter. Inference: 0.0775 s/iter. Eval: 0.0007 s/iter. Total: 0.1767 s/iter. ETA=0:03:04\n",
      "\u001b[32m[09/06 20:32:32 d2.evaluation.evaluator]: \u001b[0mInference done 186/1199. Dataloading: 0.0972 s/iter. Inference: 0.0762 s/iter. Eval: 0.0007 s/iter. Total: 0.1742 s/iter. ETA=0:02:56\n",
      "\u001b[32m[09/06 20:32:37 d2.evaluation.evaluator]: \u001b[0mInference done 218/1199. Dataloading: 0.0971 s/iter. Inference: 0.0753 s/iter. Eval: 0.0007 s/iter. Total: 0.1732 s/iter. ETA=0:02:49\n",
      "\u001b[32m[09/06 20:32:42 d2.evaluation.evaluator]: \u001b[0mInference done 245/1199. Dataloading: 0.0992 s/iter. Inference: 0.0751 s/iter. Eval: 0.0007 s/iter. Total: 0.1751 s/iter. ETA=0:02:47\n",
      "\u001b[32m[09/06 20:32:48 d2.evaluation.evaluator]: \u001b[0mInference done 272/1199. Dataloading: 0.1008 s/iter. Inference: 0.0751 s/iter. Eval: 0.0007 s/iter. Total: 0.1766 s/iter. ETA=0:02:43\n",
      "\u001b[32m[09/06 20:32:53 d2.evaluation.evaluator]: \u001b[0mInference done 288/1199. Dataloading: 0.1086 s/iter. Inference: 0.0753 s/iter. Eval: 0.0006 s/iter. Total: 0.1847 s/iter. ETA=0:02:48\n",
      "\u001b[32m[09/06 20:32:58 d2.evaluation.evaluator]: \u001b[0mInference done 319/1199. Dataloading: 0.1079 s/iter. Inference: 0.0744 s/iter. Eval: 0.0006 s/iter. Total: 0.1831 s/iter. ETA=0:02:41\n",
      "\u001b[32m[09/06 20:33:03 d2.evaluation.evaluator]: \u001b[0mInference done 350/1199. Dataloading: 0.1066 s/iter. Inference: 0.0739 s/iter. Eval: 0.0006 s/iter. Total: 0.1813 s/iter. ETA=0:02:33\n",
      "\u001b[32m[09/06 20:33:08 d2.evaluation.evaluator]: \u001b[0mInference done 375/1199. Dataloading: 0.1074 s/iter. Inference: 0.0746 s/iter. Eval: 0.0006 s/iter. Total: 0.1828 s/iter. ETA=0:02:30\n",
      "\u001b[32m[09/06 20:33:13 d2.evaluation.evaluator]: \u001b[0mInference done 399/1199. Dataloading: 0.1086 s/iter. Inference: 0.0752 s/iter. Eval: 0.0006 s/iter. Total: 0.1845 s/iter. ETA=0:02:27\n",
      "\u001b[32m[09/06 20:33:18 d2.evaluation.evaluator]: \u001b[0mInference done 423/1199. Dataloading: 0.1087 s/iter. Inference: 0.0767 s/iter. Eval: 0.0006 s/iter. Total: 0.1862 s/iter. ETA=0:02:24\n",
      "\u001b[32m[09/06 20:33:23 d2.evaluation.evaluator]: \u001b[0mInference done 451/1199. Dataloading: 0.1079 s/iter. Inference: 0.0774 s/iter. Eval: 0.0006 s/iter. Total: 0.1860 s/iter. ETA=0:02:19\n",
      "\u001b[32m[09/06 20:33:28 d2.evaluation.evaluator]: \u001b[0mInference done 477/1199. Dataloading: 0.1082 s/iter. Inference: 0.0774 s/iter. Eval: 0.0006 s/iter. Total: 0.1864 s/iter. ETA=0:02:14\n",
      "\u001b[32m[09/06 20:33:34 d2.evaluation.evaluator]: \u001b[0mInference done 504/1199. Dataloading: 0.1075 s/iter. Inference: 0.0786 s/iter. Eval: 0.0007 s/iter. Total: 0.1869 s/iter. ETA=0:02:09\n",
      "\u001b[32m[09/06 20:33:39 d2.evaluation.evaluator]: \u001b[0mInference done 534/1199. Dataloading: 0.1073 s/iter. Inference: 0.0781 s/iter. Eval: 0.0007 s/iter. Total: 0.1861 s/iter. ETA=0:02:03\n",
      "\u001b[32m[09/06 20:33:44 d2.evaluation.evaluator]: \u001b[0mInference done 566/1199. Dataloading: 0.1058 s/iter. Inference: 0.0779 s/iter. Eval: 0.0007 s/iter. Total: 0.1845 s/iter. ETA=0:01:56\n",
      "\u001b[32m[09/06 20:33:49 d2.evaluation.evaluator]: \u001b[0mInference done 593/1199. Dataloading: 0.1059 s/iter. Inference: 0.0779 s/iter. Eval: 0.0007 s/iter. Total: 0.1846 s/iter. ETA=0:01:51\n",
      "\u001b[32m[09/06 20:33:54 d2.evaluation.evaluator]: \u001b[0mInference done 625/1199. Dataloading: 0.1045 s/iter. Inference: 0.0780 s/iter. Eval: 0.0007 s/iter. Total: 0.1832 s/iter. ETA=0:01:45\n",
      "\u001b[32m[09/06 20:34:00 d2.evaluation.evaluator]: \u001b[0mInference done 645/1199. Dataloading: 0.1082 s/iter. Inference: 0.0781 s/iter. Eval: 0.0007 s/iter. Total: 0.1871 s/iter. ETA=0:01:43\n",
      "\u001b[32m[09/06 20:34:06 d2.evaluation.evaluator]: \u001b[0mInference done 675/1199. Dataloading: 0.1089 s/iter. Inference: 0.0783 s/iter. Eval: 0.0007 s/iter. Total: 0.1880 s/iter. ETA=0:01:38\n",
      "\u001b[32m[09/06 20:34:12 d2.evaluation.evaluator]: \u001b[0mInference done 710/1199. Dataloading: 0.1071 s/iter. Inference: 0.0784 s/iter. Eval: 0.0007 s/iter. Total: 0.1862 s/iter. ETA=0:01:31\n",
      "\u001b[32m[09/06 20:34:17 d2.evaluation.evaluator]: \u001b[0mInference done 735/1199. Dataloading: 0.1071 s/iter. Inference: 0.0788 s/iter. Eval: 0.0007 s/iter. Total: 0.1867 s/iter. ETA=0:01:26\n",
      "\u001b[32m[09/06 20:34:22 d2.evaluation.evaluator]: \u001b[0mInference done 752/1199. Dataloading: 0.1098 s/iter. Inference: 0.0791 s/iter. Eval: 0.0007 s/iter. Total: 0.1896 s/iter. ETA=0:01:24\n",
      "\u001b[32m[09/06 20:34:27 d2.evaluation.evaluator]: \u001b[0mInference done 782/1199. Dataloading: 0.1094 s/iter. Inference: 0.0787 s/iter. Eval: 0.0007 s/iter. Total: 0.1888 s/iter. ETA=0:01:18\n",
      "\u001b[32m[09/06 20:34:32 d2.evaluation.evaluator]: \u001b[0mInference done 815/1199. Dataloading: 0.1081 s/iter. Inference: 0.0786 s/iter. Eval: 0.0007 s/iter. Total: 0.1874 s/iter. ETA=0:01:11\n",
      "\u001b[32m[09/06 20:34:37 d2.evaluation.evaluator]: \u001b[0mInference done 848/1199. Dataloading: 0.1068 s/iter. Inference: 0.0786 s/iter. Eval: 0.0007 s/iter. Total: 0.1862 s/iter. ETA=0:01:05\n",
      "\u001b[32m[09/06 20:34:42 d2.evaluation.evaluator]: \u001b[0mInference done 873/1199. Dataloading: 0.1072 s/iter. Inference: 0.0787 s/iter. Eval: 0.0007 s/iter. Total: 0.1867 s/iter. ETA=0:01:00\n",
      "\u001b[32m[09/06 20:34:48 d2.evaluation.evaluator]: \u001b[0mInference done 899/1199. Dataloading: 0.1075 s/iter. Inference: 0.0789 s/iter. Eval: 0.0007 s/iter. Total: 0.1872 s/iter. ETA=0:00:56\n",
      "\u001b[32m[09/06 20:34:53 d2.evaluation.evaluator]: \u001b[0mInference done 931/1199. Dataloading: 0.1070 s/iter. Inference: 0.0786 s/iter. Eval: 0.0007 s/iter. Total: 0.1863 s/iter. ETA=0:00:49\n",
      "\u001b[32m[09/06 20:34:59 d2.evaluation.evaluator]: \u001b[0mInference done 963/1199. Dataloading: 0.1072 s/iter. Inference: 0.0785 s/iter. Eval: 0.0006 s/iter. Total: 0.1864 s/iter. ETA=0:00:43\n",
      "\u001b[32m[09/06 20:35:04 d2.evaluation.evaluator]: \u001b[0mInference done 991/1199. Dataloading: 0.1070 s/iter. Inference: 0.0786 s/iter. Eval: 0.0006 s/iter. Total: 0.1863 s/iter. ETA=0:00:38\n",
      "\u001b[32m[09/06 20:35:10 d2.evaluation.evaluator]: \u001b[0mInference done 1019/1199. Dataloading: 0.1076 s/iter. Inference: 0.0786 s/iter. Eval: 0.0006 s/iter. Total: 0.1869 s/iter. ETA=0:00:33\n",
      "\u001b[32m[09/06 20:35:15 d2.evaluation.evaluator]: \u001b[0mInference done 1046/1199. Dataloading: 0.1075 s/iter. Inference: 0.0790 s/iter. Eval: 0.0007 s/iter. Total: 0.1872 s/iter. ETA=0:00:28\n",
      "\u001b[32m[09/06 20:35:21 d2.evaluation.evaluator]: \u001b[0mInference done 1075/1199. Dataloading: 0.1075 s/iter. Inference: 0.0789 s/iter. Eval: 0.0007 s/iter. Total: 0.1872 s/iter. ETA=0:00:23\n",
      "\u001b[32m[09/06 20:35:26 d2.evaluation.evaluator]: \u001b[0mInference done 1103/1199. Dataloading: 0.1075 s/iter. Inference: 0.0789 s/iter. Eval: 0.0006 s/iter. Total: 0.1872 s/iter. ETA=0:00:17\n",
      "\u001b[32m[09/06 20:35:31 d2.evaluation.evaluator]: \u001b[0mInference done 1128/1199. Dataloading: 0.1082 s/iter. Inference: 0.0788 s/iter. Eval: 0.0006 s/iter. Total: 0.1878 s/iter. ETA=0:00:13\n",
      "\u001b[32m[09/06 20:35:36 d2.evaluation.evaluator]: \u001b[0mInference done 1158/1199. Dataloading: 0.1077 s/iter. Inference: 0.0788 s/iter. Eval: 0.0006 s/iter. Total: 0.1873 s/iter. ETA=0:00:07\n",
      "\u001b[32m[09/06 20:35:42 d2.evaluation.evaluator]: \u001b[0mInference done 1186/1199. Dataloading: 0.1075 s/iter. Inference: 0.0789 s/iter. Eval: 0.0006 s/iter. Total: 0.1872 s/iter. ETA=0:00:02\n",
      "\u001b[32m[09/06 20:35:44 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:03:43.488962 (0.187177 s / iter per device, on 1 devices)\n",
      "\u001b[32m[09/06 20:35:44 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:01:34 (0.078814 s / iter per device, on 1 devices)\n",
      "\u001b[32m[09/06 20:35:44 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[09/06 20:35:44 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.02s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[09/06 20:35:44 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[09/06 20:35:44 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.24 seconds.\n",
      "\u001b[32m[09/06 20:35:44 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[09/06 20:35:44 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.02 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.717\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.854\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.844\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.717\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.851\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.851\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.851\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.851\n",
      "\u001b[32m[09/06 20:35:44 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
      "| 71.734 | 85.404 | 84.447 |  nan  |  nan  | 71.734 |\n",
      "\u001b[32m[09/06 20:35:44 d2.evaluation.coco_evaluation]: \u001b[0mSome metrics cannot be computed and is shown as NaN.\n",
      "\u001b[32m[09/06 20:35:44 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category   | AP     | category   | AP     | category   | AP     |\n",
      "|:-----------|:-------|:-----------|:-------|:-----------|:-------|\n",
      "| angry      | 64.804 | sad        | 74.077 | surprised  | 67.137 |\n",
      "| happy      | 80.920 |            |        |            |        |\n",
      "\u001b[32m[09/06 20:35:44 d2.engine.defaults]: \u001b[0mEvaluation results for face_data_set_valid in csv format:\n",
      "\u001b[32m[09/06 20:35:44 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[09/06 20:35:44 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[09/06 20:35:44 d2.evaluation.testing]: \u001b[0mcopypaste: 71.7344,85.4036,84.4470,nan,nan,71.7344\n",
      "\u001b[32m[09/06 20:35:44 d2.utils.events]: \u001b[0m eta: 16 days, 14:22:09  iter: 5999  total_loss: 0.1988  loss_cls: 0.07643  loss_box_reg: 0.1164  loss_rpn_cls: 6.263e-05  loss_rpn_loc: 0.001412    time: 2.5677  last_time: 2.6701  data_time: 2.2868  last_data_time: 1.6235   lr: 0.00099975  max_mem: 4120M\n",
      "\u001b[32m[09/06 20:36:45 d2.utils.events]: \u001b[0m eta: 16 days, 14:51:40  iter: 6019  total_loss: 0.1971  loss_cls: 0.07309  loss_box_reg: 0.1242  loss_rpn_cls: 8.197e-05  loss_rpn_loc: 0.001543    time: 2.5696  last_time: 2.1481  data_time: 1.9590  last_data_time: 1.2238   lr: 0.00099975  max_mem: 4120M\n",
      "\u001b[32m[09/06 20:37:38 d2.utils.events]: \u001b[0m eta: 16 days, 15:56:06  iter: 6039  total_loss: 0.1907  loss_cls: 0.07141  loss_box_reg: 0.1227  loss_rpn_cls: 6.282e-05  loss_rpn_loc: 0.001598    time: 2.5699  last_time: 2.5001  data_time: 1.6553  last_data_time: 1.4826   lr: 0.00099975  max_mem: 4120M\n",
      "\u001b[32m[09/06 20:38:27 d2.utils.events]: \u001b[0m eta: 16 days, 15:30:44  iter: 6059  total_loss: 0.1791  loss_cls: 0.06496  loss_box_reg: 0.1077  loss_rpn_cls: 5.453e-05  loss_rpn_loc: 0.001384    time: 2.5695  last_time: 2.8356  data_time: 1.5231  last_data_time: 1.8512   lr: 0.00099975  max_mem: 4120M\n",
      "\u001b[32m[09/06 20:39:15 d2.utils.events]: \u001b[0m eta: 16 days, 14:49:15  iter: 6079  total_loss: 0.1777  loss_cls: 0.07054  loss_box_reg: 0.1097  loss_rpn_cls: 8.124e-05  loss_rpn_loc: 0.00142    time: 2.5687  last_time: 2.3147  data_time: 1.4119  last_data_time: 1.3260   lr: 0.00099975  max_mem: 4120M\n",
      "\u001b[32m[09/06 20:40:03 d2.utils.events]: \u001b[0m eta: 16 days, 14:27:43  iter: 6099  total_loss: 0.1861  loss_cls: 0.06728  loss_box_reg: 0.1169  loss_rpn_cls: 0.0001113  loss_rpn_loc: 0.001504    time: 2.5681  last_time: 2.2452  data_time: 1.5104  last_data_time: 1.3077   lr: 0.00099975  max_mem: 4120M\n",
      "\u001b[32m[09/06 20:40:53 d2.utils.events]: \u001b[0m eta: 16 days, 14:54:23  iter: 6119  total_loss: 0.1887  loss_cls: 0.06521  loss_box_reg: 0.113  loss_rpn_cls: 5.402e-05  loss_rpn_loc: 0.001512    time: 2.5678  last_time: 2.4597  data_time: 1.5501  last_data_time: 1.5389   lr: 0.00099974  max_mem: 4120M\n",
      "\u001b[32m[09/06 20:41:46 d2.utils.events]: \u001b[0m eta: 16 days, 15:35:58  iter: 6139  total_loss: 0.1832  loss_cls: 0.06996  loss_box_reg: 0.1197  loss_rpn_cls: 7.806e-05  loss_rpn_loc: 0.001458    time: 2.5681  last_time: 2.9357  data_time: 1.6441  last_data_time: 1.8523   lr: 0.00099974  max_mem: 4120M\n",
      "\u001b[32m[09/06 20:42:38 d2.utils.events]: \u001b[0m eta: 16 days, 16:01:22  iter: 6159  total_loss: 0.1877  loss_cls: 0.05419  loss_box_reg: 0.1212  loss_rpn_cls: 6.584e-05  loss_rpn_loc: 0.001546    time: 2.5682  last_time: 2.2091  data_time: 1.6197  last_data_time: 1.3802   lr: 0.00099974  max_mem: 4120M\n",
      "\u001b[32m[09/06 20:43:29 d2.utils.events]: \u001b[0m eta: 16 days, 17:16:48  iter: 6179  total_loss: 0.1899  loss_cls: 0.06877  loss_box_reg: 0.1174  loss_rpn_cls: 7.158e-05  loss_rpn_loc: 0.001505    time: 2.5682  last_time: 2.2617  data_time: 1.5945  last_data_time: 1.3753   lr: 0.00099974  max_mem: 4120M\n",
      "\u001b[32m[09/06 20:44:19 d2.utils.events]: \u001b[0m eta: 16 days, 17:15:59  iter: 6199  total_loss: 0.1864  loss_cls: 0.06514  loss_box_reg: 0.1193  loss_rpn_cls: 5.412e-05  loss_rpn_loc: 0.001366    time: 2.5679  last_time: 2.9712  data_time: 1.5247  last_data_time: 1.9087   lr: 0.00099974  max_mem: 4120M\n",
      "\u001b[32m[09/06 20:45:10 d2.utils.events]: \u001b[0m eta: 16 days, 17:53:04  iter: 6219  total_loss: 0.1744  loss_cls: 0.05946  loss_box_reg: 0.1114  loss_rpn_cls: 5.788e-05  loss_rpn_loc: 0.001576    time: 2.5678  last_time: 2.4833  data_time: 1.5961  last_data_time: 1.5837   lr: 0.00099974  max_mem: 4120M\n",
      "\u001b[32m[09/06 20:45:58 d2.utils.events]: \u001b[0m eta: 16 days, 17:59:50  iter: 6239  total_loss: 0.1781  loss_cls: 0.05567  loss_box_reg: 0.1159  loss_rpn_cls: 8.333e-05  loss_rpn_loc: 0.001623    time: 2.5672  last_time: 2.4220  data_time: 1.4845  last_data_time: 1.4757   lr: 0.00099973  max_mem: 4120M\n",
      "\u001b[32m[09/06 20:46:47 d2.utils.events]: \u001b[0m eta: 16 days, 17:34:57  iter: 6259  total_loss: 0.1833  loss_cls: 0.06406  loss_box_reg: 0.116  loss_rpn_cls: 7.977e-05  loss_rpn_loc: 0.001404    time: 2.5667  last_time: 2.5902  data_time: 1.5121  last_data_time: 1.6243   lr: 0.00099973  max_mem: 4120M\n",
      "\u001b[32m[09/06 20:47:34 d2.utils.events]: \u001b[0m eta: 16 days, 17:24:28  iter: 6279  total_loss: 0.1915  loss_cls: 0.07607  loss_box_reg: 0.1215  loss_rpn_cls: 7.391e-05  loss_rpn_loc: 0.001484    time: 2.5659  last_time: 2.6719  data_time: 1.4354  last_data_time: 1.7857   lr: 0.00099973  max_mem: 4120M\n",
      "\u001b[32m[09/06 20:48:25 d2.utils.events]: \u001b[0m eta: 16 days, 17:10:16  iter: 6299  total_loss: 0.1742  loss_cls: 0.05621  loss_box_reg: 0.107  loss_rpn_cls: 5.503e-05  loss_rpn_loc: 0.001611    time: 2.5659  last_time: 2.5984  data_time: 1.6534  last_data_time: 1.6760   lr: 0.00099973  max_mem: 4120M\n",
      "\u001b[32m[09/06 20:49:14 d2.utils.events]: \u001b[0m eta: 16 days, 17:17:17  iter: 6319  total_loss: 0.1789  loss_cls: 0.05723  loss_box_reg: 0.1172  loss_rpn_cls: 4.551e-05  loss_rpn_loc: 0.001352    time: 2.5654  last_time: 2.2970  data_time: 1.5016  last_data_time: 1.3544   lr: 0.00099973  max_mem: 4120M\n",
      "\u001b[32m[09/06 20:50:01 d2.utils.events]: \u001b[0m eta: 16 days, 16:43:44  iter: 6339  total_loss: 0.1928  loss_cls: 0.06386  loss_box_reg: 0.1249  loss_rpn_cls: 5.68e-05  loss_rpn_loc: 0.001568    time: 2.5646  last_time: 2.0570  data_time: 1.4657  last_data_time: 1.2212   lr: 0.00099972  max_mem: 4120M\n",
      "\u001b[32m[09/06 20:50:50 d2.utils.events]: \u001b[0m eta: 16 days, 15:34:04  iter: 6359  total_loss: 0.1809  loss_cls: 0.05635  loss_box_reg: 0.1203  loss_rpn_cls: 9.081e-05  loss_rpn_loc: 0.001499    time: 2.5641  last_time: 2.3279  data_time: 1.5162  last_data_time: 1.2761   lr: 0.00099972  max_mem: 4120M\n",
      "\u001b[32m[09/06 20:51:41 d2.utils.events]: \u001b[0m eta: 16 days, 16:04:07  iter: 6379  total_loss: 0.1762  loss_cls: 0.05393  loss_box_reg: 0.1148  loss_rpn_cls: 4.097e-05  loss_rpn_loc: 0.001423    time: 2.5641  last_time: 2.9851  data_time: 1.5877  last_data_time: 1.7881   lr: 0.00099972  max_mem: 4120M\n",
      "\u001b[32m[09/06 20:52:32 d2.utils.events]: \u001b[0m eta: 16 days, 16:41:18  iter: 6399  total_loss: 0.1865  loss_cls: 0.05909  loss_box_reg: 0.1149  loss_rpn_cls: 5.59e-05  loss_rpn_loc: 0.001611    time: 2.5640  last_time: 3.7666  data_time: 1.5962  last_data_time: 2.5900   lr: 0.00099972  max_mem: 4120M\n",
      "\u001b[32m[09/06 20:53:19 d2.utils.events]: \u001b[0m eta: 16 days, 16:40:29  iter: 6419  total_loss: 0.1856  loss_cls: 0.06638  loss_box_reg: 0.1196  loss_rpn_cls: 5.421e-05  loss_rpn_loc: 0.001368    time: 2.5633  last_time: 2.3321  data_time: 1.4557  last_data_time: 1.4273   lr: 0.00099972  max_mem: 4120M\n",
      "\u001b[32m[09/06 20:54:09 d2.utils.events]: \u001b[0m eta: 16 days, 16:49:25  iter: 6439  total_loss: 0.1908  loss_cls: 0.0651  loss_box_reg: 0.1114  loss_rpn_cls: 4.602e-05  loss_rpn_loc: 0.001531    time: 2.5630  last_time: 2.1929  data_time: 1.5781  last_data_time: 1.3255   lr: 0.00099972  max_mem: 4120M\n",
      "\u001b[32m[09/06 20:54:58 d2.utils.events]: \u001b[0m eta: 16 days, 16:57:37  iter: 6459  total_loss: 0.1965  loss_cls: 0.07207  loss_box_reg: 0.1156  loss_rpn_cls: 7.164e-05  loss_rpn_loc: 0.001526    time: 2.5625  last_time: 2.6471  data_time: 1.5211  last_data_time: 1.6997   lr: 0.00099971  max_mem: 4120M\n",
      "\u001b[32m[09/06 20:55:46 d2.utils.events]: \u001b[0m eta: 16 days, 17:02:58  iter: 6479  total_loss: 0.1958  loss_cls: 0.07565  loss_box_reg: 0.1151  loss_rpn_cls: 4.679e-05  loss_rpn_loc: 0.00167    time: 2.5621  last_time: 2.3820  data_time: 1.5428  last_data_time: 1.5226   lr: 0.00099971  max_mem: 4120M\n",
      "\u001b[32m[09/06 20:56:35 d2.utils.events]: \u001b[0m eta: 16 days, 16:55:59  iter: 6499  total_loss: 0.1799  loss_cls: 0.06043  loss_box_reg: 0.1166  loss_rpn_cls: 5.42e-05  loss_rpn_loc: 0.001444    time: 2.5612  last_time: 2.7407  data_time: 1.3994  last_data_time: 1.6417   lr: 0.00099971  max_mem: 4120M\n",
      "\u001b[32m[09/06 20:57:35 d2.utils.events]: \u001b[0m eta: 16 days, 18:49:49  iter: 6519  total_loss: 0.1849  loss_cls: 0.07293  loss_box_reg: 0.1109  loss_rpn_cls: 4.494e-05  loss_rpn_loc: 0.001487    time: 2.5628  last_time: 3.1174  data_time: 1.9049  last_data_time: 1.9763   lr: 0.00099971  max_mem: 4120M\n",
      "\u001b[32m[09/06 20:58:33 d2.utils.events]: \u001b[0m eta: 16 days, 20:43:41  iter: 6539  total_loss: 0.1773  loss_cls: 0.06255  loss_box_reg: 0.1107  loss_rpn_cls: 7.021e-05  loss_rpn_loc: 0.001554    time: 2.5640  last_time: 2.6651  data_time: 1.8360  last_data_time: 1.6835   lr: 0.00099971  max_mem: 4120M\n",
      "\u001b[32m[09/06 20:59:31 d2.utils.events]: \u001b[0m eta: 16 days, 22:04:01  iter: 6559  total_loss: 0.2  loss_cls: 0.07764  loss_box_reg: 0.1102  loss_rpn_cls: 4.563e-05  loss_rpn_loc: 0.001347    time: 2.5652  last_time: 2.5955  data_time: 1.8298  last_data_time: 1.6080   lr: 0.00099971  max_mem: 4120M\n",
      "\u001b[32m[09/06 21:00:29 d2.utils.events]: \u001b[0m eta: 16 days, 22:35:27  iter: 6579  total_loss: 0.1974  loss_cls: 0.07462  loss_box_reg: 0.1192  loss_rpn_cls: 9.23e-05  loss_rpn_loc: 0.001452    time: 2.5665  last_time: 3.6492  data_time: 1.8467  last_data_time: 2.1763   lr: 0.0009997  max_mem: 4120M\n",
      "\u001b[32m[09/06 21:01:34 d2.utils.events]: \u001b[0m eta: 16 days, 22:36:47  iter: 6599  total_loss: 0.1817  loss_cls: 0.07352  loss_box_reg: 0.1079  loss_rpn_cls: 6.307e-05  loss_rpn_loc: 0.001476    time: 2.5688  last_time: 3.1742  data_time: 2.1207  last_data_time: 2.0891   lr: 0.0009997  max_mem: 4120M\n",
      "\u001b[32m[09/06 21:02:30 d2.utils.events]: \u001b[0m eta: 16 days, 22:19:30  iter: 6619  total_loss: 0.1819  loss_cls: 0.06684  loss_box_reg: 0.1136  loss_rpn_cls: 4.776e-05  loss_rpn_loc: 0.001422    time: 2.5696  last_time: 3.2751  data_time: 1.7695  last_data_time: 2.1159   lr: 0.0009997  max_mem: 4120M\n",
      "\u001b[32m[09/06 21:03:33 d2.utils.events]: \u001b[0m eta: 16 days, 22:40:07  iter: 6639  total_loss: 0.1776  loss_cls: 0.06903  loss_box_reg: 0.1119  loss_rpn_cls: 5.761e-05  loss_rpn_loc: 0.001475    time: 2.5718  last_time: 3.2943  data_time: 2.0533  last_data_time: 2.0938   lr: 0.0009997  max_mem: 4120M\n",
      "\u001b[32m[09/06 21:04:31 d2.utils.events]: \u001b[0m eta: 16 days, 22:34:19  iter: 6659  total_loss: 0.1572  loss_cls: 0.04946  loss_box_reg: 0.116  loss_rpn_cls: 7.896e-05  loss_rpn_loc: 0.001471    time: 2.5729  last_time: 3.0014  data_time: 1.7858  last_data_time: 1.8366   lr: 0.0009997  max_mem: 4120M\n",
      "\u001b[32m[09/06 21:05:26 d2.utils.events]: \u001b[0m eta: 16 days, 23:55:02  iter: 6679  total_loss: 0.1834  loss_cls: 0.06716  loss_box_reg: 0.1171  loss_rpn_cls: 6.004e-05  loss_rpn_loc: 0.001388    time: 2.5735  last_time: 2.8279  data_time: 1.7490  last_data_time: 1.8347   lr: 0.00099969  max_mem: 4120M\n",
      "\u001b[32m[09/06 21:06:13 d2.utils.events]: \u001b[0m eta: 17 days, 0:28:02  iter: 6699  total_loss: 0.1792  loss_cls: 0.06302  loss_box_reg: 0.1182  loss_rpn_cls: 7.598e-05  loss_rpn_loc: 0.001594    time: 2.5728  last_time: 2.1760  data_time: 1.4525  last_data_time: 1.2852   lr: 0.00099969  max_mem: 4120M\n",
      "\u001b[32m[09/06 21:07:02 d2.utils.events]: \u001b[0m eta: 17 days, 0:55:33  iter: 6719  total_loss: 0.1698  loss_cls: 0.05823  loss_box_reg: 0.1184  loss_rpn_cls: 5.514e-05  loss_rpn_loc: 0.001547    time: 2.5722  last_time: 3.0708  data_time: 1.4944  last_data_time: 1.9272   lr: 0.00099969  max_mem: 4120M\n",
      "\u001b[32m[09/06 21:07:51 d2.utils.events]: \u001b[0m eta: 17 days, 1:11:31  iter: 6739  total_loss: 0.1736  loss_cls: 0.04601  loss_box_reg: 0.1143  loss_rpn_cls: 8.384e-05  loss_rpn_loc: 0.00147    time: 2.5718  last_time: 2.1872  data_time: 1.4974  last_data_time: 1.2401   lr: 0.00099969  max_mem: 4120M\n",
      "\u001b[32m[09/06 21:08:39 d2.utils.events]: \u001b[0m eta: 17 days, 1:45:50  iter: 6759  total_loss: 0.1869  loss_cls: 0.06666  loss_box_reg: 0.114  loss_rpn_cls: 0.0001258  loss_rpn_loc: 0.001577    time: 2.5712  last_time: 2.4075  data_time: 1.4661  last_data_time: 1.4387   lr: 0.00099969  max_mem: 4120M\n",
      "\u001b[32m[09/06 21:09:30 d2.utils.events]: \u001b[0m eta: 17 days, 2:47:00  iter: 6779  total_loss: 0.1836  loss_cls: 0.06686  loss_box_reg: 0.1135  loss_rpn_cls: 9.503e-05  loss_rpn_loc: 0.00156    time: 2.5711  last_time: 2.6533  data_time: 1.5994  last_data_time: 1.6767   lr: 0.00099969  max_mem: 4120M\n",
      "\u001b[32m[09/06 21:10:25 d2.utils.events]: \u001b[0m eta: 17 days, 4:11:09  iter: 6799  total_loss: 0.1721  loss_cls: 0.05453  loss_box_reg: 0.1182  loss_rpn_cls: 6.481e-05  loss_rpn_loc: 0.001392    time: 2.5718  last_time: 2.6991  data_time: 1.7728  last_data_time: 1.6907   lr: 0.00099968  max_mem: 4120M\n",
      "\u001b[32m[09/06 21:11:20 d2.utils.events]: \u001b[0m eta: 17 days, 5:25:29  iter: 6819  total_loss: 0.1563  loss_cls: 0.04184  loss_box_reg: 0.1102  loss_rpn_cls: 7.809e-05  loss_rpn_loc: 0.001411    time: 2.5724  last_time: 3.5216  data_time: 1.7394  last_data_time: 2.4195   lr: 0.00099968  max_mem: 4120M\n",
      "\u001b[32m[09/06 21:12:12 d2.utils.events]: \u001b[0m eta: 17 days, 6:28:36  iter: 6839  total_loss: 0.174  loss_cls: 0.05561  loss_box_reg: 0.1056  loss_rpn_cls: 4.57e-05  loss_rpn_loc: 0.001641    time: 2.5726  last_time: 2.3583  data_time: 1.6559  last_data_time: 1.4940   lr: 0.00099968  max_mem: 4120M\n",
      "\u001b[32m[09/06 21:13:07 d2.utils.events]: \u001b[0m eta: 17 days, 7:24:23  iter: 6859  total_loss: 0.1828  loss_cls: 0.06491  loss_box_reg: 0.1155  loss_rpn_cls: 7.477e-05  loss_rpn_loc: 0.001448    time: 2.5732  last_time: 3.1512  data_time: 1.7323  last_data_time: 2.0146   lr: 0.00099968  max_mem: 4120M\n",
      "\u001b[32m[09/06 21:14:05 d2.utils.events]: \u001b[0m eta: 17 days, 8:26:40  iter: 6879  total_loss: 0.1806  loss_cls: 0.05886  loss_box_reg: 0.1051  loss_rpn_cls: 7.462e-05  loss_rpn_loc: 0.001468    time: 2.5742  last_time: 2.6148  data_time: 1.8341  last_data_time: 1.6376   lr: 0.00099968  max_mem: 4120M\n",
      "\u001b[32m[09/06 21:14:59 d2.utils.events]: \u001b[0m eta: 17 days, 8:52:33  iter: 6899  total_loss: 0.1796  loss_cls: 0.06547  loss_box_reg: 0.1127  loss_rpn_cls: 5.995e-05  loss_rpn_loc: 0.001455    time: 2.5747  last_time: 2.6224  data_time: 1.7320  last_data_time: 1.6818   lr: 0.00099967  max_mem: 4120M\n",
      "\u001b[32m[09/06 21:15:55 d2.utils.events]: \u001b[0m eta: 17 days, 9:58:31  iter: 6919  total_loss: 0.195  loss_cls: 0.08776  loss_box_reg: 0.1134  loss_rpn_cls: 7.068e-05  loss_rpn_loc: 0.001681    time: 2.5754  last_time: 2.3043  data_time: 1.7530  last_data_time: 1.3517   lr: 0.00099967  max_mem: 4120M\n",
      "\u001b[32m[09/06 21:16:51 d2.utils.events]: \u001b[0m eta: 17 days, 9:58:55  iter: 6939  total_loss: 0.1864  loss_cls: 0.06492  loss_box_reg: 0.1134  loss_rpn_cls: 6.276e-05  loss_rpn_loc: 0.001489    time: 2.5762  last_time: 2.9890  data_time: 1.7817  last_data_time: 1.8525   lr: 0.00099967  max_mem: 4120M\n",
      "\u001b[32m[09/06 21:17:50 d2.utils.events]: \u001b[0m eta: 17 days, 10:05:25  iter: 6959  total_loss: 0.1858  loss_cls: 0.06733  loss_box_reg: 0.121  loss_rpn_cls: 5.46e-05  loss_rpn_loc: 0.001506    time: 2.5775  last_time: 2.8608  data_time: 1.9051  last_data_time: 1.8558   lr: 0.00099967  max_mem: 4120M\n",
      "\u001b[32m[09/06 21:18:47 d2.utils.events]: \u001b[0m eta: 17 days, 10:38:34  iter: 6979  total_loss: 0.1949  loss_cls: 0.07421  loss_box_reg: 0.1164  loss_rpn_cls: 6.081e-05  loss_rpn_loc: 0.001548    time: 2.5784  last_time: 2.9560  data_time: 1.7768  last_data_time: 1.8321   lr: 0.00099967  max_mem: 4120M\n",
      "\u001b[32m[09/06 21:19:42 d2.data.datasets.coco]: \u001b[0mLoaded 1199 images in COCO format from data/ssd_rcnn_face/annotations_val.json\n",
      "\u001b[32m[09/06 21:19:42 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(512, 512), max_size=512, sample_style='choice')]\n",
      "\u001b[32m[09/06 21:19:42 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[09/06 21:19:42 d2.data.common]: \u001b[0mSerializing 1199 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[09/06 21:19:42 d2.data.common]: \u001b[0mSerialized dataset takes 0.36 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[09/06 21:19:42 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n",
      "\u001b[32m[09/06 21:19:42 d2.evaluation.evaluator]: \u001b[0mStart inference on 1199 batches\n",
      "\u001b[32m[09/06 21:19:44 d2.evaluation.evaluator]: \u001b[0mInference done 11/1199. Dataloading: 0.0553 s/iter. Inference: 0.0632 s/iter. Eval: 0.0005 s/iter. Total: 0.1190 s/iter. ETA=0:02:21\n",
      "\u001b[32m[09/06 21:19:49 d2.evaluation.evaluator]: \u001b[0mInference done 44/1199. Dataloading: 0.0856 s/iter. Inference: 0.0634 s/iter. Eval: 0.0006 s/iter. Total: 0.1497 s/iter. ETA=0:02:52\n",
      "\u001b[32m[09/06 21:19:54 d2.evaluation.evaluator]: \u001b[0mInference done 79/1199. Dataloading: 0.0877 s/iter. Inference: 0.0632 s/iter. Eval: 0.0006 s/iter. Total: 0.1516 s/iter. ETA=0:02:49\n",
      "\u001b[32m[09/06 21:19:59 d2.evaluation.evaluator]: \u001b[0mInference done 106/1199. Dataloading: 0.0943 s/iter. Inference: 0.0663 s/iter. Eval: 0.0006 s/iter. Total: 0.1613 s/iter. ETA=0:02:56\n",
      "\u001b[32m[09/06 21:20:04 d2.evaluation.evaluator]: \u001b[0mInference done 129/1199. Dataloading: 0.1045 s/iter. Inference: 0.0670 s/iter. Eval: 0.0006 s/iter. Total: 0.1722 s/iter. ETA=0:03:04\n",
      "\u001b[32m[09/06 21:20:10 d2.evaluation.evaluator]: \u001b[0mInference done 165/1199. Dataloading: 0.0983 s/iter. Inference: 0.0670 s/iter. Eval: 0.0006 s/iter. Total: 0.1660 s/iter. ETA=0:02:51\n",
      "\u001b[32m[09/06 21:20:15 d2.evaluation.evaluator]: \u001b[0mInference done 195/1199. Dataloading: 0.0981 s/iter. Inference: 0.0674 s/iter. Eval: 0.0006 s/iter. Total: 0.1662 s/iter. ETA=0:02:46\n",
      "\u001b[32m[09/06 21:20:20 d2.evaluation.evaluator]: \u001b[0mInference done 221/1199. Dataloading: 0.1009 s/iter. Inference: 0.0689 s/iter. Eval: 0.0006 s/iter. Total: 0.1705 s/iter. ETA=0:02:46\n",
      "\u001b[32m[09/06 21:20:25 d2.evaluation.evaluator]: \u001b[0mInference done 244/1199. Dataloading: 0.1040 s/iter. Inference: 0.0705 s/iter. Eval: 0.0006 s/iter. Total: 0.1753 s/iter. ETA=0:02:47\n",
      "\u001b[32m[09/06 21:20:30 d2.evaluation.evaluator]: \u001b[0mInference done 272/1199. Dataloading: 0.1060 s/iter. Inference: 0.0703 s/iter. Eval: 0.0006 s/iter. Total: 0.1770 s/iter. ETA=0:02:44\n",
      "\u001b[32m[09/06 21:20:35 d2.evaluation.evaluator]: \u001b[0mInference done 284/1199. Dataloading: 0.1155 s/iter. Inference: 0.0711 s/iter. Eval: 0.0006 s/iter. Total: 0.1873 s/iter. ETA=0:02:51\n",
      "\u001b[32m[09/06 21:20:40 d2.evaluation.evaluator]: \u001b[0mInference done 314/1199. Dataloading: 0.1138 s/iter. Inference: 0.0710 s/iter. Eval: 0.0006 s/iter. Total: 0.1855 s/iter. ETA=0:02:44\n",
      "\u001b[32m[09/06 21:20:46 d2.evaluation.evaluator]: \u001b[0mInference done 346/1199. Dataloading: 0.1120 s/iter. Inference: 0.0711 s/iter. Eval: 0.0006 s/iter. Total: 0.1838 s/iter. ETA=0:02:36\n",
      "\u001b[32m[09/06 21:20:51 d2.evaluation.evaluator]: \u001b[0mInference done 376/1199. Dataloading: 0.1118 s/iter. Inference: 0.0708 s/iter. Eval: 0.0006 s/iter. Total: 0.1833 s/iter. ETA=0:02:30\n",
      "\u001b[32m[09/06 21:20:56 d2.evaluation.evaluator]: \u001b[0mInference done 408/1199. Dataloading: 0.1110 s/iter. Inference: 0.0705 s/iter. Eval: 0.0006 s/iter. Total: 0.1822 s/iter. ETA=0:02:24\n",
      "\u001b[32m[09/06 21:21:01 d2.evaluation.evaluator]: \u001b[0mInference done 444/1199. Dataloading: 0.1077 s/iter. Inference: 0.0704 s/iter. Eval: 0.0006 s/iter. Total: 0.1788 s/iter. ETA=0:02:15\n",
      "\u001b[32m[09/06 21:21:07 d2.evaluation.evaluator]: \u001b[0mInference done 473/1199. Dataloading: 0.1077 s/iter. Inference: 0.0701 s/iter. Eval: 0.0006 s/iter. Total: 0.1785 s/iter. ETA=0:02:09\n",
      "\u001b[32m[09/06 21:21:12 d2.evaluation.evaluator]: \u001b[0mInference done 502/1199. Dataloading: 0.1065 s/iter. Inference: 0.0711 s/iter. Eval: 0.0006 s/iter. Total: 0.1783 s/iter. ETA=0:02:04\n",
      "\u001b[32m[09/06 21:21:17 d2.evaluation.evaluator]: \u001b[0mInference done 528/1199. Dataloading: 0.1067 s/iter. Inference: 0.0717 s/iter. Eval: 0.0006 s/iter. Total: 0.1792 s/iter. ETA=0:02:00\n",
      "\u001b[32m[09/06 21:21:22 d2.evaluation.evaluator]: \u001b[0mInference done 557/1199. Dataloading: 0.1064 s/iter. Inference: 0.0718 s/iter. Eval: 0.0006 s/iter. Total: 0.1789 s/iter. ETA=0:01:54\n",
      "\u001b[32m[09/06 21:21:27 d2.evaluation.evaluator]: \u001b[0mInference done 589/1199. Dataloading: 0.1054 s/iter. Inference: 0.0716 s/iter. Eval: 0.0006 s/iter. Total: 0.1778 s/iter. ETA=0:01:48\n",
      "\u001b[32m[09/06 21:21:32 d2.evaluation.evaluator]: \u001b[0mInference done 624/1199. Dataloading: 0.1040 s/iter. Inference: 0.0711 s/iter. Eval: 0.0006 s/iter. Total: 0.1758 s/iter. ETA=0:01:41\n",
      "\u001b[32m[09/06 21:21:37 d2.evaluation.evaluator]: \u001b[0mInference done 645/1199. Dataloading: 0.1064 s/iter. Inference: 0.0709 s/iter. Eval: 0.0006 s/iter. Total: 0.1781 s/iter. ETA=0:01:38\n",
      "\u001b[32m[09/06 21:21:42 d2.evaluation.evaluator]: \u001b[0mInference done 675/1199. Dataloading: 0.1067 s/iter. Inference: 0.0706 s/iter. Eval: 0.0006 s/iter. Total: 0.1780 s/iter. ETA=0:01:33\n",
      "\u001b[32m[09/06 21:21:47 d2.evaluation.evaluator]: \u001b[0mInference done 713/1199. Dataloading: 0.1044 s/iter. Inference: 0.0705 s/iter. Eval: 0.0006 s/iter. Total: 0.1756 s/iter. ETA=0:01:25\n",
      "\u001b[32m[09/06 21:21:53 d2.evaluation.evaluator]: \u001b[0mInference done 744/1199. Dataloading: 0.1043 s/iter. Inference: 0.0703 s/iter. Eval: 0.0006 s/iter. Total: 0.1753 s/iter. ETA=0:01:19\n",
      "\u001b[32m[09/06 21:21:58 d2.evaluation.evaluator]: \u001b[0mInference done 764/1199. Dataloading: 0.1067 s/iter. Inference: 0.0702 s/iter. Eval: 0.0006 s/iter. Total: 0.1776 s/iter. ETA=0:01:17\n",
      "\u001b[32m[09/06 21:22:03 d2.evaluation.evaluator]: \u001b[0mInference done 797/1199. Dataloading: 0.1058 s/iter. Inference: 0.0702 s/iter. Eval: 0.0006 s/iter. Total: 0.1767 s/iter. ETA=0:01:11\n",
      "\u001b[32m[09/06 21:22:08 d2.evaluation.evaluator]: \u001b[0mInference done 831/1199. Dataloading: 0.1049 s/iter. Inference: 0.0702 s/iter. Eval: 0.0006 s/iter. Total: 0.1758 s/iter. ETA=0:01:04\n",
      "\u001b[32m[09/06 21:22:13 d2.evaluation.evaluator]: \u001b[0mInference done 864/1199. Dataloading: 0.1039 s/iter. Inference: 0.0703 s/iter. Eval: 0.0006 s/iter. Total: 0.1749 s/iter. ETA=0:00:58\n",
      "\u001b[32m[09/06 21:22:19 d2.evaluation.evaluator]: \u001b[0mInference done 893/1199. Dataloading: 0.1039 s/iter. Inference: 0.0705 s/iter. Eval: 0.0006 s/iter. Total: 0.1751 s/iter. ETA=0:00:53\n",
      "\u001b[32m[09/06 21:22:24 d2.evaluation.evaluator]: \u001b[0mInference done 924/1199. Dataloading: 0.1037 s/iter. Inference: 0.0704 s/iter. Eval: 0.0006 s/iter. Total: 0.1749 s/iter. ETA=0:00:48\n",
      "\u001b[32m[09/06 21:22:29 d2.evaluation.evaluator]: \u001b[0mInference done 959/1199. Dataloading: 0.1027 s/iter. Inference: 0.0705 s/iter. Eval: 0.0006 s/iter. Total: 0.1739 s/iter. ETA=0:00:41\n",
      "\u001b[32m[09/06 21:22:34 d2.evaluation.evaluator]: \u001b[0mInference done 985/1199. Dataloading: 0.1034 s/iter. Inference: 0.0704 s/iter. Eval: 0.0006 s/iter. Total: 0.1745 s/iter. ETA=0:00:37\n",
      "\u001b[32m[09/06 21:22:39 d2.evaluation.evaluator]: \u001b[0mInference done 1018/1199. Dataloading: 0.1030 s/iter. Inference: 0.0702 s/iter. Eval: 0.0006 s/iter. Total: 0.1740 s/iter. ETA=0:00:31\n",
      "\u001b[32m[09/06 21:22:44 d2.evaluation.evaluator]: \u001b[0mInference done 1040/1199. Dataloading: 0.1040 s/iter. Inference: 0.0705 s/iter. Eval: 0.0006 s/iter. Total: 0.1752 s/iter. ETA=0:00:27\n",
      "\u001b[32m[09/06 21:22:49 d2.evaluation.evaluator]: \u001b[0mInference done 1070/1199. Dataloading: 0.1038 s/iter. Inference: 0.0705 s/iter. Eval: 0.0006 s/iter. Total: 0.1750 s/iter. ETA=0:00:22\n",
      "\u001b[32m[09/06 21:22:55 d2.evaluation.evaluator]: \u001b[0mInference done 1095/1199. Dataloading: 0.1045 s/iter. Inference: 0.0705 s/iter. Eval: 0.0006 s/iter. Total: 0.1758 s/iter. ETA=0:00:18\n",
      "\u001b[32m[09/06 21:23:00 d2.evaluation.evaluator]: \u001b[0mInference done 1126/1199. Dataloading: 0.1047 s/iter. Inference: 0.0705 s/iter. Eval: 0.0006 s/iter. Total: 0.1760 s/iter. ETA=0:00:12\n",
      "\u001b[32m[09/06 21:23:05 d2.evaluation.evaluator]: \u001b[0mInference done 1159/1199. Dataloading: 0.1041 s/iter. Inference: 0.0705 s/iter. Eval: 0.0006 s/iter. Total: 0.1753 s/iter. ETA=0:00:07\n",
      "\u001b[32m[09/06 21:23:10 d2.evaluation.evaluator]: \u001b[0mInference done 1193/1199. Dataloading: 0.1035 s/iter. Inference: 0.0703 s/iter. Eval: 0.0006 s/iter. Total: 0.1745 s/iter. ETA=0:00:01\n",
      "\u001b[32m[09/06 21:23:12 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:03:28.651522 (0.174750 s / iter per device, on 1 devices)\n",
      "\u001b[32m[09/06 21:23:12 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:01:23 (0.070239 s / iter per device, on 1 devices)\n",
      "\u001b[32m[09/06 21:23:12 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[09/06 21:23:12 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.02s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[09/06 21:23:12 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[09/06 21:23:12 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.18 seconds.\n",
      "\u001b[32m[09/06 21:23:12 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[09/06 21:23:12 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.01 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.742\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.872\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.867\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.742\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.859\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.860\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.860\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.860\n",
      "\u001b[32m[09/06 21:23:12 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
      "| 74.220 | 87.234 | 86.689 |  nan  |  nan  | 74.220 |\n",
      "\u001b[32m[09/06 21:23:12 d2.evaluation.coco_evaluation]: \u001b[0mSome metrics cannot be computed and is shown as NaN.\n",
      "\u001b[32m[09/06 21:23:12 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category   | AP     | category   | AP     | category   | AP     |\n",
      "|:-----------|:-------|:-----------|:-------|:-----------|:-------|\n",
      "| angry      | 71.107 | sad        | 72.936 | surprised  | 70.723 |\n",
      "| happy      | 82.115 |            |        |            |        |\n",
      "\u001b[32m[09/06 21:23:12 d2.engine.defaults]: \u001b[0mEvaluation results for face_data_set_valid in csv format:\n",
      "\u001b[32m[09/06 21:23:12 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[09/06 21:23:12 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[09/06 21:23:12 d2.evaluation.testing]: \u001b[0mcopypaste: 74.2203,87.2336,86.6894,nan,nan,74.2203\n",
      "\u001b[32m[09/06 21:23:12 d2.utils.events]: \u001b[0m eta: 17 days, 9:43:25  iter: 6999  total_loss: 0.1747  loss_cls: 0.05802  loss_box_reg: 0.1159  loss_rpn_cls: 4.542e-05  loss_rpn_loc: 0.001448    time: 2.5783  last_time: 2.2141  data_time: 1.5439  last_data_time: 1.2888   lr: 0.00099966  max_mem: 4120M\n",
      "\u001b[32m[09/06 21:24:08 d2.utils.events]: \u001b[0m eta: 17 days, 9:11:55  iter: 7019  total_loss: 0.1746  loss_cls: 0.05104  loss_box_reg: 0.1202  loss_rpn_cls: 4.57e-05  loss_rpn_loc: 0.001557    time: 2.5790  last_time: 2.2603  data_time: 1.7835  last_data_time: 1.3774   lr: 0.00099966  max_mem: 4120M\n",
      "\u001b[32m[09/06 21:25:01 d2.utils.events]: \u001b[0m eta: 17 days, 9:00:53  iter: 7039  total_loss: 0.18  loss_cls: 0.06746  loss_box_reg: 0.1072  loss_rpn_cls: 7.927e-05  loss_rpn_loc: 0.001402    time: 2.5793  last_time: 2.6428  data_time: 1.6644  last_data_time: 1.6490   lr: 0.00099966  max_mem: 4120M\n",
      "\u001b[32m[09/06 21:25:52 d2.utils.events]: \u001b[0m eta: 17 days, 9:25:09  iter: 7059  total_loss: 0.1859  loss_cls: 0.05554  loss_box_reg: 0.1249  loss_rpn_cls: 9.777e-05  loss_rpn_loc: 0.001421    time: 2.5792  last_time: 2.3078  data_time: 1.5975  last_data_time: 1.4004   lr: 0.00099966  max_mem: 4120M\n",
      "\u001b[32m[09/06 21:26:42 d2.utils.events]: \u001b[0m eta: 17 days, 9:55:16  iter: 7079  total_loss: 0.1722  loss_cls: 0.057  loss_box_reg: 0.112  loss_rpn_cls: 7.647e-05  loss_rpn_loc: 0.001423    time: 2.5789  last_time: 2.5540  data_time: 1.5423  last_data_time: 1.5812   lr: 0.00099966  max_mem: 4120M\n",
      "\u001b[32m[09/06 21:27:36 d2.utils.events]: \u001b[0m eta: 17 days, 10:42:20  iter: 7099  total_loss: 0.1814  loss_cls: 0.06167  loss_box_reg: 0.114  loss_rpn_cls: 7.361e-05  loss_rpn_loc: 0.001614    time: 2.5794  last_time: 3.0241  data_time: 1.6067  last_data_time: 1.9717   lr: 0.00099965  max_mem: 4120M\n",
      "\u001b[32m[09/06 21:28:31 d2.utils.events]: \u001b[0m eta: 17 days, 11:32:34  iter: 7119  total_loss: 0.1754  loss_cls: 0.05945  loss_box_reg: 0.1156  loss_rpn_cls: 5.006e-05  loss_rpn_loc: 0.001408    time: 2.5798  last_time: 2.5999  data_time: 1.7328  last_data_time: 1.6860   lr: 0.00099965  max_mem: 4120M\n",
      "\u001b[32m[09/06 21:29:24 d2.utils.events]: \u001b[0m eta: 17 days, 11:08:38  iter: 7139  total_loss: 0.1743  loss_cls: 0.05253  loss_box_reg: 0.1068  loss_rpn_cls: 7.468e-05  loss_rpn_loc: 0.001582    time: 2.5801  last_time: 2.6456  data_time: 1.6760  last_data_time: 1.6484   lr: 0.00099965  max_mem: 4120M\n",
      "\u001b[32m[09/06 21:30:16 d2.utils.events]: \u001b[0m eta: 17 days, 11:52:19  iter: 7159  total_loss: 0.1644  loss_cls: 0.05856  loss_box_reg: 0.09943  loss_rpn_cls: 4.89e-05  loss_rpn_loc: 0.001487    time: 2.5801  last_time: 2.1902  data_time: 1.6483  last_data_time: 1.3478   lr: 0.00099965  max_mem: 4120M\n",
      "\u001b[32m[09/06 21:31:08 d2.utils.events]: \u001b[0m eta: 17 days, 12:06:51  iter: 7179  total_loss: 0.166  loss_cls: 0.04636  loss_box_reg: 0.1168  loss_rpn_cls: 9.141e-05  loss_rpn_loc: 0.001559    time: 2.5803  last_time: 1.9834  data_time: 1.6780  last_data_time: 1.0830   lr: 0.00099965  max_mem: 4120M\n",
      "\u001b[32m[09/06 21:31:55 d2.utils.events]: \u001b[0m eta: 17 days, 11:06:06  iter: 7199  total_loss: 0.1668  loss_cls: 0.05123  loss_box_reg: 0.1131  loss_rpn_cls: 7.816e-05  loss_rpn_loc: 0.00141    time: 2.5795  last_time: 2.2915  data_time: 1.4407  last_data_time: 1.4010   lr: 0.00099964  max_mem: 4120M\n",
      "\u001b[32m[09/06 21:32:42 d2.utils.events]: \u001b[0m eta: 17 days, 10:22:53  iter: 7219  total_loss: 0.1866  loss_cls: 0.07432  loss_box_reg: 0.1111  loss_rpn_cls: 5.045e-05  loss_rpn_loc: 0.001413    time: 2.5787  last_time: 2.2782  data_time: 1.4301  last_data_time: 1.3870   lr: 0.00099964  max_mem: 4120M\n",
      "\u001b[32m[09/06 21:33:28 d2.utils.events]: \u001b[0m eta: 17 days, 10:10:18  iter: 7239  total_loss: 0.1803  loss_cls: 0.06106  loss_box_reg: 0.1151  loss_rpn_cls: 4.647e-05  loss_rpn_loc: 0.001521    time: 2.5778  last_time: 2.5259  data_time: 1.4620  last_data_time: 1.6160   lr: 0.00099964  max_mem: 4120M\n",
      "\u001b[32m[09/06 21:34:17 d2.utils.events]: \u001b[0m eta: 17 days, 10:21:11  iter: 7259  total_loss: 0.19  loss_cls: 0.06511  loss_box_reg: 0.1182  loss_rpn_cls: 5.079e-05  loss_rpn_loc: 0.001527    time: 2.5774  last_time: 2.4166  data_time: 1.5442  last_data_time: 1.5164   lr: 0.00099964  max_mem: 4120M\n",
      "\u001b[32m[09/06 21:35:05 d2.utils.events]: \u001b[0m eta: 17 days, 10:20:21  iter: 7279  total_loss: 0.1828  loss_cls: 0.06318  loss_box_reg: 0.1077  loss_rpn_cls: 6.831e-05  loss_rpn_loc: 0.001363    time: 2.5768  last_time: 2.3137  data_time: 1.4916  last_data_time: 1.4441   lr: 0.00099964  max_mem: 4120M\n",
      "\u001b[32m[09/06 21:35:50 d2.utils.events]: \u001b[0m eta: 17 days, 9:44:00  iter: 7299  total_loss: 0.173  loss_cls: 0.05179  loss_box_reg: 0.1128  loss_rpn_cls: 7.754e-05  loss_rpn_loc: 0.001351    time: 2.5758  last_time: 2.3982  data_time: 1.4029  last_data_time: 1.5336   lr: 0.00099964  max_mem: 4120M\n",
      "\u001b[32m[09/06 21:36:39 d2.utils.events]: \u001b[0m eta: 17 days, 9:54:51  iter: 7319  total_loss: 0.1789  loss_cls: 0.06843  loss_box_reg: 0.1084  loss_rpn_cls: 6.603e-05  loss_rpn_loc: 0.001368    time: 2.5755  last_time: 2.6065  data_time: 1.5797  last_data_time: 1.7574   lr: 0.00099963  max_mem: 4120M\n",
      "\u001b[32m[09/06 21:37:23 d2.utils.events]: \u001b[0m eta: 17 days, 9:54:01  iter: 7339  total_loss: 0.1882  loss_cls: 0.0707  loss_box_reg: 0.1089  loss_rpn_cls: 5.341e-05  loss_rpn_loc: 0.001499    time: 2.5743  last_time: 2.1453  data_time: 1.3175  last_data_time: 1.2399   lr: 0.00099963  max_mem: 4120M\n",
      "\u001b[32m[09/06 21:38:11 d2.utils.events]: \u001b[0m eta: 17 days, 9:49:21  iter: 7359  total_loss: 0.1784  loss_cls: 0.05922  loss_box_reg: 0.1066  loss_rpn_cls: 5.473e-05  loss_rpn_loc: 0.00147    time: 2.5737  last_time: 2.3301  data_time: 1.5073  last_data_time: 1.4555   lr: 0.00099963  max_mem: 4120M\n",
      "\u001b[32m[09/06 21:38:58 d2.utils.events]: \u001b[0m eta: 17 days, 9:06:22  iter: 7379  total_loss: 0.1793  loss_cls: 0.06254  loss_box_reg: 0.114  loss_rpn_cls: 7.909e-05  loss_rpn_loc: 0.001641    time: 2.5730  last_time: 2.2717  data_time: 1.4646  last_data_time: 1.3584   lr: 0.00099963  max_mem: 4120M\n",
      "\u001b[32m[09/06 21:39:43 d2.utils.events]: \u001b[0m eta: 17 days, 8:39:31  iter: 7399  total_loss: 0.165  loss_cls: 0.04879  loss_box_reg: 0.1122  loss_rpn_cls: 5.278e-05  loss_rpn_loc: 0.001367    time: 2.5720  last_time: 2.0967  data_time: 1.3671  last_data_time: 1.1416   lr: 0.00099962  max_mem: 4120M\n",
      "\u001b[32m[09/06 21:40:28 d2.utils.events]: \u001b[0m eta: 17 days, 7:59:34  iter: 7419  total_loss: 0.1777  loss_cls: 0.05949  loss_box_reg: 0.1167  loss_rpn_cls: 8.597e-05  loss_rpn_loc: 0.001429    time: 2.5710  last_time: 2.6083  data_time: 1.3761  last_data_time: 1.6912   lr: 0.00099962  max_mem: 4120M\n",
      "\u001b[32m[09/06 21:41:13 d2.utils.events]: \u001b[0m eta: 17 days, 7:00:49  iter: 7439  total_loss: 0.1853  loss_cls: 0.06533  loss_box_reg: 0.1122  loss_rpn_cls: 6.75e-05  loss_rpn_loc: 0.001505    time: 2.5700  last_time: 2.3911  data_time: 1.3835  last_data_time: 1.5243   lr: 0.00099962  max_mem: 4120M\n",
      "\u001b[32m[09/06 21:42:02 d2.utils.events]: \u001b[0m eta: 17 days, 6:46:04  iter: 7459  total_loss: 0.1733  loss_cls: 0.06658  loss_box_reg: 0.1095  loss_rpn_cls: 7.525e-05  loss_rpn_loc: 0.00131    time: 2.5696  last_time: 3.3866  data_time: 1.5420  last_data_time: 2.2998   lr: 0.00099962  max_mem: 4120M\n",
      "\u001b[32m[09/06 21:42:49 d2.utils.events]: \u001b[0m eta: 17 days, 6:02:18  iter: 7479  total_loss: 0.1736  loss_cls: 0.05567  loss_box_reg: 0.107  loss_rpn_cls: 5.217e-05  loss_rpn_loc: 0.001468    time: 2.5688  last_time: 2.2577  data_time: 1.4201  last_data_time: 1.4028   lr: 0.00099962  max_mem: 4120M\n",
      "\u001b[32m[09/06 21:43:36 d2.utils.events]: \u001b[0m eta: 17 days, 5:59:47  iter: 7499  total_loss: 0.1712  loss_cls: 0.06381  loss_box_reg: 0.114  loss_rpn_cls: 5.881e-05  loss_rpn_loc: 0.001638    time: 2.5679  last_time: 2.2423  data_time: 1.3985  last_data_time: 1.4012   lr: 0.00099961  max_mem: 4120M\n",
      "\u001b[32m[09/06 21:44:21 d2.utils.events]: \u001b[0m eta: 17 days, 2:18:21  iter: 7519  total_loss: 0.1664  loss_cls: 0.05419  loss_box_reg: 0.1167  loss_rpn_cls: 6.856e-05  loss_rpn_loc: 0.00151    time: 2.5669  last_time: 2.3447  data_time: 1.3713  last_data_time: 1.5202   lr: 0.00099961  max_mem: 4120M\n",
      "\u001b[32m[09/06 21:45:08 d2.utils.events]: \u001b[0m eta: 17 days, 0:12:09  iter: 7539  total_loss: 0.1916  loss_cls: 0.07512  loss_box_reg: 0.1095  loss_rpn_cls: 5.498e-05  loss_rpn_loc: 0.001456    time: 2.5663  last_time: 3.2745  data_time: 1.4693  last_data_time: 2.2200   lr: 0.00099961  max_mem: 4120M\n",
      "\u001b[32m[09/06 21:45:55 d2.utils.events]: \u001b[0m eta: 16 days, 21:13:18  iter: 7559  total_loss: 0.1803  loss_cls: 0.05493  loss_box_reg: 0.114  loss_rpn_cls: 6.068e-05  loss_rpn_loc: 0.001536    time: 2.5657  last_time: 2.3439  data_time: 1.4714  last_data_time: 1.5629   lr: 0.00099961  max_mem: 4120M\n",
      "\u001b[32m[09/06 21:46:40 d2.utils.events]: \u001b[0m eta: 16 days, 19:31:43  iter: 7579  total_loss: 0.172  loss_cls: 0.0597  loss_box_reg: 0.1028  loss_rpn_cls: 4.609e-05  loss_rpn_loc: 0.001384    time: 2.5647  last_time: 2.0948  data_time: 1.3744  last_data_time: 1.2633   lr: 0.00099961  max_mem: 4120M\n",
      "\u001b[32m[09/06 21:47:27 d2.utils.events]: \u001b[0m eta: 16 days, 17:11:31  iter: 7599  total_loss: 0.1797  loss_cls: 0.06332  loss_box_reg: 0.1169  loss_rpn_cls: 6.354e-05  loss_rpn_loc: 0.001544    time: 2.5640  last_time: 2.3389  data_time: 1.4631  last_data_time: 1.5030   lr: 0.0009996  max_mem: 4120M\n",
      "\u001b[32m[09/06 21:48:14 d2.utils.events]: \u001b[0m eta: 16 days, 14:19:22  iter: 7619  total_loss: 0.1751  loss_cls: 0.05864  loss_box_reg: 0.1129  loss_rpn_cls: 7.411e-05  loss_rpn_loc: 0.001454    time: 2.5633  last_time: 2.3452  data_time: 1.4574  last_data_time: 1.5365   lr: 0.0009996  max_mem: 4120M\n",
      "\u001b[32m[09/06 21:48:58 d2.utils.events]: \u001b[0m eta: 16 days, 12:55:02  iter: 7639  total_loss: 0.1972  loss_cls: 0.07137  loss_box_reg: 0.1119  loss_rpn_cls: 3.96e-05  loss_rpn_loc: 0.001552    time: 2.5623  last_time: 2.4020  data_time: 1.3568  last_data_time: 1.4983   lr: 0.0009996  max_mem: 4120M\n",
      "\u001b[32m[09/06 21:49:47 d2.utils.events]: \u001b[0m eta: 16 days, 11:29:31  iter: 7659  total_loss: 0.1644  loss_cls: 0.04869  loss_box_reg: 0.1108  loss_rpn_cls: 6.25e-05  loss_rpn_loc: 0.001412    time: 2.5619  last_time: 2.3378  data_time: 1.5138  last_data_time: 1.4995   lr: 0.0009996  max_mem: 4120M\n",
      "\u001b[32m[09/06 21:50:33 d2.utils.events]: \u001b[0m eta: 16 days, 10:35:20  iter: 7679  total_loss: 0.1535  loss_cls: 0.04663  loss_box_reg: 0.1023  loss_rpn_cls: 5.933e-05  loss_rpn_loc: 0.001437    time: 2.5611  last_time: 2.1107  data_time: 1.4453  last_data_time: 1.2374   lr: 0.0009996  max_mem: 4120M\n",
      "\u001b[32m[09/06 21:51:19 d2.utils.events]: \u001b[0m eta: 16 days, 10:29:37  iter: 7699  total_loss: 0.1638  loss_cls: 0.0585  loss_box_reg: 0.1096  loss_rpn_cls: 0.0001007  loss_rpn_loc: 0.001416    time: 2.5604  last_time: 2.8229  data_time: 1.4172  last_data_time: 1.9276   lr: 0.00099959  max_mem: 4120M\n",
      "\u001b[32m[09/06 21:52:04 d2.utils.events]: \u001b[0m eta: 16 days, 10:02:54  iter: 7719  total_loss: 0.1813  loss_cls: 0.06059  loss_box_reg: 0.1162  loss_rpn_cls: 5.861e-05  loss_rpn_loc: 0.001613    time: 2.5594  last_time: 2.3885  data_time: 1.3831  last_data_time: 1.5308   lr: 0.00099959  max_mem: 4120M\n",
      "\u001b[32m[09/06 21:52:50 d2.utils.events]: \u001b[0m eta: 16 days, 9:29:17  iter: 7739  total_loss: 0.1905  loss_cls: 0.07067  loss_box_reg: 0.11  loss_rpn_cls: 6.578e-05  loss_rpn_loc: 0.001465    time: 2.5586  last_time: 2.1828  data_time: 1.4479  last_data_time: 1.3694   lr: 0.00099959  max_mem: 4120M\n",
      "\u001b[32m[09/06 21:53:37 d2.utils.events]: \u001b[0m eta: 16 days, 8:33:29  iter: 7759  total_loss: 0.1645  loss_cls: 0.05355  loss_box_reg: 0.1104  loss_rpn_cls: 6.112e-05  loss_rpn_loc: 0.001518    time: 2.5580  last_time: 2.2955  data_time: 1.4573  last_data_time: 1.4803   lr: 0.00099959  max_mem: 4120M\n",
      "\u001b[32m[09/06 21:54:23 d2.utils.events]: \u001b[0m eta: 16 days, 6:27:40  iter: 7779  total_loss: 0.1631  loss_cls: 0.04682  loss_box_reg: 0.1058  loss_rpn_cls: 3.824e-05  loss_rpn_loc: 0.001422    time: 2.5572  last_time: 2.0634  data_time: 1.4275  last_data_time: 1.2196   lr: 0.00099959  max_mem: 4120M\n",
      "\u001b[32m[09/06 21:55:09 d2.utils.events]: \u001b[0m eta: 16 days, 5:13:27  iter: 7799  total_loss: 0.167  loss_cls: 0.05814  loss_box_reg: 0.1128  loss_rpn_cls: 5.995e-05  loss_rpn_loc: 0.001535    time: 2.5565  last_time: 2.4351  data_time: 1.4435  last_data_time: 1.5821   lr: 0.00099958  max_mem: 4120M\n",
      "\u001b[32m[09/06 21:55:54 d2.utils.events]: \u001b[0m eta: 16 days, 3:52:14  iter: 7819  total_loss: 0.1734  loss_cls: 0.05047  loss_box_reg: 0.1144  loss_rpn_cls: 5.522e-05  loss_rpn_loc: 0.001518    time: 2.5556  last_time: 2.1601  data_time: 1.3773  last_data_time: 1.3623   lr: 0.00099958  max_mem: 4120M\n",
      "\u001b[32m[09/06 21:56:42 d2.utils.events]: \u001b[0m eta: 16 days, 2:14:42  iter: 7839  total_loss: 0.1785  loss_cls: 0.05834  loss_box_reg: 0.1187  loss_rpn_cls: 6.775e-05  loss_rpn_loc: 0.001452    time: 2.5551  last_time: 2.0749  data_time: 1.4913  last_data_time: 1.1656   lr: 0.00099958  max_mem: 4120M\n",
      "\u001b[32m[09/06 21:57:24 d2.utils.events]: \u001b[0m eta: 16 days, 0:41:12  iter: 7859  total_loss: 0.154  loss_cls: 0.03822  loss_box_reg: 0.1062  loss_rpn_cls: 5.733e-05  loss_rpn_loc: 0.001469    time: 2.5539  last_time: 2.3380  data_time: 1.2770  last_data_time: 1.4082   lr: 0.00099958  max_mem: 4120M\n",
      "\u001b[32m[09/06 21:58:11 d2.utils.events]: \u001b[0m eta: 15 days, 23:32:54  iter: 7879  total_loss: 0.1579  loss_cls: 0.04303  loss_box_reg: 0.1095  loss_rpn_cls: 0.0001204  loss_rpn_loc: 0.001618    time: 2.5532  last_time: 2.4957  data_time: 1.4205  last_data_time: 1.6095   lr: 0.00099957  max_mem: 4120M\n",
      "\u001b[32m[09/06 21:58:58 d2.utils.events]: \u001b[0m eta: 15 days, 22:51:55  iter: 7899  total_loss: 0.1673  loss_cls: 0.0544  loss_box_reg: 0.1047  loss_rpn_cls: 5.358e-05  loss_rpn_loc: 0.001323    time: 2.5526  last_time: 2.5439  data_time: 1.4355  last_data_time: 1.6542   lr: 0.00099957  max_mem: 4120M\n",
      "\u001b[32m[09/06 21:59:42 d2.utils.events]: \u001b[0m eta: 15 days, 22:15:51  iter: 7919  total_loss: 0.1563  loss_cls: 0.04529  loss_box_reg: 0.1033  loss_rpn_cls: 4.917e-05  loss_rpn_loc: 0.001392    time: 2.5517  last_time: 2.3780  data_time: 1.3658  last_data_time: 1.4844   lr: 0.00099957  max_mem: 4121M\n",
      "\u001b[32m[09/06 22:00:28 d2.utils.events]: \u001b[0m eta: 15 days, 21:22:59  iter: 7939  total_loss: 0.1599  loss_cls: 0.04387  loss_box_reg: 0.1106  loss_rpn_cls: 6.978e-05  loss_rpn_loc: 0.001407    time: 2.5509  last_time: 2.3379  data_time: 1.4425  last_data_time: 1.4515   lr: 0.00099957  max_mem: 4121M\n",
      "\u001b[32m[09/06 22:01:15 d2.utils.events]: \u001b[0m eta: 15 days, 19:50:19  iter: 7959  total_loss: 0.1693  loss_cls: 0.04793  loss_box_reg: 0.1128  loss_rpn_cls: 4.595e-05  loss_rpn_loc: 0.001441    time: 2.5504  last_time: 3.2073  data_time: 1.4585  last_data_time: 2.2208   lr: 0.00099957  max_mem: 4121M\n",
      "\u001b[32m[09/06 22:02:04 d2.utils.events]: \u001b[0m eta: 15 days, 18:14:36  iter: 7979  total_loss: 0.1689  loss_cls: 0.05838  loss_box_reg: 0.1144  loss_rpn_cls: 8.255e-05  loss_rpn_loc: 0.001466    time: 2.5501  last_time: 2.2851  data_time: 1.5609  last_data_time: 1.3616   lr: 0.00099956  max_mem: 4121M\n",
      "\u001b[32m[09/06 22:02:53 d2.data.datasets.coco]: \u001b[0mLoaded 1199 images in COCO format from data/ssd_rcnn_face/annotations_val.json\n",
      "\u001b[32m[09/06 22:02:53 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(512, 512), max_size=512, sample_style='choice')]\n",
      "\u001b[32m[09/06 22:02:53 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[09/06 22:02:53 d2.data.common]: \u001b[0mSerializing 1199 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[09/06 22:02:53 d2.data.common]: \u001b[0mSerialized dataset takes 0.36 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[09/06 22:02:53 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n",
      "\u001b[32m[09/06 22:02:53 d2.evaluation.evaluator]: \u001b[0mStart inference on 1199 batches\n",
      "\u001b[32m[09/06 22:02:54 d2.evaluation.evaluator]: \u001b[0mInference done 11/1199. Dataloading: 0.0458 s/iter. Inference: 0.0624 s/iter. Eval: 0.0004 s/iter. Total: 0.1087 s/iter. ETA=0:02:09\n",
      "\u001b[32m[09/06 22:02:59 d2.evaluation.evaluator]: \u001b[0mInference done 51/1199. Dataloading: 0.0664 s/iter. Inference: 0.0561 s/iter. Eval: 0.0004 s/iter. Total: 0.1230 s/iter. ETA=0:02:21\n",
      "\u001b[32m[09/06 22:03:05 d2.evaluation.evaluator]: \u001b[0mInference done 85/1199. Dataloading: 0.0870 s/iter. Inference: 0.0552 s/iter. Eval: 0.0004 s/iter. Total: 0.1428 s/iter. ETA=0:02:39\n",
      "\u001b[32m[09/06 22:03:10 d2.evaluation.evaluator]: \u001b[0mInference done 119/1199. Dataloading: 0.0888 s/iter. Inference: 0.0559 s/iter. Eval: 0.0004 s/iter. Total: 0.1452 s/iter. ETA=0:02:36\n",
      "\u001b[32m[09/06 22:03:15 d2.evaluation.evaluator]: \u001b[0mInference done 158/1199. Dataloading: 0.0835 s/iter. Inference: 0.0573 s/iter. Eval: 0.0005 s/iter. Total: 0.1412 s/iter. ETA=0:02:27\n",
      "\u001b[32m[09/06 22:03:20 d2.evaluation.evaluator]: \u001b[0mInference done 195/1199. Dataloading: 0.0828 s/iter. Inference: 0.0579 s/iter. Eval: 0.0004 s/iter. Total: 0.1412 s/iter. ETA=0:02:21\n",
      "\u001b[32m[09/06 22:03:25 d2.evaluation.evaluator]: \u001b[0mInference done 229/1199. Dataloading: 0.0840 s/iter. Inference: 0.0579 s/iter. Eval: 0.0004 s/iter. Total: 0.1425 s/iter. ETA=0:02:18\n",
      "\u001b[32m[09/06 22:03:31 d2.evaluation.evaluator]: \u001b[0mInference done 262/1199. Dataloading: 0.0854 s/iter. Inference: 0.0581 s/iter. Eval: 0.0004 s/iter. Total: 0.1440 s/iter. ETA=0:02:14\n",
      "\u001b[32m[09/06 22:03:36 d2.evaluation.evaluator]: \u001b[0mInference done 282/1199. Dataloading: 0.0943 s/iter. Inference: 0.0582 s/iter. Eval: 0.0004 s/iter. Total: 0.1531 s/iter. ETA=0:02:20\n",
      "\u001b[32m[09/06 22:03:41 d2.evaluation.evaluator]: \u001b[0mInference done 317/1199. Dataloading: 0.0931 s/iter. Inference: 0.0588 s/iter. Eval: 0.0005 s/iter. Total: 0.1524 s/iter. ETA=0:02:14\n",
      "\u001b[32m[09/06 22:03:46 d2.evaluation.evaluator]: \u001b[0mInference done 354/1199. Dataloading: 0.0920 s/iter. Inference: 0.0583 s/iter. Eval: 0.0004 s/iter. Total: 0.1508 s/iter. ETA=0:02:07\n",
      "\u001b[32m[09/06 22:03:51 d2.evaluation.evaluator]: \u001b[0mInference done 387/1199. Dataloading: 0.0919 s/iter. Inference: 0.0584 s/iter. Eval: 0.0005 s/iter. Total: 0.1509 s/iter. ETA=0:02:02\n",
      "\u001b[32m[09/06 22:03:56 d2.evaluation.evaluator]: \u001b[0mInference done 423/1199. Dataloading: 0.0913 s/iter. Inference: 0.0580 s/iter. Eval: 0.0005 s/iter. Total: 0.1499 s/iter. ETA=0:01:56\n",
      "\u001b[32m[09/06 22:04:02 d2.evaluation.evaluator]: \u001b[0mInference done 465/1199. Dataloading: 0.0891 s/iter. Inference: 0.0581 s/iter. Eval: 0.0005 s/iter. Total: 0.1477 s/iter. ETA=0:01:48\n",
      "\u001b[32m[09/06 22:04:07 d2.evaluation.evaluator]: \u001b[0mInference done 502/1199. Dataloading: 0.0879 s/iter. Inference: 0.0584 s/iter. Eval: 0.0005 s/iter. Total: 0.1468 s/iter. ETA=0:01:42\n",
      "\u001b[32m[09/06 22:04:12 d2.evaluation.evaluator]: \u001b[0mInference done 538/1199. Dataloading: 0.0877 s/iter. Inference: 0.0583 s/iter. Eval: 0.0005 s/iter. Total: 0.1465 s/iter. ETA=0:01:36\n",
      "\u001b[32m[09/06 22:04:17 d2.evaluation.evaluator]: \u001b[0mInference done 578/1199. Dataloading: 0.0867 s/iter. Inference: 0.0582 s/iter. Eval: 0.0005 s/iter. Total: 0.1455 s/iter. ETA=0:01:30\n",
      "\u001b[32m[09/06 22:04:22 d2.evaluation.evaluator]: \u001b[0mInference done 616/1199. Dataloading: 0.0858 s/iter. Inference: 0.0583 s/iter. Eval: 0.0004 s/iter. Total: 0.1447 s/iter. ETA=0:01:24\n",
      "\u001b[32m[09/06 22:04:27 d2.evaluation.evaluator]: \u001b[0mInference done 645/1199. Dataloading: 0.0879 s/iter. Inference: 0.0582 s/iter. Eval: 0.0004 s/iter. Total: 0.1466 s/iter. ETA=0:01:21\n",
      "\u001b[32m[09/06 22:04:32 d2.evaluation.evaluator]: \u001b[0mInference done 680/1199. Dataloading: 0.0879 s/iter. Inference: 0.0581 s/iter. Eval: 0.0004 s/iter. Total: 0.1465 s/iter. ETA=0:01:16\n",
      "\u001b[32m[09/06 22:04:37 d2.evaluation.evaluator]: \u001b[0mInference done 720/1199. Dataloading: 0.0866 s/iter. Inference: 0.0583 s/iter. Eval: 0.0004 s/iter. Total: 0.1454 s/iter. ETA=0:01:09\n",
      "\u001b[32m[09/06 22:04:43 d2.evaluation.evaluator]: \u001b[0mInference done 751/1199. Dataloading: 0.0875 s/iter. Inference: 0.0583 s/iter. Eval: 0.0004 s/iter. Total: 0.1464 s/iter. ETA=0:01:05\n",
      "\u001b[32m[09/06 22:04:48 d2.evaluation.evaluator]: \u001b[0mInference done 780/1199. Dataloading: 0.0885 s/iter. Inference: 0.0584 s/iter. Eval: 0.0004 s/iter. Total: 0.1474 s/iter. ETA=0:01:01\n",
      "\u001b[32m[09/06 22:04:53 d2.evaluation.evaluator]: \u001b[0mInference done 821/1199. Dataloading: 0.0875 s/iter. Inference: 0.0582 s/iter. Eval: 0.0004 s/iter. Total: 0.1463 s/iter. ETA=0:00:55\n",
      "\u001b[32m[09/06 22:04:58 d2.evaluation.evaluator]: \u001b[0mInference done 862/1199. Dataloading: 0.0865 s/iter. Inference: 0.0581 s/iter. Eval: 0.0004 s/iter. Total: 0.1452 s/iter. ETA=0:00:48\n",
      "\u001b[32m[09/06 22:05:03 d2.evaluation.evaluator]: \u001b[0mInference done 897/1199. Dataloading: 0.0869 s/iter. Inference: 0.0580 s/iter. Eval: 0.0004 s/iter. Total: 0.1454 s/iter. ETA=0:00:43\n",
      "\u001b[32m[09/06 22:05:08 d2.evaluation.evaluator]: \u001b[0mInference done 936/1199. Dataloading: 0.0862 s/iter. Inference: 0.0580 s/iter. Eval: 0.0004 s/iter. Total: 0.1447 s/iter. ETA=0:00:38\n",
      "\u001b[32m[09/06 22:05:13 d2.evaluation.evaluator]: \u001b[0mInference done 970/1199. Dataloading: 0.0862 s/iter. Inference: 0.0581 s/iter. Eval: 0.0004 s/iter. Total: 0.1448 s/iter. ETA=0:00:33\n",
      "\u001b[32m[09/06 22:05:18 d2.evaluation.evaluator]: \u001b[0mInference done 1005/1199. Dataloading: 0.0862 s/iter. Inference: 0.0582 s/iter. Eval: 0.0004 s/iter. Total: 0.1449 s/iter. ETA=0:00:28\n",
      "\u001b[32m[09/06 22:05:24 d2.evaluation.evaluator]: \u001b[0mInference done 1038/1199. Dataloading: 0.0865 s/iter. Inference: 0.0582 s/iter. Eval: 0.0004 s/iter. Total: 0.1453 s/iter. ETA=0:00:23\n",
      "\u001b[32m[09/06 22:05:29 d2.evaluation.evaluator]: \u001b[0mInference done 1073/1199. Dataloading: 0.0865 s/iter. Inference: 0.0582 s/iter. Eval: 0.0004 s/iter. Total: 0.1453 s/iter. ETA=0:00:18\n",
      "\u001b[32m[09/06 22:05:34 d2.evaluation.evaluator]: \u001b[0mInference done 1109/1199. Dataloading: 0.0863 s/iter. Inference: 0.0583 s/iter. Eval: 0.0004 s/iter. Total: 0.1451 s/iter. ETA=0:00:13\n",
      "\u001b[32m[09/06 22:05:39 d2.evaluation.evaluator]: \u001b[0mInference done 1139/1199. Dataloading: 0.0869 s/iter. Inference: 0.0583 s/iter. Eval: 0.0004 s/iter. Total: 0.1457 s/iter. ETA=0:00:08\n",
      "\u001b[32m[09/06 22:05:44 d2.evaluation.evaluator]: \u001b[0mInference done 1174/1199. Dataloading: 0.0868 s/iter. Inference: 0.0583 s/iter. Eval: 0.0004 s/iter. Total: 0.1456 s/iter. ETA=0:00:03\n",
      "\u001b[32m[09/06 22:05:47 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:02:53.406997 (0.145232 s / iter per device, on 1 devices)\n",
      "\u001b[32m[09/06 22:05:47 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:01:09 (0.058304 s / iter per device, on 1 devices)\n",
      "\u001b[32m[09/06 22:05:47 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[09/06 22:05:47 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[09/06 22:05:47 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[09/06 22:05:47 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.08 seconds.\n",
      "\u001b[32m[09/06 22:05:47 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[09/06 22:05:47 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.01 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.723\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.846\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.837\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.723\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.848\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.848\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.848\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.848\n",
      "\u001b[32m[09/06 22:05:47 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
      "| 72.283 | 84.563 | 83.671 |  nan  |  nan  | 72.283 |\n",
      "\u001b[32m[09/06 22:05:47 d2.evaluation.coco_evaluation]: \u001b[0mSome metrics cannot be computed and is shown as NaN.\n",
      "\u001b[32m[09/06 22:05:47 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category   | AP     | category   | AP     | category   | AP     |\n",
      "|:-----------|:-------|:-----------|:-------|:-----------|:-------|\n",
      "| angry      | 66.800 | sad        | 71.562 | surprised  | 68.531 |\n",
      "| happy      | 82.236 |            |        |            |        |\n",
      "\u001b[32m[09/06 22:05:47 d2.engine.defaults]: \u001b[0mEvaluation results for face_data_set_valid in csv format:\n",
      "\u001b[32m[09/06 22:05:47 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[09/06 22:05:47 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[09/06 22:05:47 d2.evaluation.testing]: \u001b[0mcopypaste: 72.2825,84.5627,83.6712,nan,nan,72.2825\n",
      "\u001b[32m[09/06 22:05:47 d2.utils.events]: \u001b[0m eta: 15 days, 17:21:52  iter: 7999  total_loss: 0.1695  loss_cls: 0.05354  loss_box_reg: 0.1139  loss_rpn_cls: 5.157e-05  loss_rpn_loc: 0.001255    time: 2.5494  last_time: 2.3150  data_time: 1.4386  last_data_time: 1.5207   lr: 0.00099956  max_mem: 4121M\n",
      "\u001b[32m[09/06 22:06:32 d2.utils.events]: \u001b[0m eta: 15 days, 16:29:54  iter: 8019  total_loss: 0.1793  loss_cls: 0.05435  loss_box_reg: 0.1206  loss_rpn_cls: 3.82e-05  loss_rpn_loc: 0.001329    time: 2.5484  last_time: 2.0555  data_time: 1.3500  last_data_time: 1.2394   lr: 0.00099956  max_mem: 4121M\n",
      "\u001b[32m[09/06 22:07:18 d2.utils.events]: \u001b[0m eta: 15 days, 15:03:07  iter: 8039  total_loss: 0.1691  loss_cls: 0.04426  loss_box_reg: 0.116  loss_rpn_cls: 9.395e-05  loss_rpn_loc: 0.001712    time: 2.5478  last_time: 2.1826  data_time: 1.4456  last_data_time: 1.3549   lr: 0.00099956  max_mem: 4121M\n",
      "\u001b[32m[09/06 22:08:04 d2.utils.events]: \u001b[0m eta: 15 days, 14:05:03  iter: 8059  total_loss: 0.1792  loss_cls: 0.05201  loss_box_reg: 0.1197  loss_rpn_cls: 4.771e-05  loss_rpn_loc: 0.001493    time: 2.5471  last_time: 2.1581  data_time: 1.4298  last_data_time: 1.2787   lr: 0.00099956  max_mem: 4121M\n",
      "\u001b[32m[09/06 22:08:49 d2.utils.events]: \u001b[0m eta: 15 days, 13:24:28  iter: 8079  total_loss: 0.201  loss_cls: 0.05493  loss_box_reg: 0.1152  loss_rpn_cls: 5.114e-05  loss_rpn_loc: 0.001474    time: 2.5463  last_time: 2.4894  data_time: 1.3941  last_data_time: 1.6696   lr: 0.00099955  max_mem: 4121M\n",
      "\u001b[32m[09/06 22:09:35 d2.utils.events]: \u001b[0m eta: 15 days, 12:30:54  iter: 8099  total_loss: 0.1627  loss_cls: 0.059  loss_box_reg: 0.1042  loss_rpn_cls: 7.025e-05  loss_rpn_loc: 0.001471    time: 2.5455  last_time: 2.1760  data_time: 1.3958  last_data_time: 1.3872   lr: 0.00099955  max_mem: 4121M\n",
      "\u001b[32m[09/06 22:10:20 d2.utils.events]: \u001b[0m eta: 15 days, 11:43:34  iter: 8119  total_loss: 0.1584  loss_cls: 0.03915  loss_box_reg: 0.1155  loss_rpn_cls: 5.009e-05  loss_rpn_loc: 0.001585    time: 2.5447  last_time: 2.2980  data_time: 1.3861  last_data_time: 1.4088   lr: 0.00099955  max_mem: 4121M\n",
      "\u001b[32m[09/06 22:11:08 d2.utils.events]: \u001b[0m eta: 15 days, 11:02:37  iter: 8139  total_loss: 0.1699  loss_cls: 0.04188  loss_box_reg: 0.1213  loss_rpn_cls: 6.302e-05  loss_rpn_loc: 0.001463    time: 2.5443  last_time: 2.1920  data_time: 1.5079  last_data_time: 1.3115   lr: 0.00099955  max_mem: 4121M\n",
      "\u001b[32m[09/06 22:11:57 d2.utils.events]: \u001b[0m eta: 15 days, 10:11:04  iter: 8159  total_loss: 0.1581  loss_cls: 0.05036  loss_box_reg: 0.1039  loss_rpn_cls: 6.875e-05  loss_rpn_loc: 0.001267    time: 2.5440  last_time: 2.3279  data_time: 1.5275  last_data_time: 1.4563   lr: 0.00099954  max_mem: 4121M\n",
      "\u001b[32m[09/06 22:12:43 d2.utils.events]: \u001b[0m eta: 15 days, 9:08:00  iter: 8179  total_loss: 0.1667  loss_cls: 0.04743  loss_box_reg: 0.1079  loss_rpn_cls: 3.705e-05  loss_rpn_loc: 0.001363    time: 2.5434  last_time: 2.2220  data_time: 1.4584  last_data_time: 1.3682   lr: 0.00099954  max_mem: 4121M\n",
      "\u001b[32m[09/06 22:13:30 d2.utils.events]: \u001b[0m eta: 15 days, 8:23:59  iter: 8199  total_loss: 0.158  loss_cls: 0.04874  loss_box_reg: 0.1072  loss_rpn_cls: 5.579e-05  loss_rpn_loc: 0.00137    time: 2.5428  last_time: 2.3498  data_time: 1.4313  last_data_time: 1.4770   lr: 0.00099954  max_mem: 4121M\n",
      "\u001b[32m[09/06 22:14:16 d2.utils.events]: \u001b[0m eta: 15 days, 8:41:13  iter: 8219  total_loss: 0.1737  loss_cls: 0.0525  loss_box_reg: 0.1178  loss_rpn_cls: 8.826e-05  loss_rpn_loc: 0.001666    time: 2.5421  last_time: 2.5107  data_time: 1.4258  last_data_time: 1.6057   lr: 0.00099954  max_mem: 4121M\n",
      "\u001b[32m[09/06 22:15:03 d2.utils.events]: \u001b[0m eta: 15 days, 8:40:28  iter: 8239  total_loss: 0.1513  loss_cls: 0.04462  loss_box_reg: 0.111  loss_rpn_cls: 6.799e-05  loss_rpn_loc: 0.001404    time: 2.5416  last_time: 2.7119  data_time: 1.4850  last_data_time: 1.7813   lr: 0.00099953  max_mem: 4121M\n",
      "\u001b[32m[09/06 22:15:51 d2.utils.events]: \u001b[0m eta: 15 days, 8:39:43  iter: 8259  total_loss: 0.1623  loss_cls: 0.03825  loss_box_reg: 0.1099  loss_rpn_cls: 5.288e-05  loss_rpn_loc: 0.001407    time: 2.5412  last_time: 2.2176  data_time: 1.4944  last_data_time: 1.3792   lr: 0.00099953  max_mem: 4121M\n",
      "\u001b[32m[09/06 22:16:37 d2.utils.events]: \u001b[0m eta: 15 days, 9:13:18  iter: 8279  total_loss: 0.1745  loss_cls: 0.063  loss_box_reg: 0.1089  loss_rpn_cls: 8.452e-05  loss_rpn_loc: 0.0015    time: 2.5406  last_time: 2.0419  data_time: 1.4285  last_data_time: 1.1873   lr: 0.00099953  max_mem: 4121M\n",
      "\u001b[32m[09/06 22:17:25 d2.utils.events]: \u001b[0m eta: 15 days, 9:52:33  iter: 8299  total_loss: 0.1662  loss_cls: 0.04732  loss_box_reg: 0.1108  loss_rpn_cls: 6.472e-05  loss_rpn_loc: 0.001523    time: 2.5401  last_time: 2.2195  data_time: 1.5147  last_data_time: 1.4282   lr: 0.00099953  max_mem: 4121M\n",
      "\u001b[32m[09/06 22:18:14 d2.utils.events]: \u001b[0m eta: 15 days, 10:13:47  iter: 8319  total_loss: 0.1663  loss_cls: 0.05882  loss_box_reg: 0.1115  loss_rpn_cls: 6.48e-05  loss_rpn_loc: 0.001432    time: 2.5399  last_time: 2.2168  data_time: 1.5566  last_data_time: 1.3112   lr: 0.00099953  max_mem: 4121M\n",
      "\u001b[32m[09/06 22:19:01 d2.utils.events]: \u001b[0m eta: 15 days, 10:52:48  iter: 8339  total_loss: 0.1691  loss_cls: 0.04746  loss_box_reg: 0.1118  loss_rpn_cls: 3.587e-05  loss_rpn_loc: 0.001549    time: 2.5394  last_time: 2.2777  data_time: 1.4715  last_data_time: 1.4783   lr: 0.00099952  max_mem: 4121M\n",
      "\u001b[32m[09/06 22:19:47 d2.utils.events]: \u001b[0m eta: 15 days, 10:49:23  iter: 8359  total_loss: 0.1745  loss_cls: 0.05277  loss_box_reg: 0.1136  loss_rpn_cls: 4.159e-05  loss_rpn_loc: 0.001584    time: 2.5387  last_time: 2.3310  data_time: 1.3861  last_data_time: 1.4439   lr: 0.00099952  max_mem: 4121M\n",
      "\u001b[32m[09/06 22:20:31 d2.utils.events]: \u001b[0m eta: 15 days, 10:19:18  iter: 8379  total_loss: 0.1642  loss_cls: 0.046  loss_box_reg: 0.1105  loss_rpn_cls: 4.434e-05  loss_rpn_loc: 0.00144    time: 2.5378  last_time: 2.4505  data_time: 1.3413  last_data_time: 1.5562   lr: 0.00099952  max_mem: 4121M\n",
      "\u001b[32m[09/06 22:21:20 d2.utils.events]: \u001b[0m eta: 15 days, 10:52:56  iter: 8399  total_loss: 0.1818  loss_cls: 0.05795  loss_box_reg: 0.1163  loss_rpn_cls: 6.072e-05  loss_rpn_loc: 0.001701    time: 2.5376  last_time: 2.3296  data_time: 1.5361  last_data_time: 1.4551   lr: 0.00099952  max_mem: 4121M\n",
      "\u001b[32m[09/06 22:22:05 d2.utils.events]: \u001b[0m eta: 15 days, 10:55:27  iter: 8419  total_loss: 0.1735  loss_cls: 0.05766  loss_box_reg: 0.1163  loss_rpn_cls: 4.382e-05  loss_rpn_loc: 0.001406    time: 2.5369  last_time: 1.5980  data_time: 1.3978  last_data_time: 0.7317   lr: 0.00099951  max_mem: 4121M\n",
      "\u001b[32m[09/06 22:22:51 d2.utils.events]: \u001b[0m eta: 15 days, 11:00:52  iter: 8439  total_loss: 0.1676  loss_cls: 0.04526  loss_box_reg: 0.1119  loss_rpn_cls: 6.932e-05  loss_rpn_loc: 0.001666    time: 2.5362  last_time: 2.3290  data_time: 1.4193  last_data_time: 1.4909   lr: 0.00099951  max_mem: 4121M\n",
      "\u001b[32m[09/06 22:23:36 d2.utils.events]: \u001b[0m eta: 15 days, 11:01:50  iter: 8459  total_loss: 0.1623  loss_cls: 0.05476  loss_box_reg: 0.1046  loss_rpn_cls: 6.933e-05  loss_rpn_loc: 0.00133    time: 2.5354  last_time: 2.1176  data_time: 1.3710  last_data_time: 1.2680   lr: 0.00099951  max_mem: 4121M\n",
      "\u001b[32m[09/06 22:24:25 d2.utils.events]: \u001b[0m eta: 15 days, 11:24:55  iter: 8479  total_loss: 0.1684  loss_cls: 0.05209  loss_box_reg: 0.1019  loss_rpn_cls: 4.653e-05  loss_rpn_loc: 0.001326    time: 2.5351  last_time: 2.2115  data_time: 1.5527  last_data_time: 1.3023   lr: 0.00099951  max_mem: 4121M\n",
      "\u001b[32m[09/06 22:25:17 d2.utils.events]: \u001b[0m eta: 15 days, 11:40:36  iter: 8499  total_loss: 0.1619  loss_cls: 0.04978  loss_box_reg: 0.1195  loss_rpn_cls: 6.661e-05  loss_rpn_loc: 0.001634    time: 2.5350  last_time: 2.4158  data_time: 1.5573  last_data_time: 1.5055   lr: 0.00099951  max_mem: 4121M\n",
      "\u001b[32m[09/06 22:26:01 d2.utils.events]: \u001b[0m eta: 15 days, 11:23:25  iter: 8519  total_loss: 0.1518  loss_cls: 0.03966  loss_box_reg: 0.1104  loss_rpn_cls: 7.191e-05  loss_rpn_loc: 0.001442    time: 2.5341  last_time: 2.1959  data_time: 1.3207  last_data_time: 1.3274   lr: 0.0009995  max_mem: 4121M\n",
      "\u001b[32m[09/06 22:26:47 d2.utils.events]: \u001b[0m eta: 15 days, 11:13:34  iter: 8539  total_loss: 0.1631  loss_cls: 0.03953  loss_box_reg: 0.1218  loss_rpn_cls: 7.662e-05  loss_rpn_loc: 0.001544    time: 2.5336  last_time: 2.1919  data_time: 1.4603  last_data_time: 1.3670   lr: 0.0009995  max_mem: 4121M\n",
      "\u001b[32m[09/06 22:27:36 d2.utils.events]: \u001b[0m eta: 15 days, 11:18:22  iter: 8559  total_loss: 0.1727  loss_cls: 0.05075  loss_box_reg: 0.1161  loss_rpn_cls: 4.633e-05  loss_rpn_loc: 0.001546    time: 2.5333  last_time: 2.4510  data_time: 1.5087  last_data_time: 1.5820   lr: 0.0009995  max_mem: 4121M\n",
      "\u001b[32m[09/06 22:28:20 d2.utils.events]: \u001b[0m eta: 15 days, 11:04:41  iter: 8579  total_loss: 0.1651  loss_cls: 0.05233  loss_box_reg: 0.1117  loss_rpn_cls: 4.61e-05  loss_rpn_loc: 0.001387    time: 2.5324  last_time: 2.2788  data_time: 1.3357  last_data_time: 1.3185   lr: 0.0009995  max_mem: 4121M\n",
      "\u001b[32m[09/06 22:29:05 d2.utils.events]: \u001b[0m eta: 15 days, 10:54:51  iter: 8599  total_loss: 0.1624  loss_cls: 0.0512  loss_box_reg: 0.1059  loss_rpn_cls: 4.596e-05  loss_rpn_loc: 0.001381    time: 2.5317  last_time: 2.3784  data_time: 1.3646  last_data_time: 1.5593   lr: 0.00099949  max_mem: 4121M\n",
      "\u001b[32m[09/06 22:29:50 d2.utils.events]: \u001b[0m eta: 15 days, 10:55:49  iter: 8619  total_loss: 0.1738  loss_cls: 0.05994  loss_box_reg: 0.1158  loss_rpn_cls: 9.278e-05  loss_rpn_loc: 0.001485    time: 2.5310  last_time: 2.4689  data_time: 1.3752  last_data_time: 1.5270   lr: 0.00099949  max_mem: 4121M\n",
      "\u001b[32m[09/06 22:30:43 d2.utils.events]: \u001b[0m eta: 15 days, 11:34:50  iter: 8639  total_loss: 0.1619  loss_cls: 0.04505  loss_box_reg: 0.111  loss_rpn_cls: 4.391e-05  loss_rpn_loc: 0.001538    time: 2.5312  last_time: 3.4546  data_time: 1.6715  last_data_time: 2.3732   lr: 0.00099949  max_mem: 4121M\n",
      "\u001b[32m[09/06 22:31:35 d2.utils.events]: \u001b[0m eta: 15 days, 12:17:50  iter: 8659  total_loss: 0.159  loss_cls: 0.04701  loss_box_reg: 0.1048  loss_rpn_cls: 5.312e-05  loss_rpn_loc: 0.00144    time: 2.5314  last_time: 2.4969  data_time: 1.6470  last_data_time: 1.5887   lr: 0.00099949  max_mem: 4121M\n",
      "\u001b[32m[09/06 22:32:27 d2.utils.events]: \u001b[0m eta: 15 days, 12:53:48  iter: 8679  total_loss: 0.1553  loss_cls: 0.04075  loss_box_reg: 0.1154  loss_rpn_cls: 5.692e-05  loss_rpn_loc: 0.001392    time: 2.5317  last_time: 2.6015  data_time: 1.7034  last_data_time: 1.7248   lr: 0.00099948  max_mem: 4121M\n",
      "\u001b[32m[09/06 22:33:22 d2.utils.events]: \u001b[0m eta: 15 days, 14:07:45  iter: 8699  total_loss: 0.1578  loss_cls: 0.03894  loss_box_reg: 0.11  loss_rpn_cls: 6.085e-05  loss_rpn_loc: 0.001573    time: 2.5321  last_time: 3.1476  data_time: 1.7443  last_data_time: 1.8952   lr: 0.00099948  max_mem: 4121M\n",
      "\u001b[32m[09/06 22:34:14 d2.utils.events]: \u001b[0m eta: 15 days, 15:09:24  iter: 8719  total_loss: 0.1703  loss_cls: 0.05295  loss_box_reg: 0.1167  loss_rpn_cls: 7.178e-05  loss_rpn_loc: 0.001501    time: 2.5323  last_time: 2.5852  data_time: 1.6580  last_data_time: 1.7067   lr: 0.00099948  max_mem: 4121M\n",
      "\u001b[32m[09/06 22:35:06 d2.utils.events]: \u001b[0m eta: 15 days, 15:27:18  iter: 8739  total_loss: 0.1752  loss_cls: 0.05411  loss_box_reg: 0.1182  loss_rpn_cls: 0.0001094  loss_rpn_loc: 0.001628    time: 2.5325  last_time: 2.2562  data_time: 1.6566  last_data_time: 1.3342   lr: 0.00099948  max_mem: 4121M\n",
      "\u001b[32m[09/06 22:35:57 d2.utils.events]: \u001b[0m eta: 15 days, 16:27:10  iter: 8759  total_loss: 0.168  loss_cls: 0.05318  loss_box_reg: 0.1196  loss_rpn_cls: 0.0001095  loss_rpn_loc: 0.001588    time: 2.5326  last_time: 2.4249  data_time: 1.6073  last_data_time: 1.5034   lr: 0.00099947  max_mem: 4121M\n",
      "\u001b[32m[09/06 22:36:48 d2.utils.events]: \u001b[0m eta: 15 days, 17:33:03  iter: 8779  total_loss: 0.1598  loss_cls: 0.04845  loss_box_reg: 0.112  loss_rpn_cls: 0.0001277  loss_rpn_loc: 0.001494    time: 2.5326  last_time: 2.3978  data_time: 1.5839  last_data_time: 1.4483   lr: 0.00099947  max_mem: 4121M\n",
      "\u001b[32m[09/06 22:37:37 d2.utils.events]: \u001b[0m eta: 15 days, 18:15:04  iter: 8799  total_loss: 0.1488  loss_cls: 0.04778  loss_box_reg: 0.1068  loss_rpn_cls: 6.759e-05  loss_rpn_loc: 0.001355    time: 2.5324  last_time: 2.9273  data_time: 1.5478  last_data_time: 1.9345   lr: 0.00099947  max_mem: 4121M\n",
      "\u001b[32m[09/06 22:38:29 d2.utils.events]: \u001b[0m eta: 15 days, 19:03:32  iter: 8819  total_loss: 0.1651  loss_cls: 0.05905  loss_box_reg: 0.1055  loss_rpn_cls: 8.135e-05  loss_rpn_loc: 0.001369    time: 2.5325  last_time: 2.5026  data_time: 1.6374  last_data_time: 1.5786   lr: 0.00099947  max_mem: 4121M\n",
      "\u001b[32m[09/06 22:39:18 d2.utils.events]: \u001b[0m eta: 15 days, 19:47:32  iter: 8839  total_loss: 0.1644  loss_cls: 0.04925  loss_box_reg: 0.1156  loss_rpn_cls: 0.0001016  loss_rpn_loc: 0.001469    time: 2.5323  last_time: 3.1260  data_time: 1.5276  last_data_time: 2.0928   lr: 0.00099946  max_mem: 4121M\n",
      "\u001b[32m[09/06 22:40:12 d2.utils.events]: \u001b[0m eta: 15 days, 20:53:34  iter: 8859  total_loss: 0.1641  loss_cls: 0.05526  loss_box_reg: 0.1108  loss_rpn_cls: 6.323e-05  loss_rpn_loc: 0.00139    time: 2.5328  last_time: 3.0486  data_time: 1.7677  last_data_time: 2.0247   lr: 0.00099946  max_mem: 4121M\n",
      "\u001b[32m[09/06 22:41:04 d2.utils.events]: \u001b[0m eta: 15 days, 21:52:07  iter: 8879  total_loss: 0.1608  loss_cls: 0.04265  loss_box_reg: 0.1128  loss_rpn_cls: 6.143e-05  loss_rpn_loc: 0.00162    time: 2.5329  last_time: 2.2495  data_time: 1.6130  last_data_time: 1.3482   lr: 0.00099946  max_mem: 4121M\n",
      "\u001b[32m[09/06 22:41:55 d2.utils.events]: \u001b[0m eta: 15 days, 22:06:41  iter: 8899  total_loss: 0.1493  loss_cls: 0.04177  loss_box_reg: 0.1044  loss_rpn_cls: 7.899e-05  loss_rpn_loc: 0.001328    time: 2.5330  last_time: 2.8029  data_time: 1.6288  last_data_time: 1.7883   lr: 0.00099946  max_mem: 4121M\n",
      "\u001b[32m[09/06 22:42:47 d2.utils.events]: \u001b[0m eta: 15 days, 22:38:13  iter: 8919  total_loss: 0.17  loss_cls: 0.05785  loss_box_reg: 0.1092  loss_rpn_cls: 6.967e-05  loss_rpn_loc: 0.001315    time: 2.5331  last_time: 2.5003  data_time: 1.6496  last_data_time: 1.6082   lr: 0.00099946  max_mem: 4121M\n",
      "\u001b[32m[09/06 22:43:36 d2.utils.events]: \u001b[0m eta: 15 days, 23:52:29  iter: 8939  total_loss: 0.161  loss_cls: 0.05279  loss_box_reg: 0.1044  loss_rpn_cls: 4.847e-05  loss_rpn_loc: 0.001386    time: 2.5329  last_time: 2.0735  data_time: 1.5346  last_data_time: 1.0835   lr: 0.00099945  max_mem: 4121M\n",
      "\u001b[32m[09/06 22:44:28 d2.utils.events]: \u001b[0m eta: 16 days, 1:02:03  iter: 8959  total_loss: 0.1557  loss_cls: 0.05698  loss_box_reg: 0.1114  loss_rpn_cls: 5.887e-05  loss_rpn_loc: 0.001385    time: 2.5331  last_time: 2.5152  data_time: 1.6763  last_data_time: 1.6373   lr: 0.00099945  max_mem: 4121M\n",
      "\u001b[32m[09/06 22:45:21 d2.utils.events]: \u001b[0m eta: 16 days, 2:28:29  iter: 8979  total_loss: 0.1566  loss_cls: 0.04937  loss_box_reg: 0.1106  loss_rpn_cls: 5.566e-05  loss_rpn_loc: 0.001501    time: 2.5334  last_time: 2.7826  data_time: 1.6279  last_data_time: 1.7646   lr: 0.00099945  max_mem: 4121M\n",
      "\u001b[32m[09/06 22:46:18 d2.data.datasets.coco]: \u001b[0mLoaded 1199 images in COCO format from data/ssd_rcnn_face/annotations_val.json\n",
      "\u001b[32m[09/06 22:46:19 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(512, 512), max_size=512, sample_style='choice')]\n",
      "\u001b[32m[09/06 22:46:19 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[09/06 22:46:19 d2.data.common]: \u001b[0mSerializing 1199 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[09/06 22:46:19 d2.data.common]: \u001b[0mSerialized dataset takes 0.36 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[09/06 22:46:19 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n",
      "\u001b[32m[09/06 22:46:19 d2.evaluation.evaluator]: \u001b[0mStart inference on 1199 batches\n",
      "\u001b[32m[09/06 22:46:20 d2.evaluation.evaluator]: \u001b[0mInference done 11/1199. Dataloading: 0.0595 s/iter. Inference: 0.0715 s/iter. Eval: 0.0006 s/iter. Total: 0.1316 s/iter. ETA=0:02:36\n",
      "\u001b[32m[09/06 22:46:26 d2.evaluation.evaluator]: \u001b[0mInference done 43/1199. Dataloading: 0.0797 s/iter. Inference: 0.0751 s/iter. Eval: 0.0006 s/iter. Total: 0.1555 s/iter. ETA=0:02:59\n",
      "\u001b[32m[09/06 22:46:31 d2.evaluation.evaluator]: \u001b[0mInference done 73/1199. Dataloading: 0.0840 s/iter. Inference: 0.0777 s/iter. Eval: 0.0007 s/iter. Total: 0.1625 s/iter. ETA=0:03:02\n",
      "\u001b[32m[09/06 22:46:36 d2.evaluation.evaluator]: \u001b[0mInference done 95/1199. Dataloading: 0.0991 s/iter. Inference: 0.0787 s/iter. Eval: 0.0007 s/iter. Total: 0.1785 s/iter. ETA=0:03:17\n",
      "\u001b[32m[09/06 22:46:41 d2.evaluation.evaluator]: \u001b[0mInference done 119/1199. Dataloading: 0.1081 s/iter. Inference: 0.0813 s/iter. Eval: 0.0007 s/iter. Total: 0.1903 s/iter. ETA=0:03:25\n",
      "\u001b[32m[09/06 22:46:47 d2.evaluation.evaluator]: \u001b[0mInference done 152/1199. Dataloading: 0.1012 s/iter. Inference: 0.0806 s/iter. Eval: 0.0007 s/iter. Total: 0.1826 s/iter. ETA=0:03:11\n",
      "\u001b[32m[09/06 22:46:52 d2.evaluation.evaluator]: \u001b[0mInference done 179/1199. Dataloading: 0.1020 s/iter. Inference: 0.0804 s/iter. Eval: 0.0007 s/iter. Total: 0.1832 s/iter. ETA=0:03:06\n",
      "\u001b[32m[09/06 22:46:57 d2.evaluation.evaluator]: \u001b[0mInference done 208/1199. Dataloading: 0.1013 s/iter. Inference: 0.0803 s/iter. Eval: 0.0007 s/iter. Total: 0.1824 s/iter. ETA=0:03:00\n",
      "\u001b[32m[09/06 22:47:02 d2.evaluation.evaluator]: \u001b[0mInference done 234/1199. Dataloading: 0.1028 s/iter. Inference: 0.0801 s/iter. Eval: 0.0007 s/iter. Total: 0.1837 s/iter. ETA=0:02:57\n",
      "\u001b[32m[09/06 22:47:07 d2.evaluation.evaluator]: \u001b[0mInference done 258/1199. Dataloading: 0.1056 s/iter. Inference: 0.0801 s/iter. Eval: 0.0007 s/iter. Total: 0.1865 s/iter. ETA=0:02:55\n",
      "\u001b[32m[09/06 22:47:13 d2.evaluation.evaluator]: \u001b[0mInference done 279/1199. Dataloading: 0.1123 s/iter. Inference: 0.0806 s/iter. Eval: 0.0007 s/iter. Total: 0.1937 s/iter. ETA=0:02:58\n",
      "\u001b[32m[09/06 22:47:18 d2.evaluation.evaluator]: \u001b[0mInference done 298/1199. Dataloading: 0.1165 s/iter. Inference: 0.0810 s/iter. Eval: 0.0007 s/iter. Total: 0.1983 s/iter. ETA=0:02:58\n",
      "\u001b[32m[09/06 22:47:23 d2.evaluation.evaluator]: \u001b[0mInference done 325/1199. Dataloading: 0.1153 s/iter. Inference: 0.0815 s/iter. Eval: 0.0007 s/iter. Total: 0.1976 s/iter. ETA=0:02:52\n",
      "\u001b[32m[09/06 22:47:28 d2.evaluation.evaluator]: \u001b[0mInference done 354/1199. Dataloading: 0.1141 s/iter. Inference: 0.0811 s/iter. Eval: 0.0007 s/iter. Total: 0.1960 s/iter. ETA=0:02:45\n",
      "\u001b[32m[09/06 22:47:33 d2.evaluation.evaluator]: \u001b[0mInference done 380/1199. Dataloading: 0.1143 s/iter. Inference: 0.0809 s/iter. Eval: 0.0007 s/iter. Total: 0.1960 s/iter. ETA=0:02:40\n",
      "\u001b[32m[09/06 22:47:38 d2.evaluation.evaluator]: \u001b[0mInference done 408/1199. Dataloading: 0.1133 s/iter. Inference: 0.0807 s/iter. Eval: 0.0007 s/iter. Total: 0.1948 s/iter. ETA=0:02:34\n",
      "\u001b[32m[09/06 22:47:43 d2.evaluation.evaluator]: \u001b[0mInference done 441/1199. Dataloading: 0.1106 s/iter. Inference: 0.0802 s/iter. Eval: 0.0007 s/iter. Total: 0.1916 s/iter. ETA=0:02:25\n",
      "\u001b[32m[09/06 22:47:48 d2.evaluation.evaluator]: \u001b[0mInference done 469/1199. Dataloading: 0.1098 s/iter. Inference: 0.0803 s/iter. Eval: 0.0007 s/iter. Total: 0.1909 s/iter. ETA=0:02:19\n",
      "\u001b[32m[09/06 22:47:54 d2.evaluation.evaluator]: \u001b[0mInference done 500/1199. Dataloading: 0.1088 s/iter. Inference: 0.0801 s/iter. Eval: 0.0007 s/iter. Total: 0.1897 s/iter. ETA=0:02:12\n",
      "\u001b[32m[09/06 22:47:59 d2.evaluation.evaluator]: \u001b[0mInference done 528/1199. Dataloading: 0.1082 s/iter. Inference: 0.0803 s/iter. Eval: 0.0007 s/iter. Total: 0.1892 s/iter. ETA=0:02:06\n",
      "\u001b[32m[09/06 22:48:04 d2.evaluation.evaluator]: \u001b[0mInference done 556/1199. Dataloading: 0.1079 s/iter. Inference: 0.0803 s/iter. Eval: 0.0007 s/iter. Total: 0.1891 s/iter. ETA=0:02:01\n",
      "\u001b[32m[09/06 22:48:09 d2.evaluation.evaluator]: \u001b[0mInference done 586/1199. Dataloading: 0.1073 s/iter. Inference: 0.0801 s/iter. Eval: 0.0007 s/iter. Total: 0.1881 s/iter. ETA=0:01:55\n",
      "\u001b[32m[09/06 22:48:14 d2.evaluation.evaluator]: \u001b[0mInference done 618/1199. Dataloading: 0.1062 s/iter. Inference: 0.0803 s/iter. Eval: 0.0007 s/iter. Total: 0.1872 s/iter. ETA=0:01:48\n",
      "\u001b[32m[09/06 22:48:21 d2.evaluation.evaluator]: \u001b[0mInference done 645/1199. Dataloading: 0.1081 s/iter. Inference: 0.0802 s/iter. Eval: 0.0007 s/iter. Total: 0.1891 s/iter. ETA=0:01:44\n",
      "\u001b[32m[09/06 22:48:26 d2.evaluation.evaluator]: \u001b[0mInference done 675/1199. Dataloading: 0.1080 s/iter. Inference: 0.0804 s/iter. Eval: 0.0007 s/iter. Total: 0.1892 s/iter. ETA=0:01:39\n",
      "\u001b[32m[09/06 22:48:32 d2.evaluation.evaluator]: \u001b[0mInference done 708/1199. Dataloading: 0.1064 s/iter. Inference: 0.0804 s/iter. Eval: 0.0007 s/iter. Total: 0.1877 s/iter. ETA=0:01:32\n",
      "\u001b[32m[09/06 22:48:37 d2.evaluation.evaluator]: \u001b[0mInference done 736/1199. Dataloading: 0.1063 s/iter. Inference: 0.0804 s/iter. Eval: 0.0007 s/iter. Total: 0.1875 s/iter. ETA=0:01:26\n",
      "\u001b[32m[09/06 22:48:42 d2.evaluation.evaluator]: \u001b[0mInference done 752/1199. Dataloading: 0.1087 s/iter. Inference: 0.0807 s/iter. Eval: 0.0007 s/iter. Total: 0.1903 s/iter. ETA=0:01:25\n",
      "\u001b[32m[09/06 22:48:47 d2.evaluation.evaluator]: \u001b[0mInference done 778/1199. Dataloading: 0.1087 s/iter. Inference: 0.0808 s/iter. Eval: 0.0007 s/iter. Total: 0.1904 s/iter. ETA=0:01:20\n",
      "\u001b[32m[09/06 22:48:52 d2.evaluation.evaluator]: \u001b[0mInference done 810/1199. Dataloading: 0.1078 s/iter. Inference: 0.0805 s/iter. Eval: 0.0007 s/iter. Total: 0.1891 s/iter. ETA=0:01:13\n",
      "\u001b[32m[09/06 22:48:57 d2.evaluation.evaluator]: \u001b[0mInference done 842/1199. Dataloading: 0.1067 s/iter. Inference: 0.0803 s/iter. Eval: 0.0007 s/iter. Total: 0.1878 s/iter. ETA=0:01:07\n",
      "\u001b[32m[09/06 22:49:02 d2.evaluation.evaluator]: \u001b[0mInference done 870/1199. Dataloading: 0.1065 s/iter. Inference: 0.0802 s/iter. Eval: 0.0007 s/iter. Total: 0.1876 s/iter. ETA=0:01:01\n",
      "\u001b[32m[09/06 22:49:07 d2.evaluation.evaluator]: \u001b[0mInference done 897/1199. Dataloading: 0.1069 s/iter. Inference: 0.0801 s/iter. Eval: 0.0007 s/iter. Total: 0.1878 s/iter. ETA=0:00:56\n",
      "\u001b[32m[09/06 22:49:12 d2.evaluation.evaluator]: \u001b[0mInference done 929/1199. Dataloading: 0.1061 s/iter. Inference: 0.0799 s/iter. Eval: 0.0007 s/iter. Total: 0.1868 s/iter. ETA=0:00:50\n",
      "\u001b[32m[09/06 22:49:18 d2.evaluation.evaluator]: \u001b[0mInference done 961/1199. Dataloading: 0.1054 s/iter. Inference: 0.0798 s/iter. Eval: 0.0007 s/iter. Total: 0.1860 s/iter. ETA=0:00:44\n",
      "\u001b[32m[09/06 22:49:23 d2.evaluation.evaluator]: \u001b[0mInference done 985/1199. Dataloading: 0.1062 s/iter. Inference: 0.0797 s/iter. Eval: 0.0007 s/iter. Total: 0.1866 s/iter. ETA=0:00:39\n",
      "\u001b[32m[09/06 22:49:28 d2.evaluation.evaluator]: \u001b[0mInference done 1016/1199. Dataloading: 0.1057 s/iter. Inference: 0.0795 s/iter. Eval: 0.0007 s/iter. Total: 0.1859 s/iter. ETA=0:00:34\n",
      "\u001b[32m[09/06 22:49:33 d2.evaluation.evaluator]: \u001b[0mInference done 1038/1199. Dataloading: 0.1067 s/iter. Inference: 0.0796 s/iter. Eval: 0.0007 s/iter. Total: 0.1871 s/iter. ETA=0:00:30\n",
      "\u001b[32m[09/06 22:49:38 d2.evaluation.evaluator]: \u001b[0mInference done 1067/1199. Dataloading: 0.1065 s/iter. Inference: 0.0795 s/iter. Eval: 0.0007 s/iter. Total: 0.1868 s/iter. ETA=0:00:24\n",
      "\u001b[32m[09/06 22:49:44 d2.evaluation.evaluator]: \u001b[0mInference done 1095/1199. Dataloading: 0.1068 s/iter. Inference: 0.0794 s/iter. Eval: 0.0007 s/iter. Total: 0.1870 s/iter. ETA=0:00:19\n",
      "\u001b[32m[09/06 22:49:50 d2.evaluation.evaluator]: \u001b[0mInference done 1126/1199. Dataloading: 0.1071 s/iter. Inference: 0.0794 s/iter. Eval: 0.0007 s/iter. Total: 0.1873 s/iter. ETA=0:00:13\n",
      "\u001b[32m[09/06 22:49:55 d2.evaluation.evaluator]: \u001b[0mInference done 1156/1199. Dataloading: 0.1067 s/iter. Inference: 0.0793 s/iter. Eval: 0.0007 s/iter. Total: 0.1868 s/iter. ETA=0:00:08\n",
      "\u001b[32m[09/06 22:50:00 d2.evaluation.evaluator]: \u001b[0mInference done 1185/1199. Dataloading: 0.1064 s/iter. Inference: 0.0793 s/iter. Eval: 0.0007 s/iter. Total: 0.1865 s/iter. ETA=0:00:02\n",
      "\u001b[32m[09/06 22:50:02 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:03:42.728449 (0.186540 s / iter per device, on 1 devices)\n",
      "\u001b[32m[09/06 22:50:02 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:01:34 (0.079242 s / iter per device, on 1 devices)\n",
      "\u001b[32m[09/06 22:50:02 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[09/06 22:50:02 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[09/06 22:50:02 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[09/06 22:50:03 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.11 seconds.\n",
      "\u001b[32m[09/06 22:50:03 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[09/06 22:50:03 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.01 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.719\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.847\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.838\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.719\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.833\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.833\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.833\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.833\n",
      "\u001b[32m[09/06 22:50:03 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
      "| 71.880 | 84.723 | 83.834 |  nan  |  nan  | 71.880 |\n",
      "\u001b[32m[09/06 22:50:03 d2.evaluation.coco_evaluation]: \u001b[0mSome metrics cannot be computed and is shown as NaN.\n",
      "\u001b[32m[09/06 22:50:03 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category   | AP     | category   | AP     | category   | AP     |\n",
      "|:-----------|:-------|:-----------|:-------|:-----------|:-------|\n",
      "| angry      | 65.797 | sad        | 70.822 | surprised  | 69.109 |\n",
      "| happy      | 81.794 |            |        |            |        |\n",
      "\u001b[32m[09/06 22:50:03 d2.engine.defaults]: \u001b[0mEvaluation results for face_data_set_valid in csv format:\n",
      "\u001b[32m[09/06 22:50:03 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[09/06 22:50:03 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[09/06 22:50:03 d2.evaluation.testing]: \u001b[0mcopypaste: 71.8804,84.7231,83.8343,nan,nan,71.8804\n",
      "\u001b[32m[09/06 22:50:03 d2.utils.events]: \u001b[0m eta: 16 days, 3:42:03  iter: 8999  total_loss: 0.1507  loss_cls: 0.04127  loss_box_reg: 0.109  loss_rpn_cls: 4.53e-05  loss_rpn_loc: 0.001366    time: 2.5339  last_time: 2.7838  data_time: 1.7087  last_data_time: 1.7354   lr: 0.00099945  max_mem: 4121M\n",
      "\u001b[32m[09/06 22:51:01 d2.utils.events]: \u001b[0m eta: 16 days, 5:24:18  iter: 9019  total_loss: 0.1601  loss_cls: 0.05405  loss_box_reg: 0.0993  loss_rpn_cls: 7.561e-05  loss_rpn_loc: 0.0015    time: 2.5349  last_time: 3.3938  data_time: 1.8616  last_data_time: 2.2308   lr: 0.00099944  max_mem: 4121M\n",
      "\u001b[32m[09/06 22:51:58 d2.utils.events]: \u001b[0m eta: 16 days, 7:53:59  iter: 9039  total_loss: 0.1688  loss_cls: 0.04129  loss_box_reg: 0.1171  loss_rpn_cls: 6.142e-05  loss_rpn_loc: 0.00136    time: 2.5357  last_time: 2.8975  data_time: 1.8100  last_data_time: 1.8325   lr: 0.00099944  max_mem: 4121M\n",
      "\u001b[32m[09/06 22:52:59 d2.utils.events]: \u001b[0m eta: 16 days, 9:41:25  iter: 9059  total_loss: 0.1679  loss_cls: 0.05492  loss_box_reg: 0.1167  loss_rpn_cls: 5.309e-05  loss_rpn_loc: 0.001517    time: 2.5370  last_time: 3.1219  data_time: 1.9648  last_data_time: 1.9897   lr: 0.00099944  max_mem: 4121M\n",
      "\u001b[32m[09/06 22:53:57 d2.utils.events]: \u001b[0m eta: 16 days, 12:15:43  iter: 9079  total_loss: 0.1586  loss_cls: 0.0485  loss_box_reg: 0.1045  loss_rpn_cls: 7.016e-05  loss_rpn_loc: 0.001489    time: 2.5379  last_time: 3.0970  data_time: 1.8023  last_data_time: 1.9331   lr: 0.00099944  max_mem: 4121M\n",
      "\u001b[32m[09/06 22:54:55 d2.utils.events]: \u001b[0m eta: 16 days, 13:30:37  iter: 9099  total_loss: 0.1572  loss_cls: 0.03973  loss_box_reg: 0.1151  loss_rpn_cls: 4.692e-05  loss_rpn_loc: 0.001442    time: 2.5387  last_time: 2.7028  data_time: 1.7852  last_data_time: 1.6589   lr: 0.00099943  max_mem: 4121M\n",
      "\u001b[32m[09/06 22:55:50 d2.utils.events]: \u001b[0m eta: 16 days, 14:18:08  iter: 9119  total_loss: 0.1578  loss_cls: 0.04137  loss_box_reg: 0.1165  loss_rpn_cls: 6.824e-05  loss_rpn_loc: 0.001446    time: 2.5392  last_time: 2.5443  data_time: 1.7222  last_data_time: 1.5432   lr: 0.00099943  max_mem: 4121M\n",
      "\u001b[32m[09/06 22:56:49 d2.utils.events]: \u001b[0m eta: 16 days, 16:05:27  iter: 9139  total_loss: 0.1578  loss_cls: 0.05079  loss_box_reg: 0.1049  loss_rpn_cls: 8.21e-05  loss_rpn_loc: 0.001525    time: 2.5403  last_time: 2.4378  data_time: 1.8925  last_data_time: 1.4191   lr: 0.00099943  max_mem: 4121M\n",
      "\u001b[32m[09/06 22:57:46 d2.utils.events]: \u001b[0m eta: 16 days, 17:22:20  iter: 9159  total_loss: 0.1887  loss_cls: 0.07129  loss_box_reg: 0.1126  loss_rpn_cls: 6.653e-05  loss_rpn_loc: 0.001542    time: 2.5410  last_time: 2.6288  data_time: 1.7734  last_data_time: 1.6913   lr: 0.00099943  max_mem: 4121M\n",
      "\u001b[32m[09/06 22:58:48 d2.utils.events]: \u001b[0m eta: 16 days, 19:44:45  iter: 9179  total_loss: 0.1604  loss_cls: 0.0434  loss_box_reg: 0.1059  loss_rpn_cls: 6.429e-05  loss_rpn_loc: 0.001449    time: 2.5423  last_time: 2.4200  data_time: 1.9895  last_data_time: 1.4948   lr: 0.00099942  max_mem: 4121M\n",
      "\u001b[32m[09/06 22:59:43 d2.utils.events]: \u001b[0m eta: 16 days, 22:01:17  iter: 9199  total_loss: 0.1572  loss_cls: 0.03762  loss_box_reg: 0.1087  loss_rpn_cls: 5.976e-05  loss_rpn_loc: 0.001303    time: 2.5429  last_time: 2.5090  data_time: 1.7258  last_data_time: 1.4838   lr: 0.00099942  max_mem: 4121M\n",
      "\u001b[32m[09/06 23:00:39 d2.utils.events]: \u001b[0m eta: 16 days, 23:54:02  iter: 9219  total_loss: 0.1707  loss_cls: 0.05849  loss_box_reg: 0.1129  loss_rpn_cls: 5.958e-05  loss_rpn_loc: 0.001649    time: 2.5435  last_time: 2.5775  data_time: 1.7737  last_data_time: 1.5923   lr: 0.00099942  max_mem: 4121M\n",
      "\u001b[32m[09/06 23:01:36 d2.utils.events]: \u001b[0m eta: 17 days, 0:54:33  iter: 9239  total_loss: 0.1653  loss_cls: 0.05882  loss_box_reg: 0.09629  loss_rpn_cls: 7.928e-05  loss_rpn_loc: 0.001506    time: 2.5442  last_time: 3.1801  data_time: 1.7514  last_data_time: 2.0101   lr: 0.00099942  max_mem: 4121M\n",
      "\u001b[32m[09/06 23:02:35 d2.utils.events]: \u001b[0m eta: 17 days, 2:41:04  iter: 9259  total_loss: 0.1502  loss_cls: 0.03878  loss_box_reg: 0.1084  loss_rpn_cls: 6.424e-05  loss_rpn_loc: 0.001468    time: 2.5452  last_time: 2.8846  data_time: 1.8993  last_data_time: 1.8260   lr: 0.00099941  max_mem: 4121M\n",
      "\u001b[32m[09/06 23:03:31 d2.utils.events]: \u001b[0m eta: 17 days, 4:16:59  iter: 9279  total_loss: 0.1533  loss_cls: 0.04967  loss_box_reg: 0.1106  loss_rpn_cls: 5.227e-05  loss_rpn_loc: 0.001428    time: 2.5458  last_time: 2.6084  data_time: 1.7463  last_data_time: 1.5514   lr: 0.00099941  max_mem: 4121M\n",
      "\u001b[32m[09/06 23:04:25 d2.utils.events]: \u001b[0m eta: 17 days, 4:29:30  iter: 9299  total_loss: 0.1381  loss_cls: 0.03215  loss_box_reg: 0.09944  loss_rpn_cls: 5.978e-05  loss_rpn_loc: 0.00145    time: 2.5463  last_time: 2.5035  data_time: 1.6788  last_data_time: 1.5092   lr: 0.00099941  max_mem: 4121M\n",
      "\u001b[32m[09/06 23:05:23 d2.utils.events]: \u001b[0m eta: 17 days, 5:39:53  iter: 9319  total_loss: 0.168  loss_cls: 0.0448  loss_box_reg: 0.1141  loss_rpn_cls: 0.0001025  loss_rpn_loc: 0.001597    time: 2.5470  last_time: 2.4699  data_time: 1.7920  last_data_time: 1.4903   lr: 0.00099941  max_mem: 4121M\n",
      "\u001b[32m[09/06 23:06:22 d2.utils.events]: \u001b[0m eta: 17 days, 7:26:22  iter: 9339  total_loss: 0.1438  loss_cls: 0.03802  loss_box_reg: 0.1062  loss_rpn_cls: 5.347e-05  loss_rpn_loc: 0.001425    time: 2.5480  last_time: 3.1406  data_time: 1.8836  last_data_time: 2.0845   lr: 0.0009994  max_mem: 4121M\n",
      "\u001b[32m[09/06 23:07:18 d2.utils.events]: \u001b[0m eta: 17 days, 9:17:16  iter: 9359  total_loss: 0.1659  loss_cls: 0.04677  loss_box_reg: 0.1135  loss_rpn_cls: 7.069e-05  loss_rpn_loc: 0.001348    time: 2.5487  last_time: 2.8796  data_time: 1.7855  last_data_time: 1.8035   lr: 0.0009994  max_mem: 4121M\n",
      "\u001b[32m[09/06 23:08:16 d2.utils.events]: \u001b[0m eta: 17 days, 12:13:13  iter: 9379  total_loss: 0.1591  loss_cls: 0.03976  loss_box_reg: 0.1158  loss_rpn_cls: 8.467e-05  loss_rpn_loc: 0.00149    time: 2.5494  last_time: 2.6782  data_time: 1.7873  last_data_time: 1.6286   lr: 0.0009994  max_mem: 4121M\n",
      "\u001b[32m[09/06 23:09:09 d2.utils.events]: \u001b[0m eta: 17 days, 13:13:10  iter: 9399  total_loss: 0.142  loss_cls: 0.03648  loss_box_reg: 0.1022  loss_rpn_cls: 6.859e-05  loss_rpn_loc: 0.001514    time: 2.5497  last_time: 2.6840  data_time: 1.6623  last_data_time: 1.6379   lr: 0.00099939  max_mem: 4121M\n",
      "\u001b[32m[09/06 23:10:02 d2.utils.events]: \u001b[0m eta: 17 days, 14:27:06  iter: 9419  total_loss: 0.1566  loss_cls: 0.04621  loss_box_reg: 0.1079  loss_rpn_cls: 6.325e-05  loss_rpn_loc: 0.001466    time: 2.5499  last_time: 2.5407  data_time: 1.6449  last_data_time: 1.5581   lr: 0.00099939  max_mem: 4121M\n",
      "\u001b[32m[09/06 23:10:57 d2.utils.events]: \u001b[0m eta: 17 days, 15:55:19  iter: 9439  total_loss: 0.1671  loss_cls: 0.05576  loss_box_reg: 0.1106  loss_rpn_cls: 5.427e-05  loss_rpn_loc: 0.001462    time: 2.5504  last_time: 2.3925  data_time: 1.7201  last_data_time: 1.4040   lr: 0.00099939  max_mem: 4121M\n",
      "\u001b[32m[09/06 23:11:53 d2.utils.events]: \u001b[0m eta: 17 days, 17:16:27  iter: 9459  total_loss: 0.1636  loss_cls: 0.04962  loss_box_reg: 0.1176  loss_rpn_cls: 4.993e-05  loss_rpn_loc: 0.001357    time: 2.5510  last_time: 2.8455  data_time: 1.7320  last_data_time: 1.8385   lr: 0.00099939  max_mem: 4121M\n",
      "\u001b[32m[09/06 23:12:51 d2.utils.events]: \u001b[0m eta: 17 days, 18:12:33  iter: 9479  total_loss: 0.1641  loss_cls: 0.05386  loss_box_reg: 0.1028  loss_rpn_cls: 6.274e-05  loss_rpn_loc: 0.001445    time: 2.5518  last_time: 2.9479  data_time: 1.8196  last_data_time: 1.8092   lr: 0.00099938  max_mem: 4121M\n",
      "\u001b[32m[09/06 23:13:48 d2.utils.events]: \u001b[0m eta: 17 days, 19:21:44  iter: 9499  total_loss: 0.1652  loss_cls: 0.05802  loss_box_reg: 0.1127  loss_rpn_cls: 7.325e-05  loss_rpn_loc: 0.001484    time: 2.5522  last_time: 2.3661  data_time: 1.7155  last_data_time: 1.3867   lr: 0.00099938  max_mem: 4121M\n",
      "\u001b[32m[09/06 23:14:42 d2.utils.events]: \u001b[0m eta: 17 days, 20:14:03  iter: 9519  total_loss: 0.1654  loss_cls: 0.04661  loss_box_reg: 0.115  loss_rpn_cls: 5.641e-05  loss_rpn_loc: 0.001435    time: 2.5525  last_time: 2.3868  data_time: 1.6338  last_data_time: 1.4307   lr: 0.00099938  max_mem: 4121M\n",
      "\u001b[32m[09/06 23:15:37 d2.utils.events]: \u001b[0m eta: 17 days, 21:52:24  iter: 9539  total_loss: 0.1504  loss_cls: 0.04217  loss_box_reg: 0.1035  loss_rpn_cls: 4.855e-05  loss_rpn_loc: 0.001375    time: 2.5530  last_time: 2.7421  data_time: 1.7297  last_data_time: 1.6990   lr: 0.00099938  max_mem: 4121M\n",
      "\u001b[32m[09/06 23:16:37 d2.utils.events]: \u001b[0m eta: 17 days, 23:37:47  iter: 9559  total_loss: 0.1566  loss_cls: 0.04993  loss_box_reg: 0.1019  loss_rpn_cls: 5.564e-05  loss_rpn_loc: 0.001291    time: 2.5541  last_time: 3.0449  data_time: 1.9516  last_data_time: 1.8894   lr: 0.00099937  max_mem: 4121M\n",
      "\u001b[32m[09/06 23:17:34 d2.utils.events]: \u001b[0m eta: 18 days, 1:22:13  iter: 9579  total_loss: 0.1566  loss_cls: 0.0359  loss_box_reg: 0.1129  loss_rpn_cls: 7.145e-05  loss_rpn_loc: 0.001458    time: 2.5547  last_time: 2.6120  data_time: 1.7945  last_data_time: 1.6384   lr: 0.00099937  max_mem: 4121M\n",
      "\u001b[32m[09/06 23:18:32 d2.utils.events]: \u001b[0m eta: 18 days, 3:19:17  iter: 9599  total_loss: 0.1573  loss_cls: 0.03755  loss_box_reg: 0.1115  loss_rpn_cls: 6.741e-05  loss_rpn_loc: 0.00152    time: 2.5555  last_time: 2.4712  data_time: 1.8198  last_data_time: 1.5054   lr: 0.00099937  max_mem: 4121M\n",
      "\u001b[32m[09/06 23:19:25 d2.utils.events]: \u001b[0m eta: 18 days, 3:45:13  iter: 9619  total_loss: 0.1627  loss_cls: 0.04043  loss_box_reg: 0.1123  loss_rpn_cls: 6.444e-05  loss_rpn_loc: 0.00148    time: 2.5558  last_time: 2.2750  data_time: 1.6618  last_data_time: 1.2746   lr: 0.00099937  max_mem: 4121M\n",
      "\u001b[32m[09/06 23:20:21 d2.utils.events]: \u001b[0m eta: 18 days, 5:56:20  iter: 9639  total_loss: 0.1666  loss_cls: 0.04479  loss_box_reg: 0.111  loss_rpn_cls: 4.28e-05  loss_rpn_loc: 0.001344    time: 2.5564  last_time: 2.2761  data_time: 1.7371  last_data_time: 1.3207   lr: 0.00099936  max_mem: 4121M\n",
      "\u001b[32m[09/06 23:21:13 d2.utils.events]: \u001b[0m eta: 18 days, 6:03:06  iter: 9659  total_loss: 0.1608  loss_cls: 0.05069  loss_box_reg: 0.1084  loss_rpn_cls: 4.267e-05  loss_rpn_loc: 0.001423    time: 2.5565  last_time: 2.1926  data_time: 1.6105  last_data_time: 1.2404   lr: 0.00099936  max_mem: 4121M\n",
      "\u001b[32m[09/06 23:22:01 d2.utils.events]: \u001b[0m eta: 18 days, 5:45:26  iter: 9679  total_loss: 0.1716  loss_cls: 0.05172  loss_box_reg: 0.1109  loss_rpn_cls: 4.413e-05  loss_rpn_loc: 0.001486    time: 2.5561  last_time: 1.9721  data_time: 1.4979  last_data_time: 1.1155   lr: 0.00099936  max_mem: 4121M\n",
      "\u001b[32m[09/06 23:22:50 d2.utils.events]: \u001b[0m eta: 18 days, 5:15:56  iter: 9699  total_loss: 0.1597  loss_cls: 0.04174  loss_box_reg: 0.1047  loss_rpn_cls: 4.638e-05  loss_rpn_loc: 0.001565    time: 2.5558  last_time: 2.5501  data_time: 1.5298  last_data_time: 1.6828   lr: 0.00099936  max_mem: 4121M\n",
      "\u001b[32m[09/06 23:23:38 d2.utils.events]: \u001b[0m eta: 18 days, 4:25:29  iter: 9719  total_loss: 0.1499  loss_cls: 0.04158  loss_box_reg: 0.1058  loss_rpn_cls: 6.731e-05  loss_rpn_loc: 0.001491    time: 2.5554  last_time: 2.0218  data_time: 1.4706  last_data_time: 1.1534   lr: 0.00099935  max_mem: 4121M\n",
      "\u001b[32m[09/06 23:24:25 d2.utils.events]: \u001b[0m eta: 18 days, 3:29:11  iter: 9739  total_loss: 0.1403  loss_cls: 0.02949  loss_box_reg: 0.1087  loss_rpn_cls: 4.458e-05  loss_rpn_loc: 0.001473    time: 2.5549  last_time: 1.4392  data_time: 1.4165  last_data_time: 0.5766   lr: 0.00099935  max_mem: 4121M\n",
      "\u001b[32m[09/06 23:25:13 d2.utils.events]: \u001b[0m eta: 18 days, 3:22:59  iter: 9759  total_loss: 0.1681  loss_cls: 0.05187  loss_box_reg: 0.1099  loss_rpn_cls: 6.562e-05  loss_rpn_loc: 0.001309    time: 2.5547  last_time: 2.3182  data_time: 1.5344  last_data_time: 1.4773   lr: 0.00099935  max_mem: 4121M\n",
      "\u001b[32m[09/06 23:26:01 d2.utils.events]: \u001b[0m eta: 18 days, 3:17:04  iter: 9779  total_loss: 0.1433  loss_cls: 0.03537  loss_box_reg: 0.1022  loss_rpn_cls: 5.964e-05  loss_rpn_loc: 0.001317    time: 2.5543  last_time: 2.3969  data_time: 1.4942  last_data_time: 1.4899   lr: 0.00099934  max_mem: 4121M\n",
      "\u001b[32m[09/06 23:26:51 d2.utils.events]: \u001b[0m eta: 18 days, 3:10:26  iter: 9799  total_loss: 0.1547  loss_cls: 0.04344  loss_box_reg: 0.1163  loss_rpn_cls: 5.975e-05  loss_rpn_loc: 0.001484    time: 2.5541  last_time: 2.4978  data_time: 1.5435  last_data_time: 1.5737   lr: 0.00099934  max_mem: 4121M\n",
      "\u001b[32m[09/06 23:27:40 d2.utils.events]: \u001b[0m eta: 18 days, 3:03:34  iter: 9819  total_loss: 0.1488  loss_cls: 0.04148  loss_box_reg: 0.1039  loss_rpn_cls: 7.584e-05  loss_rpn_loc: 0.001488    time: 2.5540  last_time: 2.1208  data_time: 1.5710  last_data_time: 1.2155   lr: 0.00099934  max_mem: 4121M\n",
      "\u001b[32m[09/06 23:28:31 d2.utils.events]: \u001b[0m eta: 18 days, 3:02:41  iter: 9839  total_loss: 0.1519  loss_cls: 0.04376  loss_box_reg: 0.1011  loss_rpn_cls: 6.2e-05  loss_rpn_loc: 0.001435    time: 2.5539  last_time: 2.1068  data_time: 1.6182  last_data_time: 1.2299   lr: 0.00099934  max_mem: 4121M\n",
      "\u001b[32m[09/06 23:29:23 d2.utils.events]: \u001b[0m eta: 18 days, 2:07:05  iter: 9859  total_loss: 0.1501  loss_cls: 0.03386  loss_box_reg: 0.1106  loss_rpn_cls: 5.033e-05  loss_rpn_loc: 0.001371    time: 2.5540  last_time: 3.4406  data_time: 1.6318  last_data_time: 2.4176   lr: 0.00099933  max_mem: 4121M\n",
      "\u001b[32m[09/06 23:30:08 d2.utils.events]: \u001b[0m eta: 18 days, 1:31:41  iter: 9879  total_loss: 0.1543  loss_cls: 0.03914  loss_box_reg: 0.1126  loss_rpn_cls: 9.049e-05  loss_rpn_loc: 0.001381    time: 2.5533  last_time: 2.1942  data_time: 1.3684  last_data_time: 1.3143   lr: 0.00099933  max_mem: 4121M\n",
      "\u001b[32m[09/06 23:31:00 d2.utils.events]: \u001b[0m eta: 18 days, 1:34:51  iter: 9899  total_loss: 0.1504  loss_cls: 0.03881  loss_box_reg: 0.101  loss_rpn_cls: 6.911e-05  loss_rpn_loc: 0.001494    time: 2.5534  last_time: 3.0573  data_time: 1.6302  last_data_time: 1.9716   lr: 0.00099933  max_mem: 4121M\n",
      "\u001b[32m[09/06 23:32:03 d2.utils.events]: \u001b[0m eta: 18 days, 2:59:08  iter: 9919  total_loss: 0.1782  loss_cls: 0.04743  loss_box_reg: 0.1152  loss_rpn_cls: 9.261e-05  loss_rpn_loc: 0.001647    time: 2.5548  last_time: 2.8784  data_time: 2.1135  last_data_time: 1.8785   lr: 0.00099933  max_mem: 4121M\n",
      "\u001b[32m[09/06 23:33:03 d2.utils.events]: \u001b[0m eta: 18 days, 5:50:38  iter: 9939  total_loss: 0.1584  loss_cls: 0.04837  loss_box_reg: 0.1063  loss_rpn_cls: 4.371e-05  loss_rpn_loc: 0.001396    time: 2.5558  last_time: 2.9401  data_time: 1.9593  last_data_time: 1.8902   lr: 0.00099932  max_mem: 4121M\n",
      "\u001b[32m[09/06 23:34:02 d2.utils.events]: \u001b[0m eta: 18 days, 7:43:16  iter: 9959  total_loss: 0.1539  loss_cls: 0.03609  loss_box_reg: 0.1097  loss_rpn_cls: 5.835e-05  loss_rpn_loc: 0.001578    time: 2.5567  last_time: 2.6930  data_time: 1.9026  last_data_time: 1.6347   lr: 0.00099932  max_mem: 4121M\n",
      "\u001b[32m[09/06 23:35:01 d2.utils.events]: \u001b[0m eta: 18 days, 8:15:20  iter: 9979  total_loss: 0.1488  loss_cls: 0.03879  loss_box_reg: 0.1093  loss_rpn_cls: 7.393e-05  loss_rpn_loc: 0.001275    time: 2.5575  last_time: 3.0372  data_time: 1.8871  last_data_time: 2.0189   lr: 0.00099932  max_mem: 4121M\n",
      "\u001b[32m[09/06 23:36:04 d2.data.datasets.coco]: \u001b[0mLoaded 1199 images in COCO format from data/ssd_rcnn_face/annotations_val.json\n",
      "\u001b[32m[09/06 23:36:04 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(512, 512), max_size=512, sample_style='choice')]\n",
      "\u001b[32m[09/06 23:36:04 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[09/06 23:36:04 d2.data.common]: \u001b[0mSerializing 1199 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[09/06 23:36:04 d2.data.common]: \u001b[0mSerialized dataset takes 0.36 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[09/06 23:36:04 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n",
      "\u001b[32m[09/06 23:36:04 d2.evaluation.evaluator]: \u001b[0mStart inference on 1199 batches\n",
      "\u001b[32m[09/06 23:36:07 d2.evaluation.evaluator]: \u001b[0mInference done 11/1199. Dataloading: 0.0630 s/iter. Inference: 0.0725 s/iter. Eval: 0.0007 s/iter. Total: 0.1363 s/iter. ETA=0:02:41\n",
      "\u001b[32m[09/06 23:36:12 d2.evaluation.evaluator]: \u001b[0mInference done 40/1199. Dataloading: 0.0877 s/iter. Inference: 0.0782 s/iter. Eval: 0.0007 s/iter. Total: 0.1667 s/iter. ETA=0:03:13\n",
      "\u001b[32m[09/06 23:36:17 d2.evaluation.evaluator]: \u001b[0mInference done 71/1199. Dataloading: 0.0848 s/iter. Inference: 0.0788 s/iter. Eval: 0.0007 s/iter. Total: 0.1644 s/iter. ETA=0:03:05\n",
      "\u001b[32m[09/06 23:36:22 d2.evaluation.evaluator]: \u001b[0mInference done 91/1199. Dataloading: 0.1048 s/iter. Inference: 0.0795 s/iter. Eval: 0.0007 s/iter. Total: 0.1852 s/iter. ETA=0:03:25\n",
      "\u001b[32m[09/06 23:36:28 d2.evaluation.evaluator]: \u001b[0mInference done 119/1199. Dataloading: 0.1096 s/iter. Inference: 0.0792 s/iter. Eval: 0.0007 s/iter. Total: 0.1896 s/iter. ETA=0:03:24\n",
      "\u001b[32m[09/06 23:36:33 d2.evaluation.evaluator]: \u001b[0mInference done 150/1199. Dataloading: 0.1043 s/iter. Inference: 0.0794 s/iter. Eval: 0.0007 s/iter. Total: 0.1844 s/iter. ETA=0:03:13\n",
      "\u001b[32m[09/06 23:36:38 d2.evaluation.evaluator]: \u001b[0mInference done 179/1199. Dataloading: 0.1037 s/iter. Inference: 0.0794 s/iter. Eval: 0.0007 s/iter. Total: 0.1839 s/iter. ETA=0:03:07\n",
      "\u001b[32m[09/06 23:36:43 d2.evaluation.evaluator]: \u001b[0mInference done 207/1199. Dataloading: 0.1025 s/iter. Inference: 0.0800 s/iter. Eval: 0.0007 s/iter. Total: 0.1833 s/iter. ETA=0:03:01\n",
      "\u001b[32m[09/06 23:36:48 d2.evaluation.evaluator]: \u001b[0mInference done 231/1199. Dataloading: 0.1053 s/iter. Inference: 0.0800 s/iter. Eval: 0.0007 s/iter. Total: 0.1861 s/iter. ETA=0:03:00\n",
      "\u001b[32m[09/06 23:36:53 d2.evaluation.evaluator]: \u001b[0mInference done 256/1199. Dataloading: 0.1070 s/iter. Inference: 0.0801 s/iter. Eval: 0.0007 s/iter. Total: 0.1879 s/iter. ETA=0:02:57\n",
      "\u001b[32m[09/06 23:36:59 d2.evaluation.evaluator]: \u001b[0mInference done 279/1199. Dataloading: 0.1127 s/iter. Inference: 0.0805 s/iter. Eval: 0.0007 s/iter. Total: 0.1941 s/iter. ETA=0:02:58\n",
      "\u001b[32m[09/06 23:37:04 d2.evaluation.evaluator]: \u001b[0mInference done 299/1199. Dataloading: 0.1163 s/iter. Inference: 0.0809 s/iter. Eval: 0.0007 s/iter. Total: 0.1979 s/iter. ETA=0:02:58\n",
      "\u001b[32m[09/06 23:37:09 d2.evaluation.evaluator]: \u001b[0mInference done 325/1199. Dataloading: 0.1154 s/iter. Inference: 0.0816 s/iter. Eval: 0.0007 s/iter. Total: 0.1978 s/iter. ETA=0:02:52\n",
      "\u001b[32m[09/06 23:37:14 d2.evaluation.evaluator]: \u001b[0mInference done 354/1199. Dataloading: 0.1138 s/iter. Inference: 0.0815 s/iter. Eval: 0.0007 s/iter. Total: 0.1961 s/iter. ETA=0:02:45\n",
      "\u001b[32m[09/06 23:37:20 d2.evaluation.evaluator]: \u001b[0mInference done 380/1199. Dataloading: 0.1142 s/iter. Inference: 0.0815 s/iter. Eval: 0.0007 s/iter. Total: 0.1965 s/iter. ETA=0:02:40\n",
      "\u001b[32m[09/06 23:37:25 d2.evaluation.evaluator]: \u001b[0mInference done 408/1199. Dataloading: 0.1135 s/iter. Inference: 0.0814 s/iter. Eval: 0.0007 s/iter. Total: 0.1957 s/iter. ETA=0:02:34\n",
      "\u001b[32m[09/06 23:37:30 d2.evaluation.evaluator]: \u001b[0mInference done 437/1199. Dataloading: 0.1119 s/iter. Inference: 0.0818 s/iter. Eval: 0.0007 s/iter. Total: 0.1944 s/iter. ETA=0:02:28\n",
      "\u001b[32m[09/06 23:37:35 d2.evaluation.evaluator]: \u001b[0mInference done 467/1199. Dataloading: 0.1102 s/iter. Inference: 0.0819 s/iter. Eval: 0.0007 s/iter. Total: 0.1929 s/iter. ETA=0:02:21\n",
      "\u001b[32m[09/06 23:37:40 d2.evaluation.evaluator]: \u001b[0mInference done 496/1199. Dataloading: 0.1091 s/iter. Inference: 0.0820 s/iter. Eval: 0.0007 s/iter. Total: 0.1918 s/iter. ETA=0:02:14\n",
      "\u001b[32m[09/06 23:37:45 d2.evaluation.evaluator]: \u001b[0mInference done 524/1199. Dataloading: 0.1087 s/iter. Inference: 0.0820 s/iter. Eval: 0.0007 s/iter. Total: 0.1915 s/iter. ETA=0:02:09\n",
      "\u001b[32m[09/06 23:37:50 d2.evaluation.evaluator]: \u001b[0mInference done 553/1199. Dataloading: 0.1080 s/iter. Inference: 0.0819 s/iter. Eval: 0.0007 s/iter. Total: 0.1907 s/iter. ETA=0:02:03\n",
      "\u001b[32m[09/06 23:37:56 d2.evaluation.evaluator]: \u001b[0mInference done 584/1199. Dataloading: 0.1067 s/iter. Inference: 0.0819 s/iter. Eval: 0.0007 s/iter. Total: 0.1894 s/iter. ETA=0:01:56\n",
      "\u001b[32m[09/06 23:38:01 d2.evaluation.evaluator]: \u001b[0mInference done 616/1199. Dataloading: 0.1054 s/iter. Inference: 0.0818 s/iter. Eval: 0.0007 s/iter. Total: 0.1881 s/iter. ETA=0:01:49\n",
      "\u001b[32m[09/06 23:38:06 d2.evaluation.evaluator]: \u001b[0mInference done 641/1199. Dataloading: 0.1064 s/iter. Inference: 0.0818 s/iter. Eval: 0.0007 s/iter. Total: 0.1891 s/iter. ETA=0:01:45\n",
      "\u001b[32m[09/06 23:38:11 d2.evaluation.evaluator]: \u001b[0mInference done 666/1199. Dataloading: 0.1071 s/iter. Inference: 0.0816 s/iter. Eval: 0.0007 s/iter. Total: 0.1895 s/iter. ETA=0:01:41\n",
      "\u001b[32m[09/06 23:38:16 d2.evaluation.evaluator]: \u001b[0mInference done 692/1199. Dataloading: 0.1074 s/iter. Inference: 0.0815 s/iter. Eval: 0.0007 s/iter. Total: 0.1897 s/iter. ETA=0:01:36\n",
      "\u001b[32m[09/06 23:38:21 d2.evaluation.evaluator]: \u001b[0mInference done 721/1199. Dataloading: 0.1067 s/iter. Inference: 0.0816 s/iter. Eval: 0.0007 s/iter. Total: 0.1891 s/iter. ETA=0:01:30\n",
      "\u001b[32m[09/06 23:38:27 d2.evaluation.evaluator]: \u001b[0mInference done 747/1199. Dataloading: 0.1080 s/iter. Inference: 0.0817 s/iter. Eval: 0.0007 s/iter. Total: 0.1905 s/iter. ETA=0:01:26\n",
      "\u001b[32m[09/06 23:38:32 d2.evaluation.evaluator]: \u001b[0mInference done 768/1199. Dataloading: 0.1094 s/iter. Inference: 0.0818 s/iter. Eval: 0.0007 s/iter. Total: 0.1920 s/iter. ETA=0:01:22\n",
      "\u001b[32m[09/06 23:38:38 d2.evaluation.evaluator]: \u001b[0mInference done 799/1199. Dataloading: 0.1082 s/iter. Inference: 0.0819 s/iter. Eval: 0.0007 s/iter. Total: 0.1909 s/iter. ETA=0:01:16\n",
      "\u001b[32m[09/06 23:38:43 d2.evaluation.evaluator]: \u001b[0mInference done 829/1199. Dataloading: 0.1076 s/iter. Inference: 0.0818 s/iter. Eval: 0.0007 s/iter. Total: 0.1902 s/iter. ETA=0:01:10\n",
      "\u001b[32m[09/06 23:38:48 d2.evaluation.evaluator]: \u001b[0mInference done 860/1199. Dataloading: 0.1066 s/iter. Inference: 0.0818 s/iter. Eval: 0.0007 s/iter. Total: 0.1893 s/iter. ETA=0:01:04\n",
      "\u001b[32m[09/06 23:38:53 d2.evaluation.evaluator]: \u001b[0mInference done 889/1199. Dataloading: 0.1062 s/iter. Inference: 0.0819 s/iter. Eval: 0.0007 s/iter. Total: 0.1889 s/iter. ETA=0:00:58\n",
      "\u001b[32m[09/06 23:38:58 d2.evaluation.evaluator]: \u001b[0mInference done 914/1199. Dataloading: 0.1066 s/iter. Inference: 0.0818 s/iter. Eval: 0.0007 s/iter. Total: 0.1892 s/iter. ETA=0:00:53\n",
      "\u001b[32m[09/06 23:39:03 d2.evaluation.evaluator]: \u001b[0mInference done 946/1199. Dataloading: 0.1054 s/iter. Inference: 0.0819 s/iter. Eval: 0.0007 s/iter. Total: 0.1881 s/iter. ETA=0:00:47\n",
      "\u001b[32m[09/06 23:39:08 d2.evaluation.evaluator]: \u001b[0mInference done 971/1199. Dataloading: 0.1060 s/iter. Inference: 0.0820 s/iter. Eval: 0.0007 s/iter. Total: 0.1888 s/iter. ETA=0:00:43\n",
      "\u001b[32m[09/06 23:39:13 d2.evaluation.evaluator]: \u001b[0mInference done 999/1199. Dataloading: 0.1057 s/iter. Inference: 0.0820 s/iter. Eval: 0.0007 s/iter. Total: 0.1885 s/iter. ETA=0:00:37\n",
      "\u001b[32m[09/06 23:39:18 d2.evaluation.evaluator]: \u001b[0mInference done 1023/1199. Dataloading: 0.1062 s/iter. Inference: 0.0821 s/iter. Eval: 0.0007 s/iter. Total: 0.1891 s/iter. ETA=0:00:33\n",
      "\u001b[32m[09/06 23:39:24 d2.evaluation.evaluator]: \u001b[0mInference done 1050/1199. Dataloading: 0.1061 s/iter. Inference: 0.0822 s/iter. Eval: 0.0007 s/iter. Total: 0.1891 s/iter. ETA=0:00:28\n",
      "\u001b[32m[09/06 23:39:29 d2.evaluation.evaluator]: \u001b[0mInference done 1076/1199. Dataloading: 0.1062 s/iter. Inference: 0.0822 s/iter. Eval: 0.0007 s/iter. Total: 0.1892 s/iter. ETA=0:00:23\n",
      "\u001b[32m[09/06 23:39:34 d2.evaluation.evaluator]: \u001b[0mInference done 1105/1199. Dataloading: 0.1059 s/iter. Inference: 0.0822 s/iter. Eval: 0.0007 s/iter. Total: 0.1889 s/iter. ETA=0:00:17\n",
      "\u001b[32m[09/06 23:39:39 d2.evaluation.evaluator]: \u001b[0mInference done 1132/1199. Dataloading: 0.1061 s/iter. Inference: 0.0820 s/iter. Eval: 0.0007 s/iter. Total: 0.1889 s/iter. ETA=0:00:12\n",
      "\u001b[32m[09/06 23:39:44 d2.evaluation.evaluator]: \u001b[0mInference done 1162/1199. Dataloading: 0.1059 s/iter. Inference: 0.0819 s/iter. Eval: 0.0007 s/iter. Total: 0.1886 s/iter. ETA=0:00:06\n",
      "\u001b[32m[09/06 23:39:49 d2.evaluation.evaluator]: \u001b[0mInference done 1196/1199. Dataloading: 0.1052 s/iter. Inference: 0.0817 s/iter. Eval: 0.0007 s/iter. Total: 0.1877 s/iter. ETA=0:00:00\n",
      "\u001b[32m[09/06 23:39:50 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:03:44.170253 (0.187747 s / iter per device, on 1 devices)\n",
      "\u001b[32m[09/06 23:39:50 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:01:37 (0.081709 s / iter per device, on 1 devices)\n",
      "\u001b[32m[09/06 23:39:50 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[09/06 23:39:50 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.02s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[09/06 23:39:50 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[09/06 23:39:54 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 3.35 seconds.\n",
      "\u001b[32m[09/06 23:39:54 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[09/06 23:39:54 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.02 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.692\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.817\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.809\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.692\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.812\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.813\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.813\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.813\n",
      "\u001b[32m[09/06 23:39:54 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
      "| 69.200 | 81.672 | 80.905 |  nan  |  nan  | 69.200 |\n",
      "\u001b[32m[09/06 23:39:54 d2.evaluation.coco_evaluation]: \u001b[0mSome metrics cannot be computed and is shown as NaN.\n",
      "\u001b[32m[09/06 23:39:54 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category   | AP     | category   | AP     | category   | AP     |\n",
      "|:-----------|:-------|:-----------|:-------|:-----------|:-------|\n",
      "| angry      | 66.401 | sad        | 65.666 | surprised  | 64.560 |\n",
      "| happy      | 80.172 |            |        |            |        |\n",
      "\u001b[32m[09/06 23:39:54 d2.engine.defaults]: \u001b[0mEvaluation results for face_data_set_valid in csv format:\n",
      "\u001b[32m[09/06 23:39:54 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[09/06 23:39:54 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[09/06 23:39:54 d2.evaluation.testing]: \u001b[0mcopypaste: 69.2000,81.6723,80.9054,nan,nan,69.2000\n",
      "\u001b[32m[09/06 23:39:54 d2.utils.events]: \u001b[0m eta: 18 days, 8:39:37  iter: 9999  total_loss: 0.148  loss_cls: 0.03999  loss_box_reg: 0.1033  loss_rpn_cls: 7.122e-05  loss_rpn_loc: 0.001444    time: 2.5585  last_time: 3.0453  data_time: 1.9781  last_data_time: 1.9577   lr: 0.00099932  max_mem: 4121M\n",
      "\u001b[32m[09/06 23:40:48 d2.utils.events]: \u001b[0m eta: 18 days, 8:26:58  iter: 10019  total_loss: 0.171  loss_cls: 0.04892  loss_box_reg: 0.1123  loss_rpn_cls: 5.733e-05  loss_rpn_loc: 0.001379    time: 2.5589  last_time: 2.6386  data_time: 1.7385  last_data_time: 1.6962   lr: 0.00099931  max_mem: 4121M\n",
      "\u001b[32m[09/06 23:41:39 d2.utils.events]: \u001b[0m eta: 18 days, 7:44:18  iter: 10039  total_loss: 0.1534  loss_cls: 0.03583  loss_box_reg: 0.1079  loss_rpn_cls: 7.344e-05  loss_rpn_loc: 0.001551    time: 2.5589  last_time: 3.0082  data_time: 1.5828  last_data_time: 1.9590   lr: 0.00099931  max_mem: 4121M\n",
      "\u001b[32m[09/06 23:42:30 d2.utils.events]: \u001b[0m eta: 18 days, 6:33:27  iter: 10059  total_loss: 0.1483  loss_cls: 0.03571  loss_box_reg: 0.109  loss_rpn_cls: 6.699e-05  loss_rpn_loc: 0.001383    time: 2.5589  last_time: 2.1600  data_time: 1.6150  last_data_time: 1.2418   lr: 0.00099931  max_mem: 4121M\n",
      "\u001b[32m[09/06 23:43:17 d2.utils.events]: \u001b[0m eta: 18 days, 3:37:46  iter: 10079  total_loss: 0.1474  loss_cls: 0.03207  loss_box_reg: 0.1085  loss_rpn_cls: 6.732e-05  loss_rpn_loc: 0.001452    time: 2.5584  last_time: 2.1971  data_time: 1.4261  last_data_time: 1.3334   lr: 0.0009993  max_mem: 4121M\n",
      "\u001b[32m[09/06 23:44:07 d2.utils.events]: \u001b[0m eta: 18 days, 2:04:36  iter: 10099  total_loss: 0.1454  loss_cls: 0.03159  loss_box_reg: 0.1086  loss_rpn_cls: 0.0001394  loss_rpn_loc: 0.001532    time: 2.5582  last_time: 2.2581  data_time: 1.5571  last_data_time: 1.3549   lr: 0.0009993  max_mem: 4121M\n",
      "\u001b[32m[09/06 23:44:57 d2.utils.events]: \u001b[0m eta: 18 days, 1:07:45  iter: 10119  total_loss: 0.1484  loss_cls: 0.03989  loss_box_reg: 0.1088  loss_rpn_cls: 6.283e-05  loss_rpn_loc: 0.001517    time: 2.5581  last_time: 2.9939  data_time: 1.5804  last_data_time: 1.9006   lr: 0.0009993  max_mem: 4121M\n",
      "\u001b[32m[09/06 23:45:46 d2.utils.events]: \u001b[0m eta: 17 days, 23:39:45  iter: 10139  total_loss: 0.163  loss_cls: 0.047  loss_box_reg: 0.1077  loss_rpn_cls: 5.847e-05  loss_rpn_loc: 0.001451    time: 2.5579  last_time: 2.3807  data_time: 1.5291  last_data_time: 1.4647   lr: 0.0009993  max_mem: 4121M\n",
      "\u001b[32m[09/06 23:46:37 d2.utils.events]: \u001b[0m eta: 17 days, 21:56:34  iter: 10159  total_loss: 0.1536  loss_cls: 0.03814  loss_box_reg: 0.1143  loss_rpn_cls: 5.692e-05  loss_rpn_loc: 0.001475    time: 2.5579  last_time: 2.2455  data_time: 1.6097  last_data_time: 1.3183   lr: 0.00099929  max_mem: 4121M\n",
      "\u001b[32m[09/06 23:47:27 d2.utils.events]: \u001b[0m eta: 17 days, 19:45:47  iter: 10179  total_loss: 0.1579  loss_cls: 0.04256  loss_box_reg: 0.1137  loss_rpn_cls: 5.311e-05  loss_rpn_loc: 0.001391    time: 2.5578  last_time: 2.3020  data_time: 1.5752  last_data_time: 1.4182   lr: 0.00099929  max_mem: 4121M\n",
      "\u001b[32m[09/06 23:48:20 d2.utils.events]: \u001b[0m eta: 17 days, 19:11:41  iter: 10199  total_loss: 0.1711  loss_cls: 0.04379  loss_box_reg: 0.117  loss_rpn_cls: 4.486e-05  loss_rpn_loc: 0.001681    time: 2.5579  last_time: 2.8331  data_time: 1.6502  last_data_time: 1.7546   lr: 0.00099929  max_mem: 4121M\n",
      "\u001b[32m[09/06 23:49:11 d2.utils.events]: \u001b[0m eta: 17 days, 17:50:26  iter: 10219  total_loss: 0.1488  loss_cls: 0.04073  loss_box_reg: 0.1075  loss_rpn_cls: 7.972e-05  loss_rpn_loc: 0.001438    time: 2.5579  last_time: 2.6757  data_time: 1.5809  last_data_time: 1.6523   lr: 0.00099928  max_mem: 4121M\n",
      "\u001b[32m[09/06 23:49:59 d2.utils.events]: \u001b[0m eta: 17 days, 16:49:23  iter: 10239  total_loss: 0.1523  loss_cls: 0.04842  loss_box_reg: 0.09686  loss_rpn_cls: 4.287e-05  loss_rpn_loc: 0.001305    time: 2.5575  last_time: 2.5200  data_time: 1.4839  last_data_time: 1.6471   lr: 0.00099928  max_mem: 4121M\n",
      "\u001b[32m[09/06 23:50:44 d2.utils.events]: \u001b[0m eta: 17 days, 14:02:07  iter: 10259  total_loss: 0.1516  loss_cls: 0.0409  loss_box_reg: 0.1055  loss_rpn_cls: 6.119e-05  loss_rpn_loc: 0.001372    time: 2.5570  last_time: 2.2677  data_time: 1.3887  last_data_time: 1.3107   lr: 0.00099928  max_mem: 4121M\n",
      "\u001b[32m[09/06 23:51:34 d2.utils.events]: \u001b[0m eta: 17 days, 12:21:14  iter: 10279  total_loss: 0.156  loss_cls: 0.03877  loss_box_reg: 0.117  loss_rpn_cls: 6.729e-05  loss_rpn_loc: 0.001512    time: 2.5568  last_time: 2.1571  data_time: 1.5569  last_data_time: 1.3125   lr: 0.00099928  max_mem: 4121M\n",
      "\u001b[32m[09/06 23:52:21 d2.utils.events]: \u001b[0m eta: 17 days, 11:06:23  iter: 10299  total_loss: 0.1498  loss_cls: 0.03783  loss_box_reg: 0.1102  loss_rpn_cls: 4.548e-05  loss_rpn_loc: 0.001493    time: 2.5563  last_time: 2.2042  data_time: 1.4609  last_data_time: 1.3191   lr: 0.00099927  max_mem: 4121M\n",
      "\u001b[32m[09/06 23:53:09 d2.utils.events]: \u001b[0m eta: 17 days, 9:41:33  iter: 10319  total_loss: 0.1777  loss_cls: 0.06427  loss_box_reg: 0.1058  loss_rpn_cls: 6.533e-05  loss_rpn_loc: 0.001421    time: 2.5561  last_time: 2.2706  data_time: 1.5120  last_data_time: 1.4114   lr: 0.00099927  max_mem: 4121M\n",
      "\u001b[32m[09/06 23:54:00 d2.utils.events]: \u001b[0m eta: 17 days, 8:18:25  iter: 10339  total_loss: 0.1611  loss_cls: 0.04593  loss_box_reg: 0.1111  loss_rpn_cls: 5.68e-05  loss_rpn_loc: 0.001346    time: 2.5560  last_time: 2.6529  data_time: 1.6092  last_data_time: 1.6990   lr: 0.00099927  max_mem: 4121M\n",
      "\u001b[32m[09/06 23:54:47 d2.utils.events]: \u001b[0m eta: 17 days, 5:47:09  iter: 10359  total_loss: 0.1751  loss_cls: 0.0507  loss_box_reg: 0.112  loss_rpn_cls: 4.584e-05  loss_rpn_loc: 0.00134    time: 2.5555  last_time: 2.2183  data_time: 1.4634  last_data_time: 1.3285   lr: 0.00099926  max_mem: 4121M\n",
      "\u001b[32m[09/06 23:55:33 d2.utils.events]: \u001b[0m eta: 17 days, 2:59:17  iter: 10379  total_loss: 0.1459  loss_cls: 0.04103  loss_box_reg: 0.1072  loss_rpn_cls: 6.858e-05  loss_rpn_loc: 0.001372    time: 2.5550  last_time: 2.6127  data_time: 1.4229  last_data_time: 1.6656   lr: 0.00099926  max_mem: 4121M\n",
      "\u001b[32m[09/06 23:56:21 d2.utils.events]: \u001b[0m eta: 17 days, 1:01:50  iter: 10399  total_loss: 0.1466  loss_cls: 0.03502  loss_box_reg: 0.107  loss_rpn_cls: 5.793e-05  loss_rpn_loc: 0.001409    time: 2.5547  last_time: 2.1732  data_time: 1.4934  last_data_time: 1.2664   lr: 0.00099926  max_mem: 4121M\n",
      "\u001b[32m[09/06 23:57:09 d2.utils.events]: \u001b[0m eta: 17 days, 0:15:26  iter: 10419  total_loss: 0.1471  loss_cls: 0.03173  loss_box_reg: 0.1146  loss_rpn_cls: 7.052e-05  loss_rpn_loc: 0.001553    time: 2.5544  last_time: 2.1339  data_time: 1.5073  last_data_time: 1.2453   lr: 0.00099926  max_mem: 4121M\n",
      "\u001b[32m[09/06 23:57:58 d2.utils.events]: \u001b[0m eta: 16 days, 22:53:43  iter: 10439  total_loss: 0.1421  loss_cls: 0.03648  loss_box_reg: 0.1034  loss_rpn_cls: 5.313e-05  loss_rpn_loc: 0.001396    time: 2.5541  last_time: 3.1877  data_time: 1.5296  last_data_time: 2.1504   lr: 0.00099925  max_mem: 4121M\n",
      "\u001b[32m[09/06 23:58:45 d2.utils.events]: \u001b[0m eta: 16 days, 21:53:50  iter: 10459  total_loss: 0.154  loss_cls: 0.0393  loss_box_reg: 0.1077  loss_rpn_cls: 5.711e-05  loss_rpn_loc: 0.001414    time: 2.5537  last_time: 2.2359  data_time: 1.4581  last_data_time: 1.2947   lr: 0.00099925  max_mem: 4121M\n",
      "\u001b[32m[09/06 23:59:32 d2.utils.events]: \u001b[0m eta: 16 days, 20:57:00  iter: 10479  total_loss: 0.1449  loss_cls: 0.03266  loss_box_reg: 0.1076  loss_rpn_cls: 7.615e-05  loss_rpn_loc: 0.001484    time: 2.5532  last_time: 2.1446  data_time: 1.4139  last_data_time: 1.3086   lr: 0.00099925  max_mem: 4121M\n",
      "\u001b[32m[09/07 00:00:22 d2.utils.events]: \u001b[0m eta: 16 days, 19:19:57  iter: 10499  total_loss: 0.1414  loss_cls: 0.03069  loss_box_reg: 0.1068  loss_rpn_cls: 8.669e-05  loss_rpn_loc: 0.001353    time: 2.5529  last_time: 2.3542  data_time: 1.4876  last_data_time: 1.3994   lr: 0.00099924  max_mem: 4121M\n",
      "\u001b[32m[09/07 00:01:17 d2.utils.events]: \u001b[0m eta: 16 days, 19:25:21  iter: 10519  total_loss: 0.1463  loss_cls: 0.03537  loss_box_reg: 0.1076  loss_rpn_cls: 4.985e-05  loss_rpn_loc: 0.00136    time: 2.5533  last_time: 2.6132  data_time: 1.7385  last_data_time: 1.6658   lr: 0.00099924  max_mem: 4121M\n",
      "\u001b[32m[09/07 00:02:14 d2.utils.events]: \u001b[0m eta: 16 days, 19:24:32  iter: 10539  total_loss: 0.1412  loss_cls: 0.03503  loss_box_reg: 0.1077  loss_rpn_cls: 6.721e-05  loss_rpn_loc: 0.001372    time: 2.5540  last_time: 3.5090  data_time: 1.8303  last_data_time: 2.3662   lr: 0.00099924  max_mem: 4121M\n",
      "\u001b[32m[09/07 00:03:09 d2.utils.events]: \u001b[0m eta: 16 days, 19:09:08  iter: 10559  total_loss: 0.1451  loss_cls: 0.03742  loss_box_reg: 0.1092  loss_rpn_cls: 6.685e-05  loss_rpn_loc: 0.001411    time: 2.5543  last_time: 2.4822  data_time: 1.7377  last_data_time: 1.4554   lr: 0.00099924  max_mem: 4121M\n",
      "\u001b[32m[09/07 00:04:05 d2.utils.events]: \u001b[0m eta: 16 days, 19:22:53  iter: 10579  total_loss: 0.146  loss_cls: 0.02998  loss_box_reg: 0.1089  loss_rpn_cls: 5.273e-05  loss_rpn_loc: 0.001433    time: 2.5549  last_time: 2.4736  data_time: 1.7775  last_data_time: 1.4680   lr: 0.00099923  max_mem: 4121M\n",
      "\u001b[32m[09/07 00:05:03 d2.utils.events]: \u001b[0m eta: 16 days, 19:22:04  iter: 10599  total_loss: 0.1475  loss_cls: 0.0344  loss_box_reg: 0.1016  loss_rpn_cls: 4.01e-05  loss_rpn_loc: 0.001304    time: 2.5556  last_time: 2.7821  data_time: 1.8225  last_data_time: 1.8034   lr: 0.00099923  max_mem: 4121M\n",
      "\u001b[32m[09/07 00:05:59 d2.utils.events]: \u001b[0m eta: 16 days, 19:21:15  iter: 10619  total_loss: 0.1535  loss_cls: 0.03387  loss_box_reg: 0.1156  loss_rpn_cls: 5.291e-05  loss_rpn_loc: 0.001641    time: 2.5561  last_time: 2.4998  data_time: 1.7805  last_data_time: 1.4213   lr: 0.00099923  max_mem: 4121M\n",
      "\u001b[32m[09/07 00:06:48 d2.utils.events]: \u001b[0m eta: 16 days, 18:39:17  iter: 10639  total_loss: 0.1449  loss_cls: 0.03907  loss_box_reg: 0.1033  loss_rpn_cls: 6.571e-05  loss_rpn_loc: 0.001406    time: 2.5559  last_time: 1.7665  data_time: 1.5688  last_data_time: 0.9331   lr: 0.00099922  max_mem: 4121M\n",
      "\u001b[32m[09/07 00:07:35 d2.utils.events]: \u001b[0m eta: 16 days, 17:16:54  iter: 10659  total_loss: 0.1498  loss_cls: 0.03251  loss_box_reg: 0.11  loss_rpn_cls: 5.687e-05  loss_rpn_loc: 0.001426    time: 2.5555  last_time: 2.1175  data_time: 1.4513  last_data_time: 1.2822   lr: 0.00099922  max_mem: 4121M\n",
      "\u001b[32m[09/07 00:08:24 d2.utils.events]: \u001b[0m eta: 16 days, 17:02:26  iter: 10679  total_loss: 0.1509  loss_cls: 0.03415  loss_box_reg: 0.1016  loss_rpn_cls: 7.311e-05  loss_rpn_loc: 0.0014    time: 2.5552  last_time: 2.6036  data_time: 1.5305  last_data_time: 1.6812   lr: 0.00099922  max_mem: 4121M\n",
      "\u001b[32m[09/07 00:09:12 d2.utils.events]: \u001b[0m eta: 16 days, 17:01:37  iter: 10699  total_loss: 0.1609  loss_cls: 0.04596  loss_box_reg: 0.1062  loss_rpn_cls: 4.826e-05  loss_rpn_loc: 0.001456    time: 2.5549  last_time: 2.4869  data_time: 1.5113  last_data_time: 1.5769   lr: 0.00099922  max_mem: 4121M\n",
      "\u001b[32m[09/07 00:10:00 d2.utils.events]: \u001b[0m eta: 16 days, 16:46:49  iter: 10719  total_loss: 0.1396  loss_cls: 0.02684  loss_box_reg: 0.1037  loss_rpn_cls: 5.775e-05  loss_rpn_loc: 0.001384    time: 2.5546  last_time: 1.9925  data_time: 1.4809  last_data_time: 1.1219   lr: 0.00099921  max_mem: 4121M\n",
      "\u001b[32m[09/07 00:10:48 d2.utils.events]: \u001b[0m eta: 16 days, 16:46:00  iter: 10739  total_loss: 0.16  loss_cls: 0.04777  loss_box_reg: 0.103  loss_rpn_cls: 4.769e-05  loss_rpn_loc: 0.001432    time: 2.5543  last_time: 2.3328  data_time: 1.5106  last_data_time: 1.3383   lr: 0.00099921  max_mem: 4121M\n",
      "\u001b[32m[09/07 00:11:35 d2.utils.events]: \u001b[0m eta: 16 days, 16:42:49  iter: 10759  total_loss: 0.1441  loss_cls: 0.0416  loss_box_reg: 0.1046  loss_rpn_cls: 7.44e-05  loss_rpn_loc: 0.001384    time: 2.5539  last_time: 2.2738  data_time: 1.4522  last_data_time: 1.4015   lr: 0.00099921  max_mem: 4121M\n",
      "\u001b[32m[09/07 00:12:25 d2.utils.events]: \u001b[0m eta: 16 days, 16:50:22  iter: 10779  total_loss: 0.1474  loss_cls: 0.03862  loss_box_reg: 0.11  loss_rpn_cls: 9.487e-05  loss_rpn_loc: 0.001431    time: 2.5537  last_time: 2.2696  data_time: 1.5219  last_data_time: 1.3924   lr: 0.0009992  max_mem: 4121M\n",
      "\u001b[32m[09/07 00:13:11 d2.utils.events]: \u001b[0m eta: 16 days, 16:35:48  iter: 10799  total_loss: 0.1438  loss_cls: 0.03359  loss_box_reg: 0.1091  loss_rpn_cls: 5.52e-05  loss_rpn_loc: 0.001486    time: 2.5532  last_time: 2.4961  data_time: 1.3907  last_data_time: 1.6044   lr: 0.0009992  max_mem: 4121M\n",
      "\u001b[32m[09/07 00:13:58 d2.utils.events]: \u001b[0m eta: 16 days, 16:18:30  iter: 10819  total_loss: 0.1471  loss_cls: 0.03673  loss_box_reg: 0.1094  loss_rpn_cls: 5.749e-05  loss_rpn_loc: 0.001399    time: 2.5528  last_time: 2.2790  data_time: 1.4195  last_data_time: 1.4399   lr: 0.0009992  max_mem: 4121M\n",
      "\u001b[32m[09/07 00:14:45 d2.utils.events]: \u001b[0m eta: 16 days, 15:59:11  iter: 10839  total_loss: 0.1514  loss_cls: 0.03457  loss_box_reg: 0.1065  loss_rpn_cls: 6.438e-05  loss_rpn_loc: 0.001467    time: 2.5524  last_time: 3.4736  data_time: 1.4500  last_data_time: 2.4233   lr: 0.0009992  max_mem: 4121M\n",
      "\u001b[32m[09/07 00:15:34 d2.utils.events]: \u001b[0m eta: 16 days, 15:49:29  iter: 10859  total_loss: 0.1408  loss_cls: 0.02643  loss_box_reg: 0.1125  loss_rpn_cls: 5.747e-05  loss_rpn_loc: 0.001338    time: 2.5522  last_time: 2.5818  data_time: 1.5343  last_data_time: 1.7307   lr: 0.00099919  max_mem: 4121M\n",
      "\u001b[32m[09/07 00:16:24 d2.utils.events]: \u001b[0m eta: 16 days, 16:16:03  iter: 10879  total_loss: 0.1505  loss_cls: 0.03876  loss_box_reg: 0.1063  loss_rpn_cls: 7.575e-05  loss_rpn_loc: 0.001282    time: 2.5520  last_time: 2.4656  data_time: 1.5150  last_data_time: 1.5423   lr: 0.00099919  max_mem: 4121M\n",
      "\u001b[32m[09/07 00:17:14 d2.utils.events]: \u001b[0m eta: 16 days, 16:15:14  iter: 10899  total_loss: 0.1528  loss_cls: 0.04187  loss_box_reg: 0.106  loss_rpn_cls: 4.274e-05  loss_rpn_loc: 0.001432    time: 2.5520  last_time: 2.0969  data_time: 1.5688  last_data_time: 1.1813   lr: 0.00099919  max_mem: 4121M\n",
      "\u001b[32m[09/07 00:18:03 d2.utils.events]: \u001b[0m eta: 16 days, 15:00:24  iter: 10919  total_loss: 0.1478  loss_cls: 0.03337  loss_box_reg: 0.1041  loss_rpn_cls: 5.289e-05  loss_rpn_loc: 0.001507    time: 2.5518  last_time: 2.2767  data_time: 1.5192  last_data_time: 1.2674   lr: 0.00099918  max_mem: 4121M\n",
      "\u001b[32m[09/07 00:18:57 d2.utils.events]: \u001b[0m eta: 16 days, 14:19:01  iter: 10939  total_loss: 0.1395  loss_cls: 0.032  loss_box_reg: 0.0983  loss_rpn_cls: 4.096e-05  loss_rpn_loc: 0.001436    time: 2.5520  last_time: 2.6859  data_time: 1.7134  last_data_time: 1.7953   lr: 0.00099918  max_mem: 4121M\n",
      "\u001b[32m[09/07 00:19:49 d2.utils.events]: \u001b[0m eta: 16 days, 13:04:46  iter: 10959  total_loss: 0.1394  loss_cls: 0.03412  loss_box_reg: 0.1054  loss_rpn_cls: 4.379e-05  loss_rpn_loc: 0.001343    time: 2.5521  last_time: 2.3991  data_time: 1.6413  last_data_time: 1.4397   lr: 0.00099918  max_mem: 4121M\n",
      "\u001b[32m[09/07 00:20:42 d2.utils.events]: \u001b[0m eta: 16 days, 12:44:23  iter: 10979  total_loss: 0.1604  loss_cls: 0.03651  loss_box_reg: 0.1082  loss_rpn_cls: 4.75e-05  loss_rpn_loc: 0.001439    time: 2.5523  last_time: 2.9560  data_time: 1.6199  last_data_time: 1.8593   lr: 0.00099917  max_mem: 4121M\n",
      "\u001b[32m[09/07 00:21:40 d2.data.datasets.coco]: \u001b[0mLoaded 1199 images in COCO format from data/ssd_rcnn_face/annotations_val.json\n",
      "\u001b[32m[09/07 00:21:40 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(512, 512), max_size=512, sample_style='choice')]\n",
      "\u001b[32m[09/07 00:21:40 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[09/07 00:21:40 d2.data.common]: \u001b[0mSerializing 1199 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[09/07 00:21:40 d2.data.common]: \u001b[0mSerialized dataset takes 0.36 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[09/07 00:21:40 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n",
      "\u001b[32m[09/07 00:21:40 d2.evaluation.evaluator]: \u001b[0mStart inference on 1199 batches\n",
      "\u001b[32m[09/07 00:21:43 d2.evaluation.evaluator]: \u001b[0mInference done 11/1199. Dataloading: 0.0687 s/iter. Inference: 0.0880 s/iter. Eval: 0.0005 s/iter. Total: 0.1572 s/iter. ETA=0:03:06\n",
      "\u001b[32m[09/07 00:21:48 d2.evaluation.evaluator]: \u001b[0mInference done 40/1199. Dataloading: 0.0903 s/iter. Inference: 0.0805 s/iter. Eval: 0.0006 s/iter. Total: 0.1716 s/iter. ETA=0:03:18\n",
      "\u001b[32m[09/07 00:21:53 d2.evaluation.evaluator]: \u001b[0mInference done 75/1199. Dataloading: 0.0825 s/iter. Inference: 0.0767 s/iter. Eval: 0.0006 s/iter. Total: 0.1600 s/iter. ETA=0:02:59\n",
      "\u001b[32m[09/07 00:21:58 d2.evaluation.evaluator]: \u001b[0mInference done 100/1199. Dataloading: 0.0929 s/iter. Inference: 0.0774 s/iter. Eval: 0.0007 s/iter. Total: 0.1710 s/iter. ETA=0:03:07\n",
      "\u001b[32m[09/07 00:22:03 d2.evaluation.evaluator]: \u001b[0mInference done 124/1199. Dataloading: 0.1004 s/iter. Inference: 0.0775 s/iter. Eval: 0.0006 s/iter. Total: 0.1786 s/iter. ETA=0:03:11\n",
      "\u001b[32m[09/07 00:22:08 d2.evaluation.evaluator]: \u001b[0mInference done 152/1199. Dataloading: 0.1000 s/iter. Inference: 0.0783 s/iter. Eval: 0.0006 s/iter. Total: 0.1791 s/iter. ETA=0:03:07\n",
      "\u001b[32m[09/07 00:22:13 d2.evaluation.evaluator]: \u001b[0mInference done 179/1199. Dataloading: 0.1013 s/iter. Inference: 0.0796 s/iter. Eval: 0.0007 s/iter. Total: 0.1817 s/iter. ETA=0:03:05\n",
      "\u001b[32m[09/07 00:22:19 d2.evaluation.evaluator]: \u001b[0mInference done 209/1199. Dataloading: 0.1003 s/iter. Inference: 0.0793 s/iter. Eval: 0.0007 s/iter. Total: 0.1803 s/iter. ETA=0:02:58\n",
      "\u001b[32m[09/07 00:22:24 d2.evaluation.evaluator]: \u001b[0mInference done 233/1199. Dataloading: 0.1032 s/iter. Inference: 0.0797 s/iter. Eval: 0.0007 s/iter. Total: 0.1837 s/iter. ETA=0:02:57\n",
      "\u001b[32m[09/07 00:22:29 d2.evaluation.evaluator]: \u001b[0mInference done 258/1199. Dataloading: 0.1055 s/iter. Inference: 0.0796 s/iter. Eval: 0.0007 s/iter. Total: 0.1858 s/iter. ETA=0:02:54\n",
      "\u001b[32m[09/07 00:22:34 d2.evaluation.evaluator]: \u001b[0mInference done 279/1199. Dataloading: 0.1110 s/iter. Inference: 0.0795 s/iter. Eval: 0.0006 s/iter. Total: 0.1913 s/iter. ETA=0:02:55\n",
      "\u001b[32m[09/07 00:22:39 d2.evaluation.evaluator]: \u001b[0mInference done 298/1199. Dataloading: 0.1154 s/iter. Inference: 0.0800 s/iter. Eval: 0.0007 s/iter. Total: 0.1961 s/iter. ETA=0:02:56\n",
      "\u001b[32m[09/07 00:22:44 d2.evaluation.evaluator]: \u001b[0mInference done 326/1199. Dataloading: 0.1137 s/iter. Inference: 0.0803 s/iter. Eval: 0.0007 s/iter. Total: 0.1948 s/iter. ETA=0:02:50\n",
      "\u001b[32m[09/07 00:22:50 d2.evaluation.evaluator]: \u001b[0mInference done 356/1199. Dataloading: 0.1124 s/iter. Inference: 0.0798 s/iter. Eval: 0.0007 s/iter. Total: 0.1930 s/iter. ETA=0:02:42\n",
      "\u001b[32m[09/07 00:22:55 d2.evaluation.evaluator]: \u001b[0mInference done 382/1199. Dataloading: 0.1129 s/iter. Inference: 0.0796 s/iter. Eval: 0.0007 s/iter. Total: 0.1933 s/iter. ETA=0:02:37\n",
      "\u001b[32m[09/07 00:23:00 d2.evaluation.evaluator]: \u001b[0mInference done 409/1199. Dataloading: 0.1126 s/iter. Inference: 0.0794 s/iter. Eval: 0.0007 s/iter. Total: 0.1928 s/iter. ETA=0:02:32\n",
      "\u001b[32m[09/07 00:23:05 d2.evaluation.evaluator]: \u001b[0mInference done 440/1199. Dataloading: 0.1106 s/iter. Inference: 0.0792 s/iter. Eval: 0.0007 s/iter. Total: 0.1907 s/iter. ETA=0:02:24\n",
      "\u001b[32m[09/07 00:23:10 d2.evaluation.evaluator]: \u001b[0mInference done 471/1199. Dataloading: 0.1098 s/iter. Inference: 0.0789 s/iter. Eval: 0.0007 s/iter. Total: 0.1896 s/iter. ETA=0:02:17\n",
      "\u001b[32m[09/07 00:23:15 d2.evaluation.evaluator]: \u001b[0mInference done 502/1199. Dataloading: 0.1084 s/iter. Inference: 0.0786 s/iter. Eval: 0.0007 s/iter. Total: 0.1878 s/iter. ETA=0:02:10\n",
      "\u001b[32m[09/07 00:23:20 d2.evaluation.evaluator]: \u001b[0mInference done 532/1199. Dataloading: 0.1075 s/iter. Inference: 0.0785 s/iter. Eval: 0.0006 s/iter. Total: 0.1868 s/iter. ETA=0:02:04\n",
      "\u001b[32m[09/07 00:23:25 d2.evaluation.evaluator]: \u001b[0mInference done 558/1199. Dataloading: 0.1077 s/iter. Inference: 0.0789 s/iter. Eval: 0.0006 s/iter. Total: 0.1874 s/iter. ETA=0:02:00\n",
      "\u001b[32m[09/07 00:23:31 d2.evaluation.evaluator]: \u001b[0mInference done 588/1199. Dataloading: 0.1068 s/iter. Inference: 0.0788 s/iter. Eval: 0.0006 s/iter. Total: 0.1863 s/iter. ETA=0:01:53\n",
      "\u001b[32m[09/07 00:23:36 d2.evaluation.evaluator]: \u001b[0mInference done 621/1199. Dataloading: 0.1052 s/iter. Inference: 0.0785 s/iter. Eval: 0.0006 s/iter. Total: 0.1845 s/iter. ETA=0:01:46\n",
      "\u001b[32m[09/07 00:23:41 d2.evaluation.evaluator]: \u001b[0mInference done 645/1199. Dataloading: 0.1073 s/iter. Inference: 0.0785 s/iter. Eval: 0.0006 s/iter. Total: 0.1865 s/iter. ETA=0:01:43\n",
      "\u001b[32m[09/07 00:23:47 d2.evaluation.evaluator]: \u001b[0mInference done 675/1199. Dataloading: 0.1072 s/iter. Inference: 0.0782 s/iter. Eval: 0.0006 s/iter. Total: 0.1861 s/iter. ETA=0:01:37\n",
      "\u001b[32m[09/07 00:23:52 d2.evaluation.evaluator]: \u001b[0mInference done 712/1199. Dataloading: 0.1052 s/iter. Inference: 0.0777 s/iter. Eval: 0.0006 s/iter. Total: 0.1836 s/iter. ETA=0:01:29\n",
      "\u001b[32m[09/07 00:23:57 d2.evaluation.evaluator]: \u001b[0mInference done 742/1199. Dataloading: 0.1046 s/iter. Inference: 0.0777 s/iter. Eval: 0.0006 s/iter. Total: 0.1830 s/iter. ETA=0:01:23\n",
      "\u001b[32m[09/07 00:24:02 d2.evaluation.evaluator]: \u001b[0mInference done 757/1199. Dataloading: 0.1076 s/iter. Inference: 0.0780 s/iter. Eval: 0.0006 s/iter. Total: 0.1864 s/iter. ETA=0:01:22\n",
      "\u001b[32m[09/07 00:24:07 d2.evaluation.evaluator]: \u001b[0mInference done 784/1199. Dataloading: 0.1078 s/iter. Inference: 0.0780 s/iter. Eval: 0.0006 s/iter. Total: 0.1865 s/iter. ETA=0:01:17\n",
      "\u001b[32m[09/07 00:24:12 d2.evaluation.evaluator]: \u001b[0mInference done 815/1199. Dataloading: 0.1067 s/iter. Inference: 0.0781 s/iter. Eval: 0.0006 s/iter. Total: 0.1855 s/iter. ETA=0:01:11\n",
      "\u001b[32m[09/07 00:24:17 d2.evaluation.evaluator]: \u001b[0mInference done 847/1199. Dataloading: 0.1056 s/iter. Inference: 0.0781 s/iter. Eval: 0.0006 s/iter. Total: 0.1845 s/iter. ETA=0:01:04\n",
      "\u001b[32m[09/07 00:24:22 d2.evaluation.evaluator]: \u001b[0mInference done 874/1199. Dataloading: 0.1057 s/iter. Inference: 0.0781 s/iter. Eval: 0.0006 s/iter. Total: 0.1846 s/iter. ETA=0:00:59\n",
      "\u001b[32m[09/07 00:24:27 d2.evaluation.evaluator]: \u001b[0mInference done 900/1199. Dataloading: 0.1061 s/iter. Inference: 0.0780 s/iter. Eval: 0.0006 s/iter. Total: 0.1848 s/iter. ETA=0:00:55\n",
      "\u001b[32m[09/07 00:24:33 d2.evaluation.evaluator]: \u001b[0mInference done 931/1199. Dataloading: 0.1056 s/iter. Inference: 0.0780 s/iter. Eval: 0.0006 s/iter. Total: 0.1844 s/iter. ETA=0:00:49\n",
      "\u001b[32m[09/07 00:24:39 d2.evaluation.evaluator]: \u001b[0mInference done 963/1199. Dataloading: 0.1057 s/iter. Inference: 0.0780 s/iter. Eval: 0.0006 s/iter. Total: 0.1844 s/iter. ETA=0:00:43\n",
      "\u001b[32m[09/07 00:24:44 d2.evaluation.evaluator]: \u001b[0mInference done 993/1199. Dataloading: 0.1054 s/iter. Inference: 0.0778 s/iter. Eval: 0.0006 s/iter. Total: 0.1840 s/iter. ETA=0:00:37\n",
      "\u001b[32m[09/07 00:24:49 d2.evaluation.evaluator]: \u001b[0mInference done 1019/1199. Dataloading: 0.1063 s/iter. Inference: 0.0777 s/iter. Eval: 0.0006 s/iter. Total: 0.1847 s/iter. ETA=0:00:33\n",
      "\u001b[32m[09/07 00:24:54 d2.evaluation.evaluator]: \u001b[0mInference done 1048/1199. Dataloading: 0.1061 s/iter. Inference: 0.0776 s/iter. Eval: 0.0006 s/iter. Total: 0.1845 s/iter. ETA=0:00:27\n",
      "\u001b[32m[09/07 00:24:59 d2.evaluation.evaluator]: \u001b[0mInference done 1075/1199. Dataloading: 0.1061 s/iter. Inference: 0.0778 s/iter. Eval: 0.0006 s/iter. Total: 0.1846 s/iter. ETA=0:00:22\n",
      "\u001b[32m[09/07 00:25:04 d2.evaluation.evaluator]: \u001b[0mInference done 1107/1199. Dataloading: 0.1054 s/iter. Inference: 0.0776 s/iter. Eval: 0.0006 s/iter. Total: 0.1838 s/iter. ETA=0:00:16\n",
      "\u001b[32m[09/07 00:25:09 d2.evaluation.evaluator]: \u001b[0mInference done 1131/1199. Dataloading: 0.1062 s/iter. Inference: 0.0774 s/iter. Eval: 0.0006 s/iter. Total: 0.1844 s/iter. ETA=0:00:12\n",
      "\u001b[32m[09/07 00:25:15 d2.evaluation.evaluator]: \u001b[0mInference done 1161/1199. Dataloading: 0.1061 s/iter. Inference: 0.0774 s/iter. Eval: 0.0006 s/iter. Total: 0.1842 s/iter. ETA=0:00:07\n",
      "\u001b[32m[09/07 00:25:20 d2.evaluation.evaluator]: \u001b[0mInference done 1195/1199. Dataloading: 0.1052 s/iter. Inference: 0.0772 s/iter. Eval: 0.0006 s/iter. Total: 0.1832 s/iter. ETA=0:00:00\n",
      "\u001b[32m[09/07 00:25:21 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:03:38.989294 (0.183408 s / iter per device, on 1 devices)\n",
      "\u001b[32m[09/07 00:25:21 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:01:32 (0.077189 s / iter per device, on 1 devices)\n",
      "\u001b[32m[09/07 00:25:21 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[09/07 00:25:21 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.02s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[09/07 00:25:21 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[09/07 00:25:21 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.22 seconds.\n",
      "\u001b[32m[09/07 00:25:21 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[09/07 00:25:21 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.02 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.707\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.831\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.826\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.707\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.821\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.821\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.821\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.821\n",
      "\u001b[32m[09/07 00:25:21 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
      "| 70.719 | 83.079 | 82.578 |  nan  |  nan  | 70.719 |\n",
      "\u001b[32m[09/07 00:25:21 d2.evaluation.coco_evaluation]: \u001b[0mSome metrics cannot be computed and is shown as NaN.\n",
      "\u001b[32m[09/07 00:25:21 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category   | AP     | category   | AP     | category   | AP     |\n",
      "|:-----------|:-------|:-----------|:-------|:-----------|:-------|\n",
      "| angry      | 64.581 | sad        | 67.982 | surprised  | 68.463 |\n",
      "| happy      | 81.850 |            |        |            |        |\n",
      "\u001b[32m[09/07 00:25:21 d2.engine.defaults]: \u001b[0mEvaluation results for face_data_set_valid in csv format:\n",
      "\u001b[32m[09/07 00:25:21 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[09/07 00:25:21 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[09/07 00:25:21 d2.evaluation.testing]: \u001b[0mcopypaste: 70.7189,83.0792,82.5778,nan,nan,70.7189\n",
      "\u001b[32m[09/07 00:25:21 d2.utils.events]: \u001b[0m eta: 16 days, 11:58:35  iter: 10999  total_loss: 0.1457  loss_cls: 0.0304  loss_box_reg: 0.1104  loss_rpn_cls: 4.428e-05  loss_rpn_loc: 0.001536    time: 2.5528  last_time: 2.1888  data_time: 1.8130  last_data_time: 1.2570   lr: 0.00099917  max_mem: 4121M\n",
      "\u001b[32m[09/07 00:26:17 d2.utils.events]: \u001b[0m eta: 16 days, 12:09:51  iter: 11019  total_loss: 0.1488  loss_cls: 0.03626  loss_box_reg: 0.1066  loss_rpn_cls: 6.508e-05  loss_rpn_loc: 0.001388    time: 2.5533  last_time: 2.3520  data_time: 1.7427  last_data_time: 1.4407   lr: 0.00099917  max_mem: 4121M\n",
      "\u001b[32m[09/07 00:27:15 d2.utils.events]: \u001b[0m eta: 16 days, 12:41:58  iter: 11039  total_loss: 0.1724  loss_cls: 0.05323  loss_box_reg: 0.1093  loss_rpn_cls: 4.194e-05  loss_rpn_loc: 0.001433    time: 2.5540  last_time: 2.4523  data_time: 1.8428  last_data_time: 1.5177   lr: 0.00099917  max_mem: 4121M\n",
      "\u001b[32m[09/07 00:28:07 d2.utils.events]: \u001b[0m eta: 16 days, 12:46:00  iter: 11059  total_loss: 0.1448  loss_cls: 0.0357  loss_box_reg: 0.1081  loss_rpn_cls: 5.172e-05  loss_rpn_loc: 0.00152    time: 2.5541  last_time: 2.3980  data_time: 1.6226  last_data_time: 1.4684   lr: 0.00099916  max_mem: 4121M\n",
      "\u001b[32m[09/07 00:29:03 d2.utils.events]: \u001b[0m eta: 16 days, 14:51:14  iter: 11079  total_loss: 0.1437  loss_cls: 0.03429  loss_box_reg: 0.1072  loss_rpn_cls: 5.542e-05  loss_rpn_loc: 0.001373    time: 2.5545  last_time: 2.5905  data_time: 1.7649  last_data_time: 1.6808   lr: 0.00099916  max_mem: 4121M\n",
      "\u001b[32m[09/07 00:30:03 d2.utils.events]: \u001b[0m eta: 16 days, 15:12:00  iter: 11099  total_loss: 0.1512  loss_cls: 0.03502  loss_box_reg: 0.1079  loss_rpn_cls: 4.801e-05  loss_rpn_loc: 0.001432    time: 2.5554  last_time: 2.9756  data_time: 1.9286  last_data_time: 1.8656   lr: 0.00099916  max_mem: 4121M\n",
      "\u001b[32m[09/07 00:30:53 d2.utils.events]: \u001b[0m eta: 16 days, 16:13:38  iter: 11119  total_loss: 0.1507  loss_cls: 0.04603  loss_box_reg: 0.1062  loss_rpn_cls: 5.774e-05  loss_rpn_loc: 0.001355    time: 2.5554  last_time: 2.3712  data_time: 1.5706  last_data_time: 1.4075   lr: 0.00099915  max_mem: 4121M\n",
      "\u001b[32m[09/07 00:31:46 d2.utils.events]: \u001b[0m eta: 16 days, 16:51:31  iter: 11139  total_loss: 0.1421  loss_cls: 0.03794  loss_box_reg: 0.105  loss_rpn_cls: 5.251e-05  loss_rpn_loc: 0.001301    time: 2.5555  last_time: 2.4455  data_time: 1.6520  last_data_time: 1.4647   lr: 0.00099915  max_mem: 4121M\n",
      "\u001b[32m[09/07 00:32:40 d2.utils.events]: \u001b[0m eta: 16 days, 16:50:42  iter: 11159  total_loss: 0.1428  loss_cls: 0.04098  loss_box_reg: 0.102  loss_rpn_cls: 3.05e-05  loss_rpn_loc: 0.001387    time: 2.5558  last_time: 3.9900  data_time: 1.7072  last_data_time: 2.9827   lr: 0.00099915  max_mem: 4121M\n",
      "\u001b[32m[09/07 00:33:33 d2.utils.events]: \u001b[0m eta: 16 days, 18:01:47  iter: 11179  total_loss: 0.1467  loss_cls: 0.0347  loss_box_reg: 0.101  loss_rpn_cls: 5.047e-05  loss_rpn_loc: 0.001461    time: 2.5560  last_time: 2.7114  data_time: 1.6892  last_data_time: 1.7894   lr: 0.00099914  max_mem: 4121M\n",
      "\u001b[32m[09/07 00:34:25 d2.utils.events]: \u001b[0m eta: 16 days, 18:20:47  iter: 11199  total_loss: 0.1463  loss_cls: 0.03276  loss_box_reg: 0.1096  loss_rpn_cls: 6.369e-05  loss_rpn_loc: 0.0015    time: 2.5561  last_time: 2.5551  data_time: 1.6299  last_data_time: 1.5789   lr: 0.00099914  max_mem: 4121M\n",
      "\u001b[32m[09/07 00:35:17 d2.utils.events]: \u001b[0m eta: 16 days, 19:09:21  iter: 11219  total_loss: 0.1426  loss_cls: 0.03075  loss_box_reg: 0.1058  loss_rpn_cls: 4.995e-05  loss_rpn_loc: 0.001413    time: 2.5562  last_time: 2.5721  data_time: 1.6041  last_data_time: 1.6003   lr: 0.00099914  max_mem: 4121M\n",
      "\u001b[32m[09/07 00:36:11 d2.utils.events]: \u001b[0m eta: 16 days, 20:05:04  iter: 11239  total_loss: 0.1377  loss_cls: 0.03008  loss_box_reg: 0.1017  loss_rpn_cls: 8.161e-05  loss_rpn_loc: 0.001449    time: 2.5565  last_time: 2.3363  data_time: 1.7001  last_data_time: 1.4532   lr: 0.00099913  max_mem: 4121M\n",
      "\u001b[32m[09/07 00:37:04 d2.utils.events]: \u001b[0m eta: 16 days, 20:40:05  iter: 11259  total_loss: 0.1437  loss_cls: 0.03271  loss_box_reg: 0.1067  loss_rpn_cls: 7.895e-05  loss_rpn_loc: 0.001262    time: 2.5567  last_time: 2.6604  data_time: 1.7021  last_data_time: 1.7186   lr: 0.00099913  max_mem: 4121M\n",
      "\u001b[32m[09/07 00:37:53 d2.utils.events]: \u001b[0m eta: 16 days, 20:43:20  iter: 11279  total_loss: 0.1449  loss_cls: 0.02864  loss_box_reg: 0.1118  loss_rpn_cls: 7.146e-05  loss_rpn_loc: 0.001377    time: 2.5564  last_time: 2.4369  data_time: 1.5041  last_data_time: 1.6582   lr: 0.00099913  max_mem: 4121M\n",
      "\u001b[32m[09/07 00:38:42 d2.utils.events]: \u001b[0m eta: 16 days, 20:48:14  iter: 11299  total_loss: 0.1499  loss_cls: 0.03753  loss_box_reg: 0.1093  loss_rpn_cls: 4.711e-05  loss_rpn_loc: 0.001526    time: 2.5562  last_time: 2.1810  data_time: 1.5736  last_data_time: 1.3883   lr: 0.00099913  max_mem: 4121M\n",
      "\u001b[32m[09/07 00:39:32 d2.utils.events]: \u001b[0m eta: 16 days, 20:52:09  iter: 11319  total_loss: 0.1511  loss_cls: 0.02827  loss_box_reg: 0.1157  loss_rpn_cls: 4.856e-05  loss_rpn_loc: 0.001479    time: 2.5561  last_time: 3.3532  data_time: 1.5995  last_data_time: 2.3625   lr: 0.00099912  max_mem: 4121M\n",
      "\u001b[32m[09/07 00:40:22 d2.utils.events]: \u001b[0m eta: 16 days, 20:36:48  iter: 11339  total_loss: 0.1459  loss_cls: 0.0343  loss_box_reg: 0.1145  loss_rpn_cls: 4.368e-05  loss_rpn_loc: 0.001396    time: 2.5559  last_time: 2.0505  data_time: 1.5897  last_data_time: 1.2576   lr: 0.00099912  max_mem: 4121M\n",
      "\u001b[32m[09/07 00:41:04 d2.utils.events]: \u001b[0m eta: 16 days, 20:00:07  iter: 11359  total_loss: 0.1545  loss_cls: 0.04884  loss_box_reg: 0.09774  loss_rpn_cls: 4.184e-05  loss_rpn_loc: 0.001418    time: 2.5551  last_time: 2.2921  data_time: 1.2767  last_data_time: 1.4917   lr: 0.00099912  max_mem: 4121M\n",
      "\u001b[32m[09/07 00:41:51 d2.utils.events]: \u001b[0m eta: 16 days, 20:14:07  iter: 11379  total_loss: 0.1549  loss_cls: 0.04589  loss_box_reg: 0.09611  loss_rpn_cls: 6.223e-05  loss_rpn_loc: 0.001342    time: 2.5547  last_time: 2.1578  data_time: 1.4786  last_data_time: 1.3325   lr: 0.00099911  max_mem: 4121M\n",
      "\u001b[32m[09/07 00:42:40 d2.utils.events]: \u001b[0m eta: 16 days, 20:29:23  iter: 11399  total_loss: 0.1319  loss_cls: 0.02667  loss_box_reg: 0.1014  loss_rpn_cls: 7.428e-05  loss_rpn_loc: 0.001591    time: 2.5545  last_time: 2.2688  data_time: 1.5420  last_data_time: 1.3707   lr: 0.00099911  max_mem: 4121M\n",
      "\u001b[32m[09/07 00:43:28 d2.utils.events]: \u001b[0m eta: 16 days, 20:12:28  iter: 11419  total_loss: 0.1436  loss_cls: 0.0343  loss_box_reg: 0.109  loss_rpn_cls: 4.835e-05  loss_rpn_loc: 0.001377    time: 2.5542  last_time: 2.8658  data_time: 1.4890  last_data_time: 1.8601   lr: 0.00099911  max_mem: 4121M\n",
      "\u001b[32m[09/07 00:44:15 d2.utils.events]: \u001b[0m eta: 16 days, 19:55:33  iter: 11439  total_loss: 0.145  loss_cls: 0.03837  loss_box_reg: 0.09972  loss_rpn_cls: 5.784e-05  loss_rpn_loc: 0.001493    time: 2.5538  last_time: 2.1283  data_time: 1.4661  last_data_time: 1.3702   lr: 0.0009991  max_mem: 4121M\n",
      "\u001b[32m[09/07 00:45:08 d2.utils.events]: \u001b[0m eta: 16 days, 20:39:46  iter: 11459  total_loss: 0.1462  loss_cls: 0.03336  loss_box_reg: 0.1027  loss_rpn_cls: 5.765e-05  loss_rpn_loc: 0.001473    time: 2.5540  last_time: 2.7545  data_time: 1.6896  last_data_time: 1.7018   lr: 0.0009991  max_mem: 4121M\n",
      "\u001b[32m[09/07 00:45:58 d2.utils.events]: \u001b[0m eta: 16 days, 20:51:36  iter: 11479  total_loss: 0.1497  loss_cls: 0.03629  loss_box_reg: 0.1073  loss_rpn_cls: 5.627e-05  loss_rpn_loc: 0.001449    time: 2.5539  last_time: 2.4934  data_time: 1.6357  last_data_time: 1.6604   lr: 0.0009991  max_mem: 4121M\n",
      "\u001b[32m[09/07 00:46:52 d2.utils.events]: \u001b[0m eta: 16 days, 21:29:53  iter: 11499  total_loss: 0.152  loss_cls: 0.04078  loss_box_reg: 0.1086  loss_rpn_cls: 5.814e-05  loss_rpn_loc: 0.001366    time: 2.5540  last_time: 3.6305  data_time: 1.6523  last_data_time: 2.6688   lr: 0.00099909  max_mem: 4121M\n",
      "\u001b[32m[09/07 00:47:40 d2.utils.events]: \u001b[0m eta: 16 days, 20:05:45  iter: 11519  total_loss: 0.1371  loss_cls: 0.03428  loss_box_reg: 0.09767  loss_rpn_cls: 5.984e-05  loss_rpn_loc: 0.001274    time: 2.5536  last_time: 2.4649  data_time: 1.4518  last_data_time: 1.5616   lr: 0.00099909  max_mem: 4121M\n",
      "\u001b[32m[09/07 00:48:26 d2.utils.events]: \u001b[0m eta: 16 days, 18:22:55  iter: 11539  total_loss: 0.1386  loss_cls: 0.03034  loss_box_reg: 0.108  loss_rpn_cls: 5.223e-05  loss_rpn_loc: 0.001346    time: 2.5531  last_time: 2.1942  data_time: 1.4106  last_data_time: 1.2164   lr: 0.00099909  max_mem: 4121M\n",
      "\u001b[32m[09/07 00:49:12 d2.utils.events]: \u001b[0m eta: 16 days, 16:07:35  iter: 11559  total_loss: 0.1497  loss_cls: 0.03515  loss_box_reg: 0.1065  loss_rpn_cls: 4.007e-05  loss_rpn_loc: 0.001427    time: 2.5527  last_time: 2.3590  data_time: 1.4442  last_data_time: 1.3389   lr: 0.00099908  max_mem: 4121M\n",
      "\u001b[32m[09/07 00:49:59 d2.utils.events]: \u001b[0m eta: 16 days, 14:30:55  iter: 11579  total_loss: 0.1323  loss_cls: 0.02752  loss_box_reg: 0.1044  loss_rpn_cls: 4.781e-05  loss_rpn_loc: 0.001378    time: 2.5523  last_time: 2.8641  data_time: 1.3875  last_data_time: 1.9206   lr: 0.00099908  max_mem: 4121M\n",
      "\u001b[32m[09/07 00:50:48 d2.utils.events]: \u001b[0m eta: 16 days, 13:55:54  iter: 11599  total_loss: 0.1347  loss_cls: 0.02996  loss_box_reg: 0.1049  loss_rpn_cls: 7.163e-05  loss_rpn_loc: 0.001375    time: 2.5522  last_time: 2.5563  data_time: 1.5536  last_data_time: 1.6341   lr: 0.00099908  max_mem: 4121M\n",
      "\u001b[32m[09/07 00:51:37 d2.utils.events]: \u001b[0m eta: 16 days, 12:49:37  iter: 11619  total_loss: 0.1231  loss_cls: 0.02787  loss_box_reg: 0.09457  loss_rpn_cls: 4.073e-05  loss_rpn_loc: 0.001363    time: 2.5519  last_time: 2.2738  data_time: 1.5329  last_data_time: 1.4415   lr: 0.00099908  max_mem: 4121M\n",
      "\u001b[32m[09/07 00:52:23 d2.utils.events]: \u001b[0m eta: 16 days, 11:52:24  iter: 11639  total_loss: 0.1338  loss_cls: 0.02717  loss_box_reg: 0.1041  loss_rpn_cls: 4.346e-05  loss_rpn_loc: 0.00157    time: 2.5514  last_time: 3.5548  data_time: 1.4045  last_data_time: 2.3256   lr: 0.00099907  max_mem: 4121M\n",
      "\u001b[32m[09/07 00:53:12 d2.utils.events]: \u001b[0m eta: 16 days, 12:06:52  iter: 11659  total_loss: 0.1518  loss_cls: 0.0315  loss_box_reg: 0.1098  loss_rpn_cls: 5.544e-05  loss_rpn_loc: 0.001518    time: 2.5512  last_time: 2.3923  data_time: 1.5253  last_data_time: 1.5154   lr: 0.00099907  max_mem: 4121M\n",
      "\u001b[32m[09/07 00:53:59 d2.utils.events]: \u001b[0m eta: 16 days, 11:44:34  iter: 11679  total_loss: 0.1598  loss_cls: 0.04241  loss_box_reg: 0.1112  loss_rpn_cls: 4.816e-05  loss_rpn_loc: 0.001376    time: 2.5508  last_time: 2.6637  data_time: 1.4668  last_data_time: 1.7595   lr: 0.00099907  max_mem: 4121M\n"
     ]
    }
   ],
   "source": [
    "from detectron2.engine import DefaultTrainer, DefaultPredictor\n",
    "from detectron2.data import MetadataCatalog, build_detection_test_loader\n",
    "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.utils.logger import setup_logger\n",
    "from detectron2.config import CfgNode as CN\n",
    "import json\n",
    "import os\n",
    "\n",
    "class CustomTrainer(DefaultTrainer):\n",
    "    @classmethod\n",
    "    def build_evaluator(cls, cfg, dataset_name, output_dir=None):\n",
    "        return COCOEvaluator(dataset_name, cfg, True, output_dir)\n",
    "    \n",
    "    def train(self):\n",
    "        self.results = {\"train\": [], \"test\": []}\n",
    "        super().train()\n",
    "        \n",
    "        # Add evaluation after each epoch\n",
    "        for epoch in range(0, self.cfg.SOLVER.MAX_ITER + 1, self.cfg.TEST.EVAL_PERIOD):\n",
    "            self.do_test(epoch)\n",
    "            if epoch % self.cfg.SOLVER.CHECKPOINT_PERIOD == 0:\n",
    "                self.checkpointer.save(f\"model_{epoch}\")\n",
    "\n",
    "    def do_test(self, epoch):\n",
    "        try:\n",
    "            # Perform evaluation\n",
    "            evaluator = self.build_evaluator(self.cfg, self.cfg.DATASETS.TEST[0], output_dir=self.cfg.OUTPUT_DIR)\n",
    "            val_loader = build_detection_test_loader(self.cfg, self.cfg.DATASETS.TEST[0])\n",
    "            results = inference_on_dataset(self.model, val_loader, evaluator)\n",
    "            self.results[\"test\"].append({\"epoch\": epoch, \"results\": results})\n",
    "            print(\"Evaluation results:\", results)\n",
    "    \n",
    "            # Save the results as JSON\n",
    "            self.save_results_as_json()\n",
    "        except Exception as e:\n",
    "            print(f\"Error during evaluation at epoch {epoch}: {e}\")\n",
    "    \n",
    "    def save_results_as_json(self):\n",
    "        try:\n",
    "            output_file_path = os.path.join(self.cfg.OUTPUT_DIR, \"train_test_results.json\")\n",
    "            print(f\"Saving results to: {output_file_path}\")\n",
    "            with open(output_file_path, 'w') as f:\n",
    "                json.dump(self.results, f, indent=2)\n",
    "        except Exception as e:\n",
    "            print(f\"Error saving results as JSON: {e}\")\n",
    "\n",
    "\n",
    "# Set up configuration\n",
    "cfg = get_cfg()\n",
    "cfg.merge_from_file(\"detectron2/configs/COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml\")\n",
    "cfg.DATASETS.TRAIN = (\"face_data_set\",)\n",
    "cfg.DATASETS.TEST = (\"face_data_set_valid\",)\n",
    "cfg.DATALOADER.NUM_WORKERS = 2\n",
    "cfg.MODEL.WEIGHTS = \"detectron2://COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x/137849600/model_final_f10217.pkl\"\n",
    "cfg.SOLVER.IMS_PER_BATCH = 16\n",
    "cfg.SOLVER.BASE_LR = 0.001\n",
    "cfg.SOLVER.MAX_ITER = 600000\n",
    "cfg.INPUT.MIN_SIZE_TRAIN = 512\n",
    "cfg.INPUT.MAX_SIZE_TRAIN = 512\n",
    "cfg.INPUT.MIN_SIZE_TEST = 512\n",
    "cfg.INPUT.MAX_SIZE_TEST = 512\n",
    "cfg.INPUT.RANDOM_FLIP = \"horizontal\"\n",
    "cfg.INPUT.RANDOM_ROTATION = 30\n",
    "cfg.INPUT.CROP = CN({\"ENABLED\": True, \"TYPE\": \"relative_range\", \"SIZE\": [0.8, 0.8]})\n",
    "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 128\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 4\n",
    "cfg.OUTPUT_DIR = \"./models/faster_rcnn_R_50_FPN_3x\"\n",
    "cfg.TEST.EVAL_PERIOD = 1000\n",
    "cfg.SOLVER.CHECKPOINT_PERIOD = 500\n",
    "cfg.SOLVER.LR_SCHEDULER_NAME = \"WarmupCosineLR\"\n",
    "cfg.SOLVER.WARMUP_ITERS = 500\n",
    "\n",
    "setup_logger()\n",
    "trainer = CustomTrainer(cfg)\n",
    "trainer.resume_or_load(resume=True)\n",
    "trainer.train()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
